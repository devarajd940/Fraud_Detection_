2025-09-29 22:28:41,375 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:6123, bind address localhost:6123.
2025-09-29 22:28:41,608 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-09-29 22:28:41,623 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-09-29 22:28:41,624 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-09-29 22:28:41,725 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink@localhost:6123]
2025-09-29 22:28:41,768 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink@localhost:6123
2025-09-29 22:28:41,776 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Loading delegation token providers
2025-09-29 22:28:41,778 INFO  org.apache.flink.runtime.security.token.hadoop.HadoopFSDelegationTokenProvider [] - Hadoop FS is not available (not packaged with this application): NoClassDefFoundError : "org/apache/hadoop/conf/Configuration".
2025-09-29 22:28:41,778 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hadoopfs loaded and initialized
2025-09-29 22:28:41,779 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hbase loaded and initialized
2025-09-29 22:28:41,779 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-09-29 22:28:41,779 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-09-29 22:28:41,779 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-09-29 22:28:41,779 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-09-29 22:28:41,779 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-09-29 22:28:41,779 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-09-29 22:28:41,779 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-09-29 22:28:41,779 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-09-29 22:28:41,779 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token providers loaded successfully
2025-09-29 22:28:41,779 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2025-09-29 22:28:41,780 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2025-09-29 22:28:41,780 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2025-09-29 22:28:41,780 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-09-29 22:28:41,780 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-09-29 22:28:41,780 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-09-29 22:28:41,780 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-09-29 22:28:41,780 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-09-29 22:28:41,780 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-09-29 22:28:41,780 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-09-29 22:28:41,780 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-09-29 22:28:41,780 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2025-09-29 22:28:41,780 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Checking provider and receiver instances consistency
2025-09-29 22:28:41,780 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Provider and receiver instances are consistent
2025-09-29 22:28:41,781 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Obtaining delegation tokens
2025-09-29 22:28:41,782 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation tokens obtained successfully
2025-09-29 22:28:41,782 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping notifications
2025-09-29 22:28:41,794 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Created BLOB server storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/jm_1a906028383dca151aadefbbe5f7ecaf/blobStorage
2025-09-29 22:28:41,795 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Started BLOB server at 127.0.0.1:62142 - max concurrent requests: 50 - max backlog: 1000
2025-09-29 22:28:41,802 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2025-09-29 22:28:41,802 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No trace reporter configured, no metrics will be exposed/reported.
2025-09-29 22:28:41,804 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2025-09-29 22:28:41,811 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-09-29 22:28:41,812 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-09-29 22:28:41,812 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-09-29 22:28:41,816 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink-metrics@localhost:62143]
2025-09-29 22:28:41,819 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink-metrics@localhost:62143
2025-09-29 22:28:41,823 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at pekko://flink-metrics/user/rpc/MetricQueryService .
2025-09-29 22:28:41,868 INFO  org.apache.flink.runtime.dispatcher.FileExecutionGraphInfoStore [] - Initializing FileExecutionGraphInfoStore: Storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/executionGraphStore-ffff51a5-11d1-41b9-81dd-d5fe8f6d9ec0, expiration time 3600000, maximum cache size 52428800 bytes.
2025-09-29 22:28:41,890 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Upload directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-web-a47c4e7e-3855-4a51-882c-c63471e7b175/flink-web-upload does not exist. 
2025-09-29 22:28:41,891 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Created directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-web-a47c4e7e-3855-4a51-882c-c63471e7b175/flink-web-upload for file uploads.
2025-09-29 22:28:41,892 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Starting rest endpoint.
2025-09-29 22:28:42,001 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component log file: /Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-standalonesession-0-Ds-MacBook-Air.local.log
2025-09-29 22:28:42,002 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component stdout file: /Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-standalonesession-0-Ds-MacBook-Air.local.out
2025-09-29 22:28:42,010 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Rest endpoint listening at 127.0.0.1:8081
2025-09-29 22:28:42,011 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - http://127.0.0.1:8081 was granted leadership with leaderSessionID=00000000-0000-0000-0000-000000000000
2025-09-29 22:28:42,012 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Web frontend listening at http://127.0.0.1:8081.
2025-09-29 22:28:42,019 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner [] - DefaultDispatcherRunner was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new DispatcherLeaderProcess.
2025-09-29 22:28:42,021 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Start SessionDispatcherLeaderProcess.
2025-09-29 22:28:42,022 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Starting resource manager service.
2025-09-29 22:28:42,022 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Resource manager service is granted leadership with session id 00000000-0000-0000-0000-000000000000.
2025-09-29 22:28:42,024 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Recover all persisted job graphs that are not finished, yet.
2025-09-29 22:28:42,024 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Successfully recovered 0 persisted job graphs.
2025-09-29 22:28:42,034 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at pekko://flink/user/rpc/dispatcher_0 .
2025-09-29 22:28:42,035 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at pekko://flink/user/rpc/resourcemanager_1 .
2025-09-29 22:28:42,040 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Starting the resource manager.
2025-09-29 22:28:42,042 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Starting the slot manager.
2025-09-29 22:28:42,043 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Starting tokens update task
2025-09-29 22:28:42,043 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping notifications
2025-09-29 22:28:42,043 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date
2025-09-29 22:28:42,938 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering TaskManager with ResourceID localhost:62144-ddfe5b (pekko.tcp://flink@localhost:62144/user/rpc/taskmanager_0) at ResourceManager
2025-09-29 22:28:42,951 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Registering task executor localhost:62144-ddfe5b under c58330be397ff7f56d1b547272976e75 at the slot manager.
2025-09-29 22:30:58,729 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.alerts' (7df07e5df00939a2f3081172614eb8c4).
2025-09-29 22:30:58,730 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.alerts' (7df07e5df00939a2f3081172614eb8c4).
2025-09-29 22:30:58,739 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 7df07e5df00939a2f3081172614eb8c4 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-09-29 22:30:58,746 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_2 .
2025-09-29 22:30:58,752 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.alerts' (7df07e5df00939a2f3081172614eb8c4).
2025-09-29 22:30:58,768 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=60000, backoffMultiplier=1.5, resetBackoffThresholdMS=3600000, jitterFactor=0.1, attemptsBeforeResetBackoff=2147483647, currentRestartAttempt=0, nextRestartTimestamp=-2147483648) for insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4).
2025-09-29 22:30:58,785 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 49ecb251348a2a8a8c7d4007d7829cb5 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:30:58,792 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4).
2025-09-29 22:30:58,792 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-09-29 22:30:58,824 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-09-29 22:30:58,828 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@793a352b
2025-09-29 22:30:58,828 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-09-29 22:30:58,828 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-09-29 22:30:58,841 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-09-29 22:30:58,843 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@616cdc4 for insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4).
2025-09-29 22:30:58,847 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.alerts' (7df07e5df00939a2f3081172614eb8c4) under job master id 00000000000000000000000000000000.
2025-09-29 22:30:58,848 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[1].
2025-09-29 22:30:58,850 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-09-29 22:30:58,850 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state CREATED to RUNNING.
2025-09-29 22:30:58,851 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-09-29 22:30:58,857 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-09-29 22:30:58,859 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-1629489345713191071-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-09-29 22:30:58,861 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-09-29 22:30:58,863 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:30:58,865 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:30:58,865 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-09-29 22:30:58,866 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:30:58,882 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-09-29 22:30:58,883 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-09-29 22:30:58,883 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-09-29 22:30:58,883 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1759165258882
2025-09-29 22:30:58,884 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-09-29 22:30:58,930 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 7df07e5df00939a2f3081172614eb8c4
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:62144-ddfe5b
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-09-29 22:30:58,932 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot ce406ef2db6298ed9e6990ab03a01b4c from localhost:62144-ddfe5b for job 7df07e5df00939a2f3081172614eb8c4 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-09-29 22:30:58,993 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:30:58,995 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #0) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:30:59,071 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-data-0]
2025-09-29 22:30:59,083 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:30:59,311 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#0) @ localhost
2025-09-29 22:30:59,311 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-data-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-09-29 22:30:59,316 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-09-29 22:30:59,646 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165259641 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:30:59,697 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Completed checkpoint 1 for job 7df07e5df00939a2f3081172614eb8c4 (910 bytes, checkpointDuration=54 ms, finalizationTime=2 ms).
2025-09-29 22:30:59,700 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 1 as completed for source Source: transactions[1].
2025-09-29 22:31:00,298 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@572d088c).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:31:00,319 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:31:00,322 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: transactions[1].
2025-09-29 22:31:00,324 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-09-29 22:31:00,324 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:31:01,335 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:31:01,339 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 1 @ 1759165259641 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:31:01,351 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:31:01,353 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 1 for source Source: transactions[1] to checkpoint.
2025-09-29 22:31:01,354 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_1) switched from CREATED to SCHEDULED.
2025-09-29 22:31:01,355 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:31:01,355 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_1) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:31:01,356 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #1) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_1 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:31:01,366 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_1) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:31:01,383 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#1) @ localhost
2025-09-29 22:31:01,384 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_1) switched from INITIALIZING to RUNNING.
2025-09-29 22:31:01,993 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_1) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@679c2af1).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:31:01,997 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:31:01,998 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#1) of source Source: transactions[1].
2025-09-29 22:31:01,999 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_1.
2025-09-29 22:31:01,999 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:31:03,411 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:31:03,414 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 1 @ 1759165259641 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:31:03,416 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:31:03,417 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 1 for source Source: transactions[1] to checkpoint.
2025-09-29 22:31:03,417 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_2) switched from CREATED to SCHEDULED.
2025-09-29 22:31:03,419 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:31:03,420 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_2) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:31:03,420 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #2) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_2 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:31:03,452 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_2) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:31:03,470 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#2) @ localhost
2025-09-29 22:31:03,471 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_2) switched from INITIALIZING to RUNNING.
2025-09-29 22:31:04,006 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165264005 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:31:04,088 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_2) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65e7e351).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:31:04,090 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:31:04,091 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#2) of source Source: transactions[1].
2025-09-29 22:31:04,091 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_2.
2025-09-29 22:31:04,091 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:31:04,098 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 2 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:31:04,106 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 2 as aborted for source Source: transactions[1].
2025-09-29 22:31:06,167 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:31:06,173 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 1 @ 1759165259641 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:31:06,175 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:31:06,175 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 1 for source Source: transactions[1] to checkpoint.
2025-09-29 22:31:06,176 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_3) switched from CREATED to SCHEDULED.
2025-09-29 22:31:06,180 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:31:06,180 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_3) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:31:06,181 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #3) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_3 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:31:06,219 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_3) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:31:06,243 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#3) @ localhost
2025-09-29 22:31:06,243 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_3) switched from INITIALIZING to RUNNING.
2025-09-29 22:31:06,420 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165266419 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:31:06,863 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_3) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@9c56367).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:31:06,865 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:31:06,865 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#3) of source Source: transactions[1].
2025-09-29 22:31:06,865 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_3.
2025-09-29 22:31:06,865 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:31:06,866 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 3 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:31:06,867 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 3 as aborted for source Source: transactions[1].
2025-09-29 22:31:09,966 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:31:09,968 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 1 @ 1759165259641 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:31:09,970 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:31:09,970 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 1 for source Source: transactions[1] to checkpoint.
2025-09-29 22:31:09,970 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_4) switched from CREATED to SCHEDULED.
2025-09-29 22:31:09,971 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:31:09,972 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_4) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:31:09,972 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #4) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_4 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:31:09,983 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_4) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:31:09,993 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#4) @ localhost
2025-09-29 22:31:09,994 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_4) switched from INITIALIZING to RUNNING.
2025-09-29 22:31:10,599 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165270597 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:31:10,609 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_4) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4597cd10).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:31:10,610 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering Checkpoint 4 for job 7df07e5df00939a2f3081172614eb8c4 failed due to org.apache.flink.runtime.checkpoint.CheckpointException: TaskManager received a checkpoint request for unknown task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_4. Failure reason: Task local checkpoint failure.
2025-09-29 22:31:10,611 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:31:10,611 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#4) of source Source: transactions[1].
2025-09-29 22:31:10,611 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_4.
2025-09-29 22:31:10,612 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:31:10,612 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 4 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: TaskManager received a checkpoint request for unknown task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_4. Failure reason: Task local checkpoint failure.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.triggerCheckpoint(TaskExecutor.java:1103) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[?:?]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[?:?]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) ~[?:?]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) ~[?:?]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) ~[flink-scala_2.12-1.20.2.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) ~[flink-scala_2.12-1.20.2.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) ~[?:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) ~[flink-scala_2.12-1.20.2.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) ~[flink-scala_2.12-1.20.2.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) ~[flink-scala_2.12-1.20.2.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) ~[?:?]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) ~[?:?]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) ~[?:?]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) ~[?:?]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) ~[?:?]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) ~[?:?]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) ~[?:?]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) ~[?:?]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) ~[?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) ~[?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) ~[?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) ~[?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) ~[?:?]
2025-09-29 22:31:10,624 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 4 as aborted for source Source: transactions[1].
2025-09-29 22:31:15,687 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:31:15,690 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 1 @ 1759165259641 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:31:15,691 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:31:15,692 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 1 for source Source: transactions[1] to checkpoint.
2025-09-29 22:31:15,692 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_5) switched from CREATED to SCHEDULED.
2025-09-29 22:31:15,694 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:31:15,694 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_5) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:31:15,695 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #5) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_5 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:31:15,711 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_5) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:31:15,723 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#5) @ localhost
2025-09-29 22:31:15,724 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_5) switched from INITIALIZING to RUNNING.
2025-09-29 22:31:16,186 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165276185 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:31:16,312 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_5) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@70bd1ea3).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:31:16,314 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:31:16,314 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#5) of source Source: transactions[1].
2025-09-29 22:31:16,315 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_5.
2025-09-29 22:31:16,315 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:31:16,315 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 5 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:31:16,317 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 5 as aborted for source Source: transactions[1].
2025-09-29 22:31:23,691 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:31:23,700 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 1 @ 1759165259641 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:31:23,704 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:31:23,705 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 1 for source Source: transactions[1] to checkpoint.
2025-09-29 22:31:23,705 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_6) switched from CREATED to SCHEDULED.
2025-09-29 22:31:23,707 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:31:23,707 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_6) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:31:23,707 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #6) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_6 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:31:23,719 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_6) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:31:23,733 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#6) @ localhost
2025-09-29 22:31:23,733 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_6) switched from INITIALIZING to RUNNING.
2025-09-29 22:31:23,782 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 6 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165283780 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:31:24,340 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_6) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@194513e).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:31:24,342 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:31:24,343 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#6) of source Source: transactions[1].
2025-09-29 22:31:24,343 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_6.
2025-09-29 22:31:24,343 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:31:24,344 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 6 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:31:24,345 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 6 as aborted for source Source: transactions[1].
2025-09-29 22:31:36,742 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:31:36,798 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 1 @ 1759165259641 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:31:36,800 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:31:36,800 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 1 for source Source: transactions[1] to checkpoint.
2025-09-29 22:31:36,801 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_7) switched from CREATED to SCHEDULED.
2025-09-29 22:31:36,807 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_7) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:31:36,808 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #7) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_7 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:31:36,809 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:31:36,868 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_7) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:31:36,898 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#7) @ localhost
2025-09-29 22:31:36,899 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_7) switched from INITIALIZING to RUNNING.
2025-09-29 22:31:36,970 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 7 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165296969 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:31:36,984 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Completed checkpoint 7 for job 7df07e5df00939a2f3081172614eb8c4 (1148 bytes, checkpointDuration=10 ms, finalizationTime=5 ms).
2025-09-29 22:31:36,984 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 7 as completed for source Source: transactions[1].
2025-09-29 22:31:37,700 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_7) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73149e16).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:31:37,702 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_7.
2025-09-29 22:31:37,702 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#7) of source Source: transactions[1].
2025-09-29 22:31:37,702 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:31:37,702 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:31:54,623 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:31:54,631 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 7 @ 1759165296969 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:31:54,633 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:31:54,638 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 7 for source Source: transactions[1] to checkpoint.
2025-09-29 22:31:54,639 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_8) switched from CREATED to SCHEDULED.
2025-09-29 22:31:54,641 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:31:54,642 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_8) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:31:54,643 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #8) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_8 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:31:54,657 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_8) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:31:54,676 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#8) @ localhost
2025-09-29 22:31:54,677 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_8) switched from INITIALIZING to RUNNING.
2025-09-29 22:31:54,786 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 8 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165314785 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:31:54,794 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Completed checkpoint 8 for job 7df07e5df00939a2f3081172614eb8c4 (1148 bytes, checkpointDuration=7 ms, finalizationTime=2 ms).
2025-09-29 22:31:54,795 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 8 as completed for source Source: transactions[1].
2025-09-29 22:31:55,449 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_8) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@754db2b8).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:31:55,452 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:31:55,452 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#8) of source Source: transactions[1].
2025-09-29 22:31:55,453 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_8.
2025-09-29 22:31:55,453 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:32:19,918 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:32:19,926 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:32:19,928 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:32:19,928 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:32:19,929 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_9) switched from CREATED to SCHEDULED.
2025-09-29 22:32:19,931 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:32:19,932 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_9) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:32:19,932 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #9) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_9 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:32:19,951 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_9) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:32:19,968 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#9) @ localhost
2025-09-29 22:32:19,969 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_9) switched from INITIALIZING to RUNNING.
2025-09-29 22:32:20,503 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 9 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165340501 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:32:20,539 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_9) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@43352eff).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:32:20,542 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:32:20,543 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#9) of source Source: transactions[1].
2025-09-29 22:32:20,543 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_9.
2025-09-29 22:32:20,543 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:32:20,544 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 9 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:32:20,547 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 9 as aborted for source Source: transactions[1].
2025-09-29 22:32:59,021 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:32:59,024 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:32:59,025 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:32:59,026 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:32:59,026 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_10) switched from CREATED to SCHEDULED.
2025-09-29 22:32:59,027 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:32:59,028 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_10) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:32:59,028 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #10) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_10 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:32:59,039 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_10) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:32:59,054 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#10) @ localhost
2025-09-29 22:32:59,054 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_10) switched from INITIALIZING to RUNNING.
2025-09-29 22:32:59,658 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_10) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19582440).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:32:59,660 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:32:59,661 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#10) of source Source: transactions[1].
2025-09-29 22:32:59,663 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_10.
2025-09-29 22:32:59,663 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:33:59,676 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:33:59,685 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:33:59,688 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:33:59,689 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:33:59,690 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_11) switched from CREATED to SCHEDULED.
2025-09-29 22:33:59,692 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:33:59,693 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_11) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:33:59,693 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #11) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_11 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:33:59,719 INFO  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger checkpoint for job 7df07e5df00939a2f3081172614eb8c4 since Checkpoint triggering task Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) of job 7df07e5df00939a2f3081172614eb8c4 is not being executed at the moment. Aborting checkpoint. Failure reason: Not all required tasks are currently running..
2025-09-29 22:33:59,735 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_11) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:33:59,796 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#11) @ localhost
2025-09-29 22:33:59,797 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_11) switched from INITIALIZING to RUNNING.
2025-09-29 22:34:00,661 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_11) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53b3db8b).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:34:00,666 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:34:00,666 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#11) of source Source: transactions[1].
2025-09-29 22:34:00,666 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_11.
2025-09-29 22:34:00,666 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:35:00,671 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:35:00,678 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:35:00,694 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:35:00,696 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:35:00,696 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_12) switched from CREATED to SCHEDULED.
2025-09-29 22:35:00,698 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:35:00,699 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_12) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:35:00,699 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #12) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_12 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ce406ef2db6298ed9e6990ab03a01b4c
2025-09-29 22:35:00,724 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_12) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:35:00,745 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#12) @ localhost
2025-09-29 22:35:00,745 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_12) switched from INITIALIZING to RUNNING.
2025-09-29 22:35:01,036 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 10 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165501032 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:35:01,312 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_12) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@155f62c5).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:35:01,316 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:35:01,317 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#12) of source Source: transactions[1].
2025-09-29 22:35:01,317 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_12.
2025-09-29 22:35:01,317 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:35:01,319 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 10 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:35:01,327 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 10 as aborted for source Source: transactions[1].
2025-09-29 22:35:58,898 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [ce406ef2db6298ed9e6990ab03a01b4c].
2025-09-29 22:35:58,919 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot ce406ef2db6298ed9e6990ab03a01b4c.
2025-09-29 22:35:58,924 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:62144-ddfe5b because: TaskExecutor pekko.tcp://flink@localhost:62144/user/rpc/taskmanager_0 has no more allocated slots for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:35:59,027 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-1629489345713191071-enumerator-admin-client] Node -1 disconnected.
2025-09-29 22:36:01,333 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:36:01,337 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:36:01,339 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:36:01,339 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:36:01,340 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_13) switched from CREATED to SCHEDULED.
2025-09-29 22:36:01,342 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:36:01,412 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 7df07e5df00939a2f3081172614eb8c4
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:62144-ddfe5b
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-09-29 22:36:01,414 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 08b2e2d58b632478e4d2d7538ff5a572 from localhost:62144-ddfe5b for job 7df07e5df00939a2f3081172614eb8c4 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-09-29 22:36:01,457 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_13) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:36:01,459 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #13) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_13 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id 08b2e2d58b632478e4d2d7538ff5a572
2025-09-29 22:36:01,468 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_13) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:36:01,496 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#13) @ localhost
2025-09-29 22:36:01,497 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_13) switched from INITIALIZING to RUNNING.
2025-09-29 22:36:01,570 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 11 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165561570 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:36:02,104 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_13) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@283e381e).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:36:02,107 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:36:02,108 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#13) of source Source: transactions[1].
2025-09-29 22:36:02,108 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_13.
2025-09-29 22:36:02,108 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:36:02,109 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 11 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:36:02,113 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 11 as aborted for source Source: transactions[1].
2025-09-29 22:37:02,119 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:37:02,125 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:37:02,127 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:37:02,128 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:37:02,129 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_14) switched from CREATED to SCHEDULED.
2025-09-29 22:37:02,141 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:37:02,141 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_14) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:37:02,141 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #14) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_14 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id 08b2e2d58b632478e4d2d7538ff5a572
2025-09-29 22:37:02,164 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_14) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:37:02,179 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#14) @ localhost
2025-09-29 22:37:02,180 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_14) switched from INITIALIZING to RUNNING.
2025-09-29 22:37:02,479 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 12 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165622477 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:37:02,777 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_14) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@74028ca8).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:37:02,781 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:37:02,781 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#14) of source Source: transactions[1].
2025-09-29 22:37:02,782 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_14.
2025-09-29 22:37:02,782 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:37:02,782 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 12 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:37:02,785 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 12 as aborted for source Source: transactions[1].
2025-09-29 22:38:02,789 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:38:02,795 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:38:02,797 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:38:02,798 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:38:02,799 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_15) switched from CREATED to SCHEDULED.
2025-09-29 22:38:02,801 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:38:02,802 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_15) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:38:02,802 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #15) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_15 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id 08b2e2d58b632478e4d2d7538ff5a572
2025-09-29 22:38:02,825 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_15) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:38:02,843 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#15) @ localhost
2025-09-29 22:38:02,844 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_15) switched from INITIALIZING to RUNNING.
2025-09-29 22:38:03,444 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_15) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@10c3ad40).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:38:03,448 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:38:03,448 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#15) of source Source: transactions[1].
2025-09-29 22:38:03,449 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_15.
2025-09-29 22:38:03,449 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:39:03,457 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:39:03,464 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:39:03,472 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:39:03,480 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:39:03,482 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_16) switched from CREATED to SCHEDULED.
2025-09-29 22:39:03,486 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:39:03,487 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_16) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:39:03,487 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #16) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_16 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id 08b2e2d58b632478e4d2d7538ff5a572
2025-09-29 22:39:03,502 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_16) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:39:03,521 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#16) @ localhost
2025-09-29 22:39:03,522 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_16) switched from INITIALIZING to RUNNING.
2025-09-29 22:39:03,680 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 13 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165743679 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:39:04,097 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_16) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5676f253).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:39:04,102 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:39:04,103 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#16) of source Source: transactions[1].
2025-09-29 22:39:04,104 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_16.
2025-09-29 22:39:04,104 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:39:04,105 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 13 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:39:04,110 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 13 as aborted for source Source: transactions[1].
2025-09-29 22:40:04,113 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:40:04,116 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:40:04,118 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:40:04,118 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:40:04,118 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_17) switched from CREATED to SCHEDULED.
2025-09-29 22:40:04,120 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:40:04,121 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_17) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:40:04,121 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #17) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_17 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id 08b2e2d58b632478e4d2d7538ff5a572
2025-09-29 22:40:04,140 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_17) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:40:04,157 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#17) @ localhost
2025-09-29 22:40:04,158 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_17) switched from INITIALIZING to RUNNING.
2025-09-29 22:40:04,641 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 14 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165804638 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:40:04,774 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_17) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56ac0461).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:40:04,786 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:40:04,787 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_17.
2025-09-29 22:40:04,788 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:40:04,788 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#17) of source Source: transactions[1].
2025-09-29 22:40:04,788 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 14 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:40:04,795 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 14 as aborted for source Source: transactions[1].
2025-09-29 22:40:58,937 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [08b2e2d58b632478e4d2d7538ff5a572].
2025-09-29 22:40:58,949 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 08b2e2d58b632478e4d2d7538ff5a572.
2025-09-29 22:40:58,955 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:62144-ddfe5b because: TaskExecutor pekko.tcp://flink@localhost:62144/user/rpc/taskmanager_0 has no more allocated slots for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:41:04,797 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:41:04,801 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:41:04,802 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:41:04,803 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:41:04,803 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_18) switched from CREATED to SCHEDULED.
2025-09-29 22:41:04,805 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:41:04,875 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 7df07e5df00939a2f3081172614eb8c4
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:62144-ddfe5b
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-09-29 22:41:04,876 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot ae3d5b5b52247560d5a5d365049546da from localhost:62144-ddfe5b for job 7df07e5df00939a2f3081172614eb8c4 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-09-29 22:41:04,912 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_18) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:41:04,914 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #18) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_18 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ae3d5b5b52247560d5a5d365049546da
2025-09-29 22:41:04,929 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_18) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:41:04,966 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#18) @ localhost
2025-09-29 22:41:04,967 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_18) switched from INITIALIZING to RUNNING.
2025-09-29 22:41:05,378 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 15 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759165865376 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:41:05,565 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_18) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e8fa083).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:41:05,569 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:41:05,570 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#18) of source Source: transactions[1].
2025-09-29 22:41:05,570 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_18.
2025-09-29 22:41:05,570 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:41:05,571 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 15 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:41:05,574 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 15 as aborted for source Source: transactions[1].
2025-09-29 22:42:05,578 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:42:05,584 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:42:05,586 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:42:05,587 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:42:05,587 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_19) switched from CREATED to SCHEDULED.
2025-09-29 22:42:05,589 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:42:05,590 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_19) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:42:05,590 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #19) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_19 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ae3d5b5b52247560d5a5d365049546da
2025-09-29 22:42:05,611 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_19) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:42:05,637 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#19) @ localhost
2025-09-29 22:42:05,638 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_19) switched from INITIALIZING to RUNNING.
2025-09-29 22:42:06,276 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_19) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46f33ac).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:42:06,279 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:42:06,281 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#19) of source Source: transactions[1].
2025-09-29 22:42:06,281 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_19.
2025-09-29 22:42:06,281 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:43:06,295 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:43:06,301 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:43:06,303 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:43:06,304 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:43:06,305 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_20) switched from CREATED to SCHEDULED.
2025-09-29 22:43:06,319 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:43:06,319 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_20) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:43:06,319 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #20) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_20 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ae3d5b5b52247560d5a5d365049546da
2025-09-29 22:43:06,366 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_20) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:43:06,386 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#20) @ localhost
2025-09-29 22:43:06,387 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_20) switched from INITIALIZING to RUNNING.
2025-09-29 22:43:07,026 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_20) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18e4051a).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:43:07,036 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:43:07,037 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#20) of source Source: transactions[1].
2025-09-29 22:43:07,038 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_20.
2025-09-29 22:43:07,038 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:44:07,045 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:44:07,050 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:44:07,053 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:44:07,053 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:44:07,054 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_21) switched from CREATED to SCHEDULED.
2025-09-29 22:44:07,056 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:44:07,057 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_21) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:44:07,057 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #21) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_21 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ae3d5b5b52247560d5a5d365049546da
2025-09-29 22:44:07,082 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_21) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:44:07,101 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#21) @ localhost
2025-09-29 22:44:07,102 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_21) switched from INITIALIZING to RUNNING.
2025-09-29 22:44:07,311 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 16 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759166047310 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:44:07,675 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_21) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46bc7a66).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:44:07,679 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:44:07,680 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#21) of source Source: transactions[1].
2025-09-29 22:44:07,681 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_21.
2025-09-29 22:44:07,681 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:44:07,681 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 16 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:44:07,685 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 16 as aborted for source Source: transactions[1].
2025-09-29 22:45:07,694 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RESTARTING to RUNNING.
2025-09-29 22:45:07,700 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Restoring job 7df07e5df00939a2f3081172614eb8c4 from Checkpoint 8 @ 1759165314785 for 7df07e5df00939a2f3081172614eb8c4 located at <checkpoint-not-externally-addressable>.
2025-09-29 22:45:07,701 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No master state to restore
2025-09-29 22:45:07,702 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Recovering subtask 0 to checkpoint 8 for source Source: transactions[1] to checkpoint.
2025-09-29 22:45:07,702 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_22) switched from CREATED to SCHEDULED.
2025-09-29 22:45:07,707 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 7df07e5df00939a2f3081172614eb8c4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-09-29 22:45:07,707 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_22) switched from SCHEDULED to DEPLOYING.
2025-09-29 22:45:07,708 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #22) with attempt id 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_22 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:62144-ddfe5b @ localhost (dataPort=62146) with allocation id ae3d5b5b52247560d5a5d365049546da
2025-09-29 22:45:07,731 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_22) switched from DEPLOYING to INITIALIZING.
2025-09-29 22:45:07,746 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#22) @ localhost
2025-09-29 22:45:07,748 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_22) switched from INITIALIZING to RUNNING.
2025-09-29 22:45:08,067 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 17 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1759166108066 for job 7df07e5df00939a2f3081172614eb8c4.
2025-09-29 22:45:08,312 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_22) switched from RUNNING to FAILED on localhost:62144-ddfe5b @ localhost (dataPort=62146).
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:203) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.io.IOException: Failed to deserialize consumer record ConsumerRecord(topic = transactions-data, partition = 0, leaderEpoch = 0, offset = 10207, CreateTime = 1759065375065, serialized key size = -1, serialized value size = 125, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@213b81a6).
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:59) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: java.io.IOException: Failed to deserialize JSON '{"transaction_id": "TX000001", "user_id": "AC00128", "amount": 14.09, "timestamp": "11/04/23 16:29", "location": "San Diego"}'.
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:97) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
Caused by: org.apache.flink.formats.json.JsonParseException: Fail to deserialize at field: timestamp.
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$createRowConverter$43b82837$1(JsonParserToRowDataConverters.java:419) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserToRowDataConverters.lambda$wrapIntoNullableConverter$ca96cb8f$1(JsonParserToRowDataConverters.java:463) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:91) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.formats.json.JsonParserRowDataDeserializationSchema.deserialize(JsonParserRowDataDeserializationSchema.java:42) ~[flink-json-1.20.2.jar:1.20.2]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.connectors.kafka.table.DynamicKafkaDeserializationSchema.deserialize(DynamicKafkaDeserializationSchema.java:115) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaDeserializationSchemaWrapper.deserialize(KafkaDeserializationSchemaWrapper.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	... 14 more
2025-09-29 22:45:08,319 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 7df07e5df00939a2f3081172614eb8c4
2025-09-29 22:45:08,320 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#22) of source Source: transactions[1].
2025-09-29 22:45:08,320 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 1 tasks will be restarted to recover the failed task 49ecb251348a2a8a8c7d4007d7829cb5_cbc357ccb763df2852fee8c4fc7d55f2_0_22.
2025-09-29 22:45:08,320 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (7df07e5df00939a2f3081172614eb8c4) switched from state RUNNING to RESTARTING.
2025-09-29 22:45:08,321 WARN  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger or complete checkpoint 17 for job 7df07e5df00939a2f3081172614eb8c4. (0 consecutive failed attempts so far)
org.apache.flink.runtime.checkpoint.CheckpointException: Checkpoint Coordinator is suspending.
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.stopCheckpointScheduler(CheckpointCoordinator.java:2068) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinatorDeActivator.jobStatusChanges(CheckpointCoordinatorDeActivator.java:49) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifyJobStatusChange(DefaultExecutionGraph.java:1609) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1167) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.transitionState(DefaultExecutionGraph.java:1139) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.transitionExecutionGraphState(SchedulerBase.java:601) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.addVerticesToRestartPending(DefaultScheduler.java:386) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.restartTasksWithDelay(DefaultScheduler.java:362) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeRestartTasks(DefaultScheduler.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka2959751e-e72d-4e0e-a257-624608a4715a.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
2025-09-29 22:45:08,323 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 17 as aborted for source Source: transactions[1].
2025-09-29 22:45:50,963 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Closing TaskExecutor connection localhost:62144-ddfe5b because: The TaskExecutor is shutting down.
2025-09-29 22:45:50,964 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Unregistering task executor c58330be397ff7f56d1b547272976e75 from the slot manager.
2025-09-29 22:45:50,964 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot ae3d5b5b52247560d5a5d365049546da.
2025-09-29 22:45:50,968 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [ae3d5b5b52247560d5a5d365049546da].
2025-09-29 22:45:50,969 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:62144-ddfe5b because: The TaskExecutor is shutting down.
2025-09-29 22:45:51,718 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - RECEIVED SIGNAL 15: SIGTERM. Shutting down as requested.
2025-09-29 22:45:51,720 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Shutting StandaloneSessionClusterEntrypoint down with application status UNKNOWN. Diagnostics Cluster entrypoint has been closed externally..
2025-09-29 22:45:51,721 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Stopped BLOB server at 127.0.0.1:62142
