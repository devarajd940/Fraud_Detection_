2025-10-28 22:54:20,117 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Preconfiguration: 
2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - 


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx1073741824 -Xms1073741824 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D jobmanager.memory.off-heap.size=134217728b -D jobmanager.memory.jvm-overhead.min=201326592b -D jobmanager.memory.jvm-metaspace.size=268435456b -D jobmanager.memory.heap.size=1073741824b -D jobmanager.memory.jvm-overhead.max=201326592b
logs: INFO  [] - Using standard YAML parser to load flink configuration file from /Users/dev/Fraud_Detection/flink-1.20.2/conf/config.yaml.
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1728m
INFO  [] - Loading configuration property: taskmanager.bind-host, localhost
INFO  [] - Loading configuration property: jobmanager.execution.failover-strategy, region
INFO  [] - Loading configuration property: jobmanager.rpc.address, localhost
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1600m
INFO  [] - Loading configuration property: jobmanager.rpc.port, 6123
INFO  [] - Loading configuration property: rest.bind-address, localhost
INFO  [] - Loading configuration property: jobmanager.bind-host, localhost
INFO  [] - Loading configuration property: taskmanager.host, localhost
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 4
INFO  [] - Loading configuration property: rest.address, localhost
INFO  [] - Loading configuration property: env.java.opts.all, --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
INFO  [] - The derived from fraction jvm overhead memory (160.000mb (167772162 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final Master Memory configuration:
INFO  [] -   Total Process Memory: 1.563gb (1677721600 bytes)
INFO  [] -     Total Flink Memory: 1.125gb (1207959552 bytes)
INFO  [] -       JVM Heap:         1024.000mb (1073741824 bytes)
INFO  [] -       Off-heap:         128.000mb (134217728 bytes)
INFO  [] -     JVM Metaspace:      256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:       192.000mb (201326592 bytes)

2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Starting StandaloneSessionClusterEntrypoint (Version: 1.20.2, Scala: 2.12, Rev:1641cb9, Date:2025-06-12T21:40:37+02:00)
2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  OS current user: dev
2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Current Hadoop/Kerberos user: <no hadoop dependency found>
2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM: OpenJDK 64-Bit Server VM - Homebrew - 17/17.0.16+0
2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Arch: aarch64
2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Maximum heap size: 1024 MiBytes
2025-10-28 22:54:20,118 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JAVA_HOME: /opt/homebrew/opt/openjdk@17
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  No Hadoop Dependency available
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM Options:
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xmx1073741824
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xms1073741824
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -XX:MaxMetaspaceSize=268435456
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -XX:+IgnoreUnrecognizedVMOptions
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=java.base/sun.net.util=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.lang=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.net=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.io=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.nio=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/sun.nio.ch=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.text=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.time=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.util=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.util.concurrent=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog.file=/Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-standalonesession-0-Ds-MacBook-Air.local.log
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configuration=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/log4j.properties
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configurationFile=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/log4j.properties
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlogback.configurationFile=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/logback.xml
2025-10-28 22:54:20,119 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Program Arguments:
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.off-heap.size=134217728b
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.min=201326592b
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-metaspace.size=268435456b
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.heap.size=1073741824b
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.max=201326592b
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --configDir
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     /Users/dev/Fraud_Detection/flink-1.20.2/conf
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --executionMode
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     cluster
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Classpath: /Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-cep-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-connector-files-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-connector-kafka-3.4.0-1.20.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-csv-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-json-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-scala_2.12-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-api-java-uber-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-planner-loader-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-runtime-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/kafka-clients-3.6.0.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-1.2-api-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-api-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-core-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-slf4j-impl-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-dist-1.20.2.jar::::
2025-10-28 22:54:20,120 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2025-10-28 22:54:20,121 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2025-10-28 22:54:20,125 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Using standard YAML parser to load flink configuration file from /Users/dev/Fraud_Detection/flink-1.20.2/conf/config.yaml.
2025-10-28 22:54:20,142 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1728m
2025-10-28 22:54:20,142 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.bind-host, localhost
2025-10-28 22:54:20,142 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2025-10-28 22:54:20,142 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2025-10-28 22:54:20,142 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1600m
2025-10-28 22:54:20,142 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-address, localhost
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.bind-host, localhost
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.host, localhost
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 4
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.address, localhost
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: env.java.opts.all, --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.off-heap.size, 134217728b
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-overhead.min, 201326592b
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-metaspace.size, 268435456b
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.heap.size, 1073741824b
2025-10-28 22:54:20,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-overhead.max, 201326592b
2025-10-28 22:54:20,161 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Starting StandaloneSessionClusterEntrypoint.
2025-10-28 22:54:20,174 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install default filesystem.
2025-10-28 22:54:20,176 INFO  org.apache.flink.core.fs.FileSystem                          [] - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2025-10-28 22:54:20,186 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-statsd
2025-10-28 22:54:20,188 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-prometheus
2025-10-28 22:54:20,188 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-graphite
2025-10-28 22:54:20,188 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: external-resource-gpu
2025-10-28 22:54:20,188 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-jmx
2025-10-28 22:54:20,188 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-influx
2025-10-28 22:54:20,188 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-slf4j
2025-10-28 22:54:20,188 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-datadog
2025-10-28 22:54:20,196 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install security context.
2025-10-28 22:54:20,201 INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory [] - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.
2025-10-28 22:54:20,207 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/jaas-179735874916127915.conf.
2025-10-28 22:54:20,209 INFO  org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory [] - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.
2025-10-28 22:54:20,209 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Initializing cluster services.
2025-10-28 22:54:20,215 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Using working directory: WorkingDirectory(/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/jm_467535e488a77a2152a8d85ef53ec3b0).
2025-10-28 22:54:20,356 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:6123, bind address localhost:6123.
2025-10-28 22:54:20,595 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-10-28 22:54:20,612 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-10-28 22:54:20,613 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-10-28 22:54:20,711 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink@localhost:6123]
2025-10-28 22:54:20,748 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink@localhost:6123
2025-10-28 22:54:20,755 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Loading delegation token providers
2025-10-28 22:54:20,756 INFO  org.apache.flink.runtime.security.token.hadoop.HadoopFSDelegationTokenProvider [] - Hadoop FS is not available (not packaged with this application): NoClassDefFoundError : "org/apache/hadoop/conf/Configuration".
2025-10-28 22:54:20,756 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hadoopfs loaded and initialized
2025-10-28 22:54:20,757 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hbase loaded and initialized
2025-10-28 22:54:20,757 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-10-28 22:54:20,757 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-10-28 22:54:20,757 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-10-28 22:54:20,757 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-10-28 22:54:20,757 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-10-28 22:54:20,757 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-10-28 22:54:20,757 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-10-28 22:54:20,757 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-10-28 22:54:20,757 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token providers loaded successfully
2025-10-28 22:54:20,757 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2025-10-28 22:54:20,759 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2025-10-28 22:54:20,759 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2025-10-28 22:54:20,759 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-10-28 22:54:20,759 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-10-28 22:54:20,759 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-10-28 22:54:20,759 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-10-28 22:54:20,759 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-10-28 22:54:20,759 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-10-28 22:54:20,759 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-10-28 22:54:20,759 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-10-28 22:54:20,759 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2025-10-28 22:54:20,759 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Checking provider and receiver instances consistency
2025-10-28 22:54:20,759 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Provider and receiver instances are consistent
2025-10-28 22:54:20,759 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Obtaining delegation tokens
2025-10-28 22:54:20,760 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation tokens obtained successfully
2025-10-28 22:54:20,760 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping notifications
2025-10-28 22:54:20,769 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Created BLOB server storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/jm_467535e488a77a2152a8d85ef53ec3b0/blobStorage
2025-10-28 22:54:20,770 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Started BLOB server at 127.0.0.1:49383 - max concurrent requests: 50 - max backlog: 1000
2025-10-28 22:54:20,778 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2025-10-28 22:54:20,778 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No trace reporter configured, no metrics will be exposed/reported.
2025-10-28 22:54:20,780 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2025-10-28 22:54:20,787 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-10-28 22:54:20,788 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-10-28 22:54:20,788 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-10-28 22:54:20,791 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink-metrics@localhost:49384]
2025-10-28 22:54:20,794 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink-metrics@localhost:49384
2025-10-28 22:54:20,800 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at pekko://flink-metrics/user/rpc/MetricQueryService .
2025-10-28 22:54:20,847 INFO  org.apache.flink.runtime.dispatcher.FileExecutionGraphInfoStore [] - Initializing FileExecutionGraphInfoStore: Storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/executionGraphStore-591c1fd6-738c-4880-a445-7950739406ab, expiration time 3600000, maximum cache size 52428800 bytes.
2025-10-28 22:54:20,870 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Upload directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-web-be50d16c-27a3-4da8-a4cc-68f3ead49cc1/flink-web-upload does not exist. 
2025-10-28 22:54:20,871 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Created directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-web-be50d16c-27a3-4da8-a4cc-68f3ead49cc1/flink-web-upload for file uploads.
2025-10-28 22:54:20,872 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Starting rest endpoint.
2025-10-28 22:54:20,986 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component log file: /Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-standalonesession-0-Ds-MacBook-Air.local.log
2025-10-28 22:54:20,986 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component stdout file: /Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-standalonesession-0-Ds-MacBook-Air.local.out
2025-10-28 22:54:20,995 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Rest endpoint listening at 127.0.0.1:8081
2025-10-28 22:54:20,996 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - http://127.0.0.1:8081 was granted leadership with leaderSessionID=00000000-0000-0000-0000-000000000000
2025-10-28 22:54:20,996 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Web frontend listening at http://127.0.0.1:8081.
2025-10-28 22:54:21,004 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner [] - DefaultDispatcherRunner was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new DispatcherLeaderProcess.
2025-10-28 22:54:21,006 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Start SessionDispatcherLeaderProcess.
2025-10-28 22:54:21,007 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Starting resource manager service.
2025-10-28 22:54:21,007 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Resource manager service is granted leadership with session id 00000000-0000-0000-0000-000000000000.
2025-10-28 22:54:21,009 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Recover all persisted job graphs that are not finished, yet.
2025-10-28 22:54:21,009 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Successfully recovered 0 persisted job graphs.
2025-10-28 22:54:21,016 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at pekko://flink/user/rpc/dispatcher_0 .
2025-10-28 22:54:21,019 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at pekko://flink/user/rpc/resourcemanager_1 .
2025-10-28 22:54:21,024 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Starting the resource manager.
2025-10-28 22:54:21,029 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Starting the slot manager.
2025-10-28 22:54:21,029 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Starting tokens update task
2025-10-28 22:54:21,029 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping notifications
2025-10-28 22:54:21,029 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date
2025-10-28 22:54:21,915 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering TaskManager with ResourceID localhost:49385-5990f3 (pekko.tcp://flink@localhost:49385/user/rpc/taskmanager_0) at ResourceManager
2025-10-28 22:54:21,926 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Registering task executor localhost:49385-5990f3 under 1a66a6d805f931bd2c182227b4d834e1 at the slot manager.
2025-10-28 22:56:08,943 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.alerts' (6ea2503ef4a8a3467dce3baae050fe41).
2025-10-28 22:56:08,945 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.alerts' (6ea2503ef4a8a3467dce3baae050fe41).
2025-10-28 22:56:08,952 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 6ea2503ef4a8a3467dce3baae050fe41 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-28 22:56:08,957 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_2 .
2025-10-28 22:56:08,960 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.alerts' (6ea2503ef4a8a3467dce3baae050fe41).
2025-10-28 22:56:08,973 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.alerts (6ea2503ef4a8a3467dce3baae050fe41).
2025-10-28 22:56:08,987 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 0fa840a28117ec86c3f68e5c65e59029 for job 6ea2503ef4a8a3467dce3baae050fe41.
2025-10-28 22:56:08,996 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.alerts (6ea2503ef4a8a3467dce3baae050fe41).
2025-10-28 22:56:08,996 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-28 22:56:09,028 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-28 22:56:09,031 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1f7e5174
2025-10-28 22:56:09,031 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-28 22:56:09,032 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-28 22:56:09,045 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-28 22:56:09,047 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@5e531549 for insert-into_default_catalog.default_database.alerts (6ea2503ef4a8a3467dce3baae050fe41).
2025-10-28 22:56:09,051 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.alerts' (6ea2503ef4a8a3467dce3baae050fe41) under job master id 00000000000000000000000000000000.
2025-10-28 22:56:09,052 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[1].
2025-10-28 22:56:09,053 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-28 22:56:09,053 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (6ea2503ef4a8a3467dce3baae050fe41) switched from state CREATED to RUNNING.
2025-10-28 22:56:09,054 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (0fa840a28117ec86c3f68e5c65e59029_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-28 22:56:09,060 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-28 22:56:09,061 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--8706818374987702430-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-28 22:56:09,062 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-28 22:56:09,063 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 6ea2503ef4a8a3467dce3baae050fe41.
2025-10-28 22:56:09,066 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 6ea2503ef4a8a3467dce3baae050fe41.
2025-10-28 22:56:09,066 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-28 22:56:09,067 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 6ea2503ef4a8a3467dce3baae050fe41: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-28 22:56:09,084 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-28 22:56:09,084 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-28 22:56:09,084 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-28 22:56:09,084 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761672369084
2025-10-28 22:56:09,085 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-28 22:56:09,128 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 6ea2503ef4a8a3467dce3baae050fe41
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-28 22:56:09,130 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot b3f572ead95110f8d0c8850c7d7c14df from localhost:49385-5990f3 for job 6ea2503ef4a8a3467dce3baae050fe41 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-28 22:56:09,171 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (0fa840a28117ec86c3f68e5c65e59029_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-28 22:56:09,176 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (attempt #0) with attempt id 0fa840a28117ec86c3f68e5c65e59029_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id b3f572ead95110f8d0c8850c7d7c14df
2025-10-28 22:56:09,216 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-data-0]
2025-10-28 22:56:09,243 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (0fa840a28117ec86c3f68e5c65e59029_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-28 22:56:09,449 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#0) @ localhost
2025-10-28 22:56:09,449 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-data-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-28 22:56:09,454 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (0fa840a28117ec86c3f68e5c65e59029_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-28 23:01:09,229 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node -1 disconnected.
2025-10-29 21:44:43,697 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 21:44:43,831 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 21:44:43,831 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 21:44:43,933 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 21:44:43,933 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 21:44:44,136 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 21:44:44,136 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 21:44:44,663 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 21:44:44,664 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 21:44:45,472 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 21:44:45,472 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 21:44:46,691 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 21:44:46,695 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 21:56:48,571 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.filtered_transactions' (cd26c9845974958140a55e4f03b31f62).
2025-10-29 21:56:48,576 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.filtered_transactions' (cd26c9845974958140a55e4f03b31f62).
2025-10-29 21:56:48,581 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job cd26c9845974958140a55e4f03b31f62 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-29 21:56:48,612 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_3 .
2025-10-29 21:56:48,614 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.filtered_transactions' (cd26c9845974958140a55e4f03b31f62).
2025-10-29 21:56:48,619 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.filtered_transactions (cd26c9845974958140a55e4f03b31f62).
2025-10-29 21:56:48,632 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 7be2db6bef65caecd0a090d04fa7ba25 for job cd26c9845974958140a55e4f03b31f62.
2025-10-29 21:56:48,634 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.filtered_transactions (cd26c9845974958140a55e4f03b31f62).
2025-10-29 21:56:48,635 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-29 21:56:48,682 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: transactions[1] -> Calc[2] -> filtered_transactions[3]: Writer -> filtered_transactions[3]: Committer exceeded the 80 characters length limit and was truncated.
2025-10-29 21:56:48,684 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-29 21:56:48,685 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1a9ccc64
2025-10-29 21:56:48,685 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-29 21:56:48,685 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-29 21:56:48,693 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-29 21:56:48,693 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@4072cf39 for insert-into_default_catalog.default_database.filtered_transactions (cd26c9845974958140a55e4f03b31f62).
2025-10-29 21:56:48,695 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.filtered_transactions' (cd26c9845974958140a55e4f03b31f62) under job master id 00000000000000000000000000000000.
2025-10-29 21:56:48,695 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[1].
2025-10-29 21:56:48,695 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-29 21:56:48,696 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.filtered_transactions (cd26c9845974958140a55e4f03b31f62) switched from state CREATED to RUNNING.
2025-10-29 21:56:48,696 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> filtered_transactions[3]: Writer -> filtered_transactions[3]: Committer (1/1) (7be2db6bef65caecd0a090d04fa7ba25_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-29 21:56:48,698 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-29 21:56:48,698 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-5159150177618345690-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-29 21:56:48,704 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-29 21:56:48,704 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-29 21:56:48,704 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-29 21:56:48,704 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761755208704
2025-10-29 21:56:48,705 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-29 21:56:48,705 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-29 21:56:48,706 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job cd26c9845974958140a55e4f03b31f62.
2025-10-29 21:56:48,707 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job cd26c9845974958140a55e4f03b31f62.
2025-10-29 21:56:48,708 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-29 21:56:48,708 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job cd26c9845974958140a55e4f03b31f62: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-29 21:56:48,722 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-29 21:56:48,779 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job cd26c9845974958140a55e4f03b31f62
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=3, taskHeapMemory=288.000mb (301989881 bytes), taskOffHeapMemory=0 bytes, managedMemory=384.000mb (402653190 bytes), networkMemory=96.000mb (100663298 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-29 21:56:48,781 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 6bce14e4e18e05b18abb18af469b92b9 from localhost:49385-5990f3 for job cd26c9845974958140a55e4f03b31f62 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-29 21:56:48,951 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> filtered_transactions[3]: Writer -> filtered_transactions[3]: Committer (1/1) (7be2db6bef65caecd0a090d04fa7ba25_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-29 21:56:48,954 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[1] -> Calc[2] -> filtered_transactions[3]: Writer -> filtered_transactions[3]: Committer (1/1) (attempt #0) with attempt id 7be2db6bef65caecd0a090d04fa7ba25_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 6bce14e4e18e05b18abb18af469b92b9
2025-10-29 21:56:49,035 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> filtered_transactions[3]: Writer -> filtered_transactions[3]: Committer (1/1) (7be2db6bef65caecd0a090d04fa7ba25_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-29 21:56:49,153 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[1] registering reader for parallel task 0 (#0) @ localhost
2025-10-29 21:56:49,153 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-29 21:56:49,157 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> filtered_transactions[3]: Writer -> filtered_transactions[3]: Committer (1/1) (7be2db6bef65caecd0a090d04fa7ba25_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-29 22:01:48,724 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node -1 disconnected.
2025-10-29 22:02:16,961 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.filtered_transactions' (f3b0f80c3e88861297869313971f3084).
2025-10-29 22:02:16,962 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.filtered_transactions' (f3b0f80c3e88861297869313971f3084).
2025-10-29 22:02:16,962 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job f3b0f80c3e88861297869313971f3084 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-29 22:02:16,966 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_4 .
2025-10-29 22:02:16,966 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.filtered_transactions' (f3b0f80c3e88861297869313971f3084).
2025-10-29 22:02:16,968 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.filtered_transactions (f3b0f80c3e88861297869313971f3084).
2025-10-29 22:02:16,968 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 319cfb8294f19606b01da865ef87dd48 for job f3b0f80c3e88861297869313971f3084.
2025-10-29 22:02:16,969 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.filtered_transactions (f3b0f80c3e88861297869313971f3084).
2025-10-29 22:02:16,969 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-29 22:02:16,973 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: transactions[4] -> Calc[5] -> filtered_transactions[6]: Writer -> filtered_transactions[6]: Committer exceeded the 80 characters length limit and was truncated.
2025-10-29 22:02:16,973 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-29 22:02:16,973 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@60d0f016
2025-10-29 22:02:16,973 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-29 22:02:16,973 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-29 22:02:16,977 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-29 22:02:16,977 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@7ce9722f for insert-into_default_catalog.default_database.filtered_transactions (f3b0f80c3e88861297869313971f3084).
2025-10-29 22:02:16,978 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.filtered_transactions' (f3b0f80c3e88861297869313971f3084) under job master id 00000000000000000000000000000000.
2025-10-29 22:02:16,978 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[4].
2025-10-29 22:02:16,978 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-29 22:02:16,978 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.filtered_transactions (f3b0f80c3e88861297869313971f3084) switched from state CREATED to RUNNING.
2025-10-29 22:02:16,978 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[4] -> Calc[5] -> filtered_transactions[6]: Writer -> filtered_transactions[6]: Committer (1/1) (319cfb8294f19606b01da865ef87dd48_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-29 22:02:16,979 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-29 22:02:16,979 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-6127157721103620611-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-29 22:02:16,980 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-29 22:02:16,980 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job f3b0f80c3e88861297869313971f3084.
2025-10-29 22:02:16,980 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job f3b0f80c3e88861297869313971f3084.
2025-10-29 22:02:16,981 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-29 22:02:16,981 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job f3b0f80c3e88861297869313971f3084: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-29 22:02:16,983 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-29 22:02:16,983 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-29 22:02:16,983 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-29 22:02:16,983 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761755536983
2025-10-29 22:02:16,983 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-29 22:02:16,996 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-29 22:02:17,051 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job f3b0f80c3e88861297869313971f3084
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=2, taskHeapMemory=192.000mb (201326588 bytes), taskOffHeapMemory=0 bytes, managedMemory=256.000mb (268435460 bytes), networkMemory=64.000mb (67108866 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-29 22:02:17,051 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 1191858bc7160358757186f510fde611 from localhost:49385-5990f3 for job f3b0f80c3e88861297869313971f3084 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-29 22:02:17,067 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[4] -> Calc[5] -> filtered_transactions[6]: Writer -> filtered_transactions[6]: Committer (1/1) (319cfb8294f19606b01da865ef87dd48_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-29 22:02:17,069 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[4] -> Calc[5] -> filtered_transactions[6]: Writer -> filtered_transactions[6]: Committer (1/1) (attempt #0) with attempt id 319cfb8294f19606b01da865ef87dd48_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 1191858bc7160358757186f510fde611
2025-10-29 22:02:17,110 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[4] -> Calc[5] -> filtered_transactions[6]: Writer -> filtered_transactions[6]: Committer (1/1) (319cfb8294f19606b01da865ef87dd48_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-29 22:02:17,152 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[4] registering reader for parallel task 0 (#0) @ localhost
2025-10-29 22:02:17,152 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-29 22:02:17,153 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[4] -> Calc[5] -> filtered_transactions[6]: Writer -> filtered_transactions[6]: Committer (1/1) (319cfb8294f19606b01da865ef87dd48_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-29 22:07:17,000 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node -1 disconnected.
2025-10-29 22:08:54,809 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:54,809 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:54,809 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:54,914 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:54,914 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:54,914 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:54,915 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:54,915 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:54,915 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:55,016 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:55,016 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:55,016 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:55,016 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:55,017 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:55,017 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:55,218 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:55,218 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:55,219 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:55,219 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:55,220 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:55,220 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:55,624 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:55,624 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:55,725 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:55,725 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:55,725 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:55,726 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:56,332 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:56,333 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:56,435 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:56,435 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:56,636 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:56,637 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:57,344 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:57,345 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:57,547 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:57,547 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:57,850 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:57,852 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:58,701 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:58,701 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:58,702 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:58,802 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:58,802 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:58,803 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:58,803 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:58,804 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:58,804 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:58,904 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:58,904 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:59,007 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:59,007 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:59,007 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:59,007 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:59,108 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:59,108 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:59,210 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:59,211 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:59,211 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:59,211 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:59,515 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:59,515 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:59,616 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:59,617 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:08:59,617 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:08:59,617 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:00,326 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:00,326 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:00,427 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:00,428 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:00,528 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:00,529 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:01,244 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:01,245 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:01,339 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:01,340 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:01,641 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:01,642 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:02,155 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:02,156 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:02,352 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:02,352 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:02,552 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:02,552 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:03,268 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:03,269 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:03,465 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:03,465 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:03,565 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:03,565 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:04,380 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:04,381 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:04,577 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:04,577 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:04,677 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:04,677 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:05,393 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:05,393 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:05,488 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:05,488 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:05,587 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:05,588 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:06,601 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:06,601 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:06,606 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:06,606 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:06,698 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:06,699 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:07,716 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:07,717 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:07,812 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:07,812 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:09:07,912 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-29 22:09:07,912 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-10-29 22:58:11,364 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.filter_alerts' (2f68e4b182d8b44ad089c53e12e56e96).
2025-10-29 22:58:11,376 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.filter_alerts' (2f68e4b182d8b44ad089c53e12e56e96).
2025-10-29 22:58:11,381 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 2f68e4b182d8b44ad089c53e12e56e96 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-29 22:58:11,414 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_5 .
2025-10-29 22:58:11,417 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.filter_alerts' (2f68e4b182d8b44ad089c53e12e56e96).
2025-10-29 22:58:11,425 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.filter_alerts (2f68e4b182d8b44ad089c53e12e56e96).
2025-10-29 22:58:11,433 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 6081fc4cbc82cc3d2ecc476f957cf5be for job 2f68e4b182d8b44ad089c53e12e56e96.
2025-10-29 22:58:11,435 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.filter_alerts (2f68e4b182d8b44ad089c53e12e56e96).
2025-10-29 22:58:11,436 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-29 22:58:11,452 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: transactions[7] -> Calc[8] -> filter_alerts[9]: Writer -> filter_alerts[9]: Committer exceeded the 80 characters length limit and was truncated.
2025-10-29 22:58:11,454 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-29 22:58:11,455 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@43c8a1bb
2025-10-29 22:58:11,455 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-29 22:58:11,455 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-29 22:58:11,461 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-29 22:58:11,461 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@7f19e15e for insert-into_default_catalog.default_database.filter_alerts (2f68e4b182d8b44ad089c53e12e56e96).
2025-10-29 22:58:11,463 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.filter_alerts' (2f68e4b182d8b44ad089c53e12e56e96) under job master id 00000000000000000000000000000000.
2025-10-29 22:58:11,464 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[7].
2025-10-29 22:58:11,464 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-29 22:58:11,464 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.filter_alerts (2f68e4b182d8b44ad089c53e12e56e96) switched from state CREATED to RUNNING.
2025-10-29 22:58:11,464 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[7] -> Calc[8] -> filter_alerts[9]: Writer -> filter_alerts[9]: Committer (1/1) (6081fc4cbc82cc3d2ecc476f957cf5be_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-29 22:58:11,466 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-29 22:58:11,467 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-8136707445529912723-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-29 22:58:11,473 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-29 22:58:11,475 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job 2f68e4b182d8b44ad089c53e12e56e96.
2025-10-29 22:58:11,476 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job 2f68e4b182d8b44ad089c53e12e56e96.
2025-10-29 22:58:11,477 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-29 22:58:11,477 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-29 22:58:11,477 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-29 22:58:11,477 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761758891477
2025-10-29 22:58:11,478 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-29 22:58:11,478 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-29 22:58:11,478 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 2f68e4b182d8b44ad089c53e12e56e96: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-29 22:58:11,507 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-29 22:58:11,543 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 2f68e4b182d8b44ad089c53e12e56e96
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-29 22:58:11,544 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot aa7ba14640f7423063594005529ec97f from localhost:49385-5990f3 for job 2f68e4b182d8b44ad089c53e12e56e96 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-29 22:58:11,924 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[7] -> Calc[8] -> filter_alerts[9]: Writer -> filter_alerts[9]: Committer (1/1) (6081fc4cbc82cc3d2ecc476f957cf5be_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-29 22:58:11,929 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[7] -> Calc[8] -> filter_alerts[9]: Writer -> filter_alerts[9]: Committer (1/1) (attempt #0) with attempt id 6081fc4cbc82cc3d2ecc476f957cf5be_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id aa7ba14640f7423063594005529ec97f
2025-10-29 22:58:12,111 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[7] -> Calc[8] -> filter_alerts[9]: Writer -> filter_alerts[9]: Committer (1/1) (6081fc4cbc82cc3d2ecc476f957cf5be_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-29 22:58:12,312 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[7] registering reader for parallel task 0 (#0) @ localhost
2025-10-29 22:58:12,312 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-29 22:58:12,315 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[7] -> Calc[8] -> filter_alerts[9]: Writer -> filter_alerts[9]: Committer (1/1) (6081fc4cbc82cc3d2ecc476f957cf5be_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-29 23:09:46,529 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-8136707445529912723-enumerator-admin-client] Node -1 disconnected.
2025-10-30 10:47:14,053 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-30 20:13:07,014 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-8136707445529912723-enumerator-admin-client] Node 1 disconnected.
2025-10-31 19:10:37,445 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--8706818374987702430-enumerator-admin-client] Node 1 disconnected.
2025-10-31 19:11:31,445 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-5159150177618345690-enumerator-admin-client] Node 1 disconnected.
2025-10-31 19:13:45,886 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (8b4bc6153b304bdf0a089888153beef3).
2025-10-31 19:13:45,888 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (8b4bc6153b304bdf0a089888153beef3).
2025-10-31 19:13:45,892 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 8b4bc6153b304bdf0a089888153beef3 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:13:45,926 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_6 .
2025-10-31 19:13:45,927 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (8b4bc6153b304bdf0a089888153beef3).
2025-10-31 19:13:45,932 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (8b4bc6153b304bdf0a089888153beef3).
2025-10-31 19:13:45,943 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph ffb80b92a562588fec231348b0515069 for job 8b4bc6153b304bdf0a089888153beef3.
2025-10-31 19:13:45,945 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (8b4bc6153b304bdf0a089888153beef3).
2025-10-31 19:13:45,945 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:13:45,990 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:13:45,991 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@9692a30
2025-10-31 19:13:45,991 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:13:45,991 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:13:45,998 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:13:45,998 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@b98a5fd for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (8b4bc6153b304bdf0a089888153beef3).
2025-10-31 19:13:45,999 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (8b4bc6153b304bdf0a089888153beef3) under job master id 00000000000000000000000000000000.
2025-10-31 19:13:46,000 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[12].
2025-10-31 19:13:46,000 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:13:46,000 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (8b4bc6153b304bdf0a089888153beef3) switched from state CREATED to RUNNING.
2025-10-31 19:13:46,000 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[12] -> Sink: Collect table sink (1/1) (ffb80b92a562588fec231348b0515069_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:13:46,002 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:13:46,003 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-6325290707235089334-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:13:46,009 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:13:46,009 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job 8b4bc6153b304bdf0a089888153beef3.
2025-10-31 19:13:46,009 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job 8b4bc6153b304bdf0a089888153beef3.
2025-10-31 19:13:46,010 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:13:46,010 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:13:46,010 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:13:46,010 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761918226010
2025-10-31 19:13:46,010 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:13:46,011 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:13:46,010 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 8b4bc6153b304bdf0a089888153beef3: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:13:46,026 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-31 19:13:46,069 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 8b4bc6153b304bdf0a089888153beef3
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=0, taskHeapMemory=2 bytes, taskOffHeapMemory=0 bytes, managedMemory=0 bytes, networkMemory=2 bytes}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:13:46,073 WARN  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Could not fulfill resource requirements of job 8b4bc6153b304bdf0a089888153beef3.
2025-10-31 19:13:46,075 WARN  org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge [] - Could not acquire the minimum required resources, failing slot requests. Acquired: []. Current slot pool status: Registered TMs: 0, registered slots: 0 free slots: 0
2025-10-31 19:13:46,094 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[12] -> Sink: Collect table sink (1/1) (ffb80b92a562588fec231348b0515069_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to FAILED on [unassigned resource].
org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:13:46,103 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution ffb80b92a562588fec231348b0515069_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-10-31 19:13:46,110 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: transactions[12].
2025-10-31 19:13:46,114 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (8b4bc6153b304bdf0a089888153beef3) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:13:46,123 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (8b4bc6153b304bdf0a089888153beef3) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:13:46,124 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 8b4bc6153b304bdf0a089888153beef3.
2025-10-31 19:13:46,134 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 8b4bc6153b304bdf0a089888153beef3
2025-10-31 19:13:46,142 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 8b4bc6153b304bdf0a089888153beef3 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51)
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130)
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969)
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162)
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399)
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226)
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636)
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:13:46,202 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (8b4bc6153b304bdf0a089888153beef3).
2025-10-31 19:13:46,207 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions[12].
2025-10-31 19:13:46,209 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-6325290707235089334-enumerator-admin-client unregistered
2025-10-31 19:13:46,210 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:13:46,214 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:13:46,214 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:13:46,214 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:13:46,214 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:13:46,215 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (8b4bc6153b304bdf0a089888153beef3).
2025-10-31 19:13:46,216 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job 8b4bc6153b304bdf0a089888153beef3 from the resource manager.
2025-10-31 19:13:46,216 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions[12] closed.
2025-10-31 19:13:54,601 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (c05ceb28543e4c4e2f4ff31ce8904a5b).
2025-10-31 19:13:54,601 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (c05ceb28543e4c4e2f4ff31ce8904a5b).
2025-10-31 19:13:54,601 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job c05ceb28543e4c4e2f4ff31ce8904a5b was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:13:54,603 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_7 .
2025-10-31 19:13:54,603 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (c05ceb28543e4c4e2f4ff31ce8904a5b).
2025-10-31 19:13:54,604 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (c05ceb28543e4c4e2f4ff31ce8904a5b).
2025-10-31 19:13:54,605 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph a16f13033efcfe0f456da9cc6b73a25d for job c05ceb28543e4c4e2f4ff31ce8904a5b.
2025-10-31 19:13:54,605 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (c05ceb28543e4c4e2f4ff31ce8904a5b).
2025-10-31 19:13:54,605 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:13:54,608 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:13:54,608 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7b87907e
2025-10-31 19:13:54,608 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:13:54,608 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:13:54,613 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:13:54,613 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@410c4e84 for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (c05ceb28543e4c4e2f4ff31ce8904a5b).
2025-10-31 19:13:54,613 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (c05ceb28543e4c4e2f4ff31ce8904a5b) under job master id 00000000000000000000000000000000.
2025-10-31 19:13:54,613 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[14].
2025-10-31 19:13:54,613 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:13:54,614 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (c05ceb28543e4c4e2f4ff31ce8904a5b) switched from state CREATED to RUNNING.
2025-10-31 19:13:54,614 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[14] -> Sink: Collect table sink (1/1) (a16f13033efcfe0f456da9cc6b73a25d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:13:54,614 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:13:54,614 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:13:54,614 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--7502432789184964586-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:13:54,615 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_7 for job c05ceb28543e4c4e2f4ff31ce8904a5b.
2025-10-31 19:13:54,615 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_7 for job c05ceb28543e4c4e2f4ff31ce8904a5b.
2025-10-31 19:13:54,616 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:13:54,616 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job c05ceb28543e4c4e2f4ff31ce8904a5b: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:13:54,619 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:13:54,619 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:13:54,619 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:13:54,619 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761918234619
2025-10-31 19:13:54,619 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:13:54,626 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-31 19:13:54,682 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job c05ceb28543e4c4e2f4ff31ce8904a5b
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=0, taskHeapMemory=2 bytes, taskOffHeapMemory=0 bytes, managedMemory=0 bytes, networkMemory=2 bytes}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:13:54,682 WARN  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Could not fulfill resource requirements of job c05ceb28543e4c4e2f4ff31ce8904a5b.
2025-10-31 19:13:54,683 WARN  org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge [] - Could not acquire the minimum required resources, failing slot requests. Acquired: []. Current slot pool status: Registered TMs: 0, registered slots: 0 free slots: 0
2025-10-31 19:13:54,686 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[14] -> Sink: Collect table sink (1/1) (a16f13033efcfe0f456da9cc6b73a25d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to FAILED on [unassigned resource].
org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:13:54,688 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution a16f13033efcfe0f456da9cc6b73a25d_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-10-31 19:13:54,690 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: transactions[14].
2025-10-31 19:13:54,690 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (c05ceb28543e4c4e2f4ff31ce8904a5b) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:13:54,694 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (c05ceb28543e4c4e2f4ff31ce8904a5b) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:13:54,695 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job c05ceb28543e4c4e2f4ff31ce8904a5b.
2025-10-31 19:13:54,698 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job c05ceb28543e4c4e2f4ff31ce8904a5b
2025-10-31 19:13:54,699 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job c05ceb28543e4c4e2f4ff31ce8904a5b reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51)
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130)
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969)
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162)
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399)
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226)
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636)
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:13:54,702 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (c05ceb28543e4c4e2f4ff31ce8904a5b).
2025-10-31 19:13:54,702 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:13:54,702 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:13:54,702 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (c05ceb28543e4c4e2f4ff31ce8904a5b).
2025-10-31 19:13:54,703 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_7 for job c05ceb28543e4c4e2f4ff31ce8904a5b from the resource manager.
2025-10-31 19:13:54,703 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions[14].
2025-10-31 19:13:54,703 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--7502432789184964586-enumerator-admin-client unregistered
2025-10-31 19:13:54,706 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:13:54,707 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:13:54,707 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:13:54,707 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions[14] closed.
2025-10-31 19:15:56,749 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.filter_alerts (2f68e4b182d8b44ad089c53e12e56e96) switched from state RUNNING to CANCELLING.
2025-10-31 19:15:56,752 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[7] -> Calc[8] -> filter_alerts[9]: Writer -> filter_alerts[9]: Committer (1/1) (6081fc4cbc82cc3d2ecc476f957cf5be_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:15:57,335 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[7] -> Calc[8] -> filter_alerts[9]: Writer -> filter_alerts[9]: Committer (1/1) (6081fc4cbc82cc3d2ecc476f957cf5be_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:15:57,339 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 2f68e4b182d8b44ad089c53e12e56e96
2025-10-31 19:15:57,339 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.filter_alerts (2f68e4b182d8b44ad089c53e12e56e96) switched from state CANCELLING to CANCELED.
2025-10-31 19:15:57,339 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 2f68e4b182d8b44ad089c53e12e56e96.
2025-10-31 19:15:57,340 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 2f68e4b182d8b44ad089c53e12e56e96 reached terminal state CANCELED.
2025-10-31 19:15:57,345 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'insert-into_default_catalog.default_database.filter_alerts' (2f68e4b182d8b44ad089c53e12e56e96).
2025-10-31 19:15:57,346 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:15:57,346 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions[7].
2025-10-31 19:15:57,347 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [aa7ba14640f7423063594005529ec97f].
2025-10-31 19:15:57,347 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-8136707445529912723-enumerator-admin-client unregistered
2025-10-31 19:15:57,347 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'insert-into_default_catalog.default_database.filter_alerts' (2f68e4b182d8b44ad089c53e12e56e96).
2025-10-31 19:15:57,348 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'insert-into_default_catalog.default_database.filter_alerts' (2f68e4b182d8b44ad089c53e12e56e96).
2025-10-31 19:15:57,348 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job 2f68e4b182d8b44ad089c53e12e56e96 from the resource manager.
2025-10-31 19:15:57,350 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:15:57,350 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:15:57,350 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:15:57,350 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions[7] closed.
2025-10-31 19:15:57,363 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot aa7ba14640f7423063594005529ec97f.
2025-10-31 19:16:05,891 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (6fa8f1b366eabd555412581d9e872573).
2025-10-31 19:16:05,892 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (6fa8f1b366eabd555412581d9e872573).
2025-10-31 19:16:05,892 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 6fa8f1b366eabd555412581d9e872573 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:16:05,894 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_8 .
2025-10-31 19:16:05,895 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (6fa8f1b366eabd555412581d9e872573).
2025-10-31 19:16:05,896 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (6fa8f1b366eabd555412581d9e872573).
2025-10-31 19:16:05,897 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 2aacb1adaee593614034f6d90c347064 for job 6fa8f1b366eabd555412581d9e872573.
2025-10-31 19:16:05,897 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (6fa8f1b366eabd555412581d9e872573).
2025-10-31 19:16:05,897 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:16:05,901 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:16:05,901 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2d411adf
2025-10-31 19:16:05,901 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:16:05,901 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:16:05,905 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:16:05,905 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@55c4430a for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (6fa8f1b366eabd555412581d9e872573).
2025-10-31 19:16:05,905 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (6fa8f1b366eabd555412581d9e872573) under job master id 00000000000000000000000000000000.
2025-10-31 19:16:05,906 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[20].
2025-10-31 19:16:05,906 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:16:05,906 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (6fa8f1b366eabd555412581d9e872573) switched from state CREATED to RUNNING.
2025-10-31 19:16:05,906 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[20] -> Sink: Collect table sink (1/1) (2aacb1adaee593614034f6d90c347064_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:16:05,906 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:16:05,906 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-3171718255976465801-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:16:05,907 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:16:05,907 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_8 for job 6fa8f1b366eabd555412581d9e872573.
2025-10-31 19:16:05,907 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_8 for job 6fa8f1b366eabd555412581d9e872573.
2025-10-31 19:16:05,908 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:16:05,908 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 6fa8f1b366eabd555412581d9e872573: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:16:05,911 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:16:05,911 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:16:05,911 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:16:05,911 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761918365911
2025-10-31 19:16:05,911 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:16:05,926 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-31 19:16:05,972 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 6fa8f1b366eabd555412581d9e872573
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:16:05,972 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 5f7d990c05b17a79e24b26e56320dffd from localhost:49385-5990f3 for job 6fa8f1b366eabd555412581d9e872573 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:16:06,022 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[20] -> Sink: Collect table sink (1/1) (2aacb1adaee593614034f6d90c347064_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:16:06,024 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[20] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 2aacb1adaee593614034f6d90c347064_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 5f7d990c05b17a79e24b26e56320dffd
2025-10-31 19:16:06,076 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[20] -> Sink: Collect table sink (1/1) (2aacb1adaee593614034f6d90c347064_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:16:06,173 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:54087
2025-10-31 19:16:06,174 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[20] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:16:06,174 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:16:06,175 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[20] -> Sink: Collect table sink (1/1) (2aacb1adaee593614034f6d90c347064_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:16:06,182 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:17:35,197 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (6fa8f1b366eabd555412581d9e872573) switched from state RUNNING to CANCELLING.
2025-10-31 19:17:35,199 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[20] -> Sink: Collect table sink (1/1) (2aacb1adaee593614034f6d90c347064_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:17:35,302 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-10-31 19:17:35,413 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:17:35,521 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:17:35,625 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:17:35,737 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:17:35,760 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[20] -> Sink: Collect table sink (1/1) (2aacb1adaee593614034f6d90c347064_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:17:35,760 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions` (6fa8f1b366eabd555412581d9e872573) switched from state CANCELLING to CANCELED.
2025-10-31 19:17:35,760 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 6fa8f1b366eabd555412581d9e872573.
2025-10-31 19:17:35,761 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 6fa8f1b366eabd555412581d9e872573
2025-10-31 19:17:35,762 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 6fa8f1b366eabd555412581d9e872573 reached terminal state CANCELED.
2025-10-31 19:17:35,764 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (6fa8f1b366eabd555412581d9e872573).
2025-10-31 19:17:35,765 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:17:35,765 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:17:35,765 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [5f7d990c05b17a79e24b26e56320dffd].
2025-10-31 19:17:35,765 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (6fa8f1b366eabd555412581d9e872573).
2025-10-31 19:17:35,765 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions[20].
2025-10-31 19:17:35,765 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`' (6fa8f1b366eabd555412581d9e872573).
2025-10-31 19:17:35,765 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_8 for job 6fa8f1b366eabd555412581d9e872573 from the resource manager.
2025-10-31 19:17:35,766 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-3171718255976465801-enumerator-admin-client unregistered
2025-10-31 19:17:35,768 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:17:35,768 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:17:35,768 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:17:35,769 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions[20] closed.
2025-10-31 19:17:35,769 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 5f7d990c05b17a79e24b26e56320dffd.
2025-10-31 19:20:57,960 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fc094cd2196df37718db12207b344942).
2025-10-31 19:20:57,961 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fc094cd2196df37718db12207b344942).
2025-10-31 19:20:57,964 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job fc094cd2196df37718db12207b344942 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:20:57,969 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_9 .
2025-10-31 19:20:57,969 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fc094cd2196df37718db12207b344942).
2025-10-31 19:20:57,971 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fc094cd2196df37718db12207b344942).
2025-10-31 19:20:57,972 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 45cb4589f5750e4106b919d507ddc67a for job fc094cd2196df37718db12207b344942.
2025-10-31 19:20:57,972 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fc094cd2196df37718db12207b344942).
2025-10-31 19:20:57,972 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:20:57,978 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:20:57,978 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@4c4bf2b3
2025-10-31 19:20:57,978 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:20:57,978 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:20:57,978 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:20:57,978 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@602b6137 for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fc094cd2196df37718db12207b344942).
2025-10-31 19:20:57,979 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fc094cd2196df37718db12207b344942) under job master id 00000000000000000000000000000000.
2025-10-31 19:20:57,979 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[24].
2025-10-31 19:20:57,979 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:20:57,979 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fc094cd2196df37718db12207b344942) switched from state CREATED to RUNNING.
2025-10-31 19:20:57,979 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[24] -> Calc[25] -> Sink: Collect table sink (1/1) (45cb4589f5750e4106b919d507ddc67a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:20:57,979 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:20:57,979 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--3278501250782824845-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:20:57,980 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:20:57,980 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_9 for job fc094cd2196df37718db12207b344942.
2025-10-31 19:20:57,981 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:20:57,981 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:20:57,981 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:20:57,981 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761918657981
2025-10-31 19:20:57,981 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:20:57,981 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_9 for job fc094cd2196df37718db12207b344942.
2025-10-31 19:20:57,982 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:20:57,982 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fc094cd2196df37718db12207b344942: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:20:57,989 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-31 19:20:58,052 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fc094cd2196df37718db12207b344942
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:20:58,052 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 75ae2a6b94401bcfa5f32269119b9736 from localhost:49385-5990f3 for job fc094cd2196df37718db12207b344942 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:20:58,083 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[24] -> Calc[25] -> Sink: Collect table sink (1/1) (45cb4589f5750e4106b919d507ddc67a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:20:58,085 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[24] -> Calc[25] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 45cb4589f5750e4106b919d507ddc67a_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 75ae2a6b94401bcfa5f32269119b9736
2025-10-31 19:20:58,109 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[24] -> Calc[25] -> Sink: Collect table sink (1/1) (45cb4589f5750e4106b919d507ddc67a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:20:58,166 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:56655
2025-10-31 19:20:58,166 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[24] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:20:58,166 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:20:58,166 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[24] -> Calc[25] -> Sink: Collect table sink (1/1) (45cb4589f5750e4106b919d507ddc67a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:20:58,249 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:21:08,928 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fc094cd2196df37718db12207b344942) switched from state RUNNING to CANCELLING.
2025-10-31 19:21:08,929 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[24] -> Calc[25] -> Sink: Collect table sink (1/1) (45cb4589f5750e4106b919d507ddc67a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:21:09,038 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-10-31 19:21:09,108 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[24] -> Calc[25] -> Sink: Collect table sink (1/1) (45cb4589f5750e4106b919d507ddc67a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:21:09,109 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fc094cd2196df37718db12207b344942) switched from state CANCELLING to CANCELED.
2025-10-31 19:21:09,109 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job fc094cd2196df37718db12207b344942.
2025-10-31 19:21:09,109 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fc094cd2196df37718db12207b344942
2025-10-31 19:21:09,110 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job fc094cd2196df37718db12207b344942 reached terminal state CANCELED.
2025-10-31 19:21:09,112 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fc094cd2196df37718db12207b344942).
2025-10-31 19:21:09,113 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:21:09,113 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:21:09,113 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions[24].
2025-10-31 19:21:09,113 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [75ae2a6b94401bcfa5f32269119b9736].
2025-10-31 19:21:09,113 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fc094cd2196df37718db12207b344942).
2025-10-31 19:21:09,113 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fc094cd2196df37718db12207b344942).
2025-10-31 19:21:09,113 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_9 for job fc094cd2196df37718db12207b344942 from the resource manager.
2025-10-31 19:21:09,114 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--3278501250782824845-enumerator-admin-client unregistered
2025-10-31 19:21:09,114 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:21:09,115 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:21:09,115 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:21:09,115 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 75ae2a6b94401bcfa5f32269119b9736.
2025-10-31 19:21:09,115 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions[24] closed.
2025-10-31 19:21:17,556 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fd621b747d5be47bc9cc2daaa90d4bb6).
2025-10-31 19:21:17,556 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fd621b747d5be47bc9cc2daaa90d4bb6).
2025-10-31 19:21:17,557 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job fd621b747d5be47bc9cc2daaa90d4bb6 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:21:17,558 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_10 .
2025-10-31 19:21:17,559 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fd621b747d5be47bc9cc2daaa90d4bb6).
2025-10-31 19:21:17,559 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fd621b747d5be47bc9cc2daaa90d4bb6).
2025-10-31 19:21:17,560 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph b86204ef8a865efbc522db28f3533f50 for job fd621b747d5be47bc9cc2daaa90d4bb6.
2025-10-31 19:21:17,560 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fd621b747d5be47bc9cc2daaa90d4bb6).
2025-10-31 19:21:17,560 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:21:17,562 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7228c870
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@4902e571 for SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fd621b747d5be47bc9cc2daaa90d4bb6).
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fd621b747d5be47bc9cc2daaa90d4bb6) under job master id 00000000000000000000000000000000.
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[27].
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fd621b747d5be47bc9cc2daaa90d4bb6) switched from state CREATED to RUNNING.
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (b86204ef8a865efbc522db28f3533f50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:21:17,563 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:21:17,564 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-367557566483648412-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:21:17,564 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:21:17,564 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_10 for job fd621b747d5be47bc9cc2daaa90d4bb6.
2025-10-31 19:21:17,565 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_10 for job fd621b747d5be47bc9cc2daaa90d4bb6.
2025-10-31 19:21:17,565 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:21:17,565 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:21:17,565 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:21:17,565 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761918677565
2025-10-31 19:21:17,565 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:21:17,565 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:21:17,565 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fd621b747d5be47bc9cc2daaa90d4bb6: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:21:17,569 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-31 19:21:17,630 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fd621b747d5be47bc9cc2daaa90d4bb6
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:21:17,630 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot b8a05000381f4a98a4454ff0ed019e44 from localhost:49385-5990f3 for job fd621b747d5be47bc9cc2daaa90d4bb6 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:21:17,639 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (b86204ef8a865efbc522db28f3533f50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:21:17,640 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id b86204ef8a865efbc522db28f3533f50_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id b8a05000381f4a98a4454ff0ed019e44
2025-10-31 19:21:17,651 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (b86204ef8a865efbc522db28f3533f50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:21:17,668 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:62213
2025-10-31 19:21:17,669 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[27] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:21:17,669 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:21:17,669 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (b86204ef8a865efbc522db28f3533f50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:21:17,723 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:22:40,268 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fd621b747d5be47bc9cc2daaa90d4bb6) switched from state RUNNING to CANCELLING.
2025-10-31 19:22:40,269 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (b86204ef8a865efbc522db28f3533f50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:22:40,379 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-10-31 19:22:40,482 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (b86204ef8a865efbc522db28f3533f50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:22:40,483 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000 (fd621b747d5be47bc9cc2daaa90d4bb6) switched from state CANCELLING to CANCELED.
2025-10-31 19:22:40,483 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job fd621b747d5be47bc9cc2daaa90d4bb6.
2025-10-31 19:22:40,483 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fd621b747d5be47bc9cc2daaa90d4bb6
2025-10-31 19:22:40,484 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:22:40,485 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job fd621b747d5be47bc9cc2daaa90d4bb6 reached terminal state CANCELED.
2025-10-31 19:22:40,486 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fd621b747d5be47bc9cc2daaa90d4bb6).
2025-10-31 19:22:40,487 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:22:40,487 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:22:40,487 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [b8a05000381f4a98a4454ff0ed019e44].
2025-10-31 19:22:40,487 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions[27].
2025-10-31 19:22:40,487 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fd621b747d5be47bc9cc2daaa90d4bb6).
2025-10-31 19:22:40,488 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions`.`TransactionID`, `transactions`.`AccountID`, `transactions`.`TransactionAmount`, `transactions`.`TransactionDate`, `transactions`.`TransactionType`, `transactions`.`Location`, `transactions`.`DeviceID`, `transactions`.`IP Address`, `transactions`.`MerchantID`, `transactions`.`Channel`, `transactions`.`CustomerAge`, `transactions`.`CustomerOccupation`, `transactions`.`TransactionDuration`, `transactions`.`LoginAttempts`, `transactions`.`AccountBalance`, `transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`transactions` AS `transactions`
WHERE `transactions`.`TransactionAmount` > 1000' (fd621b747d5be47bc9cc2daaa90d4bb6).
2025-10-31 19:22:40,488 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_10 for job fd621b747d5be47bc9cc2daaa90d4bb6 from the resource manager.
2025-10-31 19:22:40,489 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-367557566483648412-enumerator-admin-client unregistered
2025-10-31 19:22:40,493 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:22:40,493 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:22:40,493 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:22:40,493 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot b8a05000381f4a98a4454ff0ed019e44.
2025-10-31 19:22:40,494 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions[27] closed.
2025-10-31 19:25:50,961 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (04544edcef158bed083143bbfc58c81d).
2025-10-31 19:25:50,962 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (04544edcef158bed083143bbfc58c81d).
2025-10-31 19:25:50,963 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 04544edcef158bed083143bbfc58c81d was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:25:50,967 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_11 .
2025-10-31 19:25:50,967 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (04544edcef158bed083143bbfc58c81d).
2025-10-31 19:25:50,968 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (04544edcef158bed083143bbfc58c81d).
2025-10-31 19:25:50,969 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 2f8c281c890c1bf2ca52b1bf8c285bcb for job 04544edcef158bed083143bbfc58c81d.
2025-10-31 19:25:50,969 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (04544edcef158bed083143bbfc58c81d).
2025-10-31 19:25:50,969 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:25:50,973 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:25:50,973 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@64881c7c
2025-10-31 19:25:50,973 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:25:50,973 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:25:50,977 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:25:50,977 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@4c56450b for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (04544edcef158bed083143bbfc58c81d).
2025-10-31 19:25:50,978 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (04544edcef158bed083143bbfc58c81d) under job master id 00000000000000000000000000000000.
2025-10-31 19:25:50,978 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions2[30].
2025-10-31 19:25:50,978 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:25:50,978 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (04544edcef158bed083143bbfc58c81d) switched from state CREATED to RUNNING.
2025-10-31 19:25:50,978 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[30] -> Sink: Collect table sink (1/1) (2f8c281c890c1bf2ca52b1bf8c285bcb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:25:50,978 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:25:50,978 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-8501751689275247483-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:25:50,979 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:25:50,979 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_11 for job 04544edcef158bed083143bbfc58c81d.
2025-10-31 19:25:50,979 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_11 for job 04544edcef158bed083143bbfc58c81d.
2025-10-31 19:25:50,980 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:25:50,980 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 04544edcef158bed083143bbfc58c81d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:25:50,981 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:25:50,982 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:25:50,982 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:25:50,982 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761918950982
2025-10-31 19:25:50,982 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:25:50,996 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [alerts-0]
2025-10-31 19:25:51,042 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 04544edcef158bed083143bbfc58c81d
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:25:51,042 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot a2a8ab880256558d8f8d80bcda5996f4 from localhost:49385-5990f3 for job 04544edcef158bed083143bbfc58c81d with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:25:51,063 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[30] -> Sink: Collect table sink (1/1) (2f8c281c890c1bf2ca52b1bf8c285bcb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:25:51,065 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions2[30] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 2f8c281c890c1bf2ca52b1bf8c285bcb_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id a2a8ab880256558d8f8d80bcda5996f4
2025-10-31 19:25:51,089 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[30] -> Sink: Collect table sink (1/1) (2f8c281c890c1bf2ca52b1bf8c285bcb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:25:51,097 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:62506
2025-10-31 19:25:51,098 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions2[30] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:25:51,098 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:25:51,099 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[30] -> Sink: Collect table sink (1/1) (2f8c281c890c1bf2ca52b1bf8c285bcb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:25:51,138 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:26:17,562 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (04544edcef158bed083143bbfc58c81d) switched from state RUNNING to CANCELLING.
2025-10-31 19:26:17,564 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[30] -> Sink: Collect table sink (1/1) (2f8c281c890c1bf2ca52b1bf8c285bcb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:26:17,643 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[30] -> Sink: Collect table sink (1/1) (2f8c281c890c1bf2ca52b1bf8c285bcb_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:26:17,645 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (04544edcef158bed083143bbfc58c81d) switched from state CANCELLING to CANCELED.
2025-10-31 19:26:17,645 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 04544edcef158bed083143bbfc58c81d
2025-10-31 19:26:17,645 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 04544edcef158bed083143bbfc58c81d.
2025-10-31 19:26:17,647 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 04544edcef158bed083143bbfc58c81d reached terminal state CANCELED.
2025-10-31 19:26:17,656 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (04544edcef158bed083143bbfc58c81d).
2025-10-31 19:26:17,656 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:26:17,656 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:26:17,657 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [a2a8ab880256558d8f8d80bcda5996f4].
2025-10-31 19:26:17,657 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (04544edcef158bed083143bbfc58c81d).
2025-10-31 19:26:17,657 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (04544edcef158bed083143bbfc58c81d).
2025-10-31 19:26:17,656 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions2[30].
2025-10-31 19:26:17,657 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_11 for job 04544edcef158bed083143bbfc58c81d from the resource manager.
2025-10-31 19:26:17,658 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-8501751689275247483-enumerator-admin-client unregistered
2025-10-31 19:26:17,660 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:26:17,660 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:26:17,660 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:26:17,660 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions2[30] closed.
2025-10-31 19:26:17,660 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot a2a8ab880256558d8f8d80bcda5996f4.
2025-10-31 19:33:17,870 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.transactions3' (8a9e212457525f9c96b11442e31c27ac).
2025-10-31 19:33:17,870 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.transactions3' (8a9e212457525f9c96b11442e31c27ac).
2025-10-31 19:33:17,871 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 8a9e212457525f9c96b11442e31c27ac was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:33:17,875 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_12 .
2025-10-31 19:33:17,875 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.transactions3' (8a9e212457525f9c96b11442e31c27ac).
2025-10-31 19:33:17,876 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.transactions3 (8a9e212457525f9c96b11442e31c27ac).
2025-10-31 19:33:17,877 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 97c522b1f57dfd1cbb73588b325b2a83 for job 8a9e212457525f9c96b11442e31c27ac.
2025-10-31 19:33:17,878 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.transactions3 (8a9e212457525f9c96b11442e31c27ac).
2025-10-31 19:33:17,878 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:33:17,882 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: transactions[32] -> Calc[33] -> transactions3[34]: Writer -> transactions3[34]: Committer exceeded the 80 characters length limit and was truncated.
2025-10-31 19:33:17,882 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:33:17,883 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@4e1a0df1
2025-10-31 19:33:17,883 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:33:17,883 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:33:17,887 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:33:17,887 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@43486dd3 for insert-into_default_catalog.default_database.transactions3 (8a9e212457525f9c96b11442e31c27ac).
2025-10-31 19:33:17,887 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.transactions3' (8a9e212457525f9c96b11442e31c27ac) under job master id 00000000000000000000000000000000.
2025-10-31 19:33:17,888 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions[32].
2025-10-31 19:33:17,888 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:33:17,888 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.transactions3 (8a9e212457525f9c96b11442e31c27ac) switched from state CREATED to RUNNING.
2025-10-31 19:33:17,888 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[32] -> Calc[33] -> transactions3[34]: Writer -> transactions3[34]: Committer (1/1) (97c522b1f57dfd1cbb73588b325b2a83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:33:17,888 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:33:17,889 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-6919266241583439448-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:33:17,889 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:33:17,889 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_12 for job 8a9e212457525f9c96b11442e31c27ac.
2025-10-31 19:33:17,889 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_12 for job 8a9e212457525f9c96b11442e31c27ac.
2025-10-31 19:33:17,890 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:33:17,890 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 8a9e212457525f9c96b11442e31c27ac: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:33:17,893 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:33:17,893 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:33:17,893 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:33:17,893 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761919397893
2025-10-31 19:33:17,894 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:33:17,905 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-31 19:33:17,962 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 8a9e212457525f9c96b11442e31c27ac
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:33:17,962 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot dda87ce59a1038bfb671cacec791828b from localhost:49385-5990f3 for job 8a9e212457525f9c96b11442e31c27ac with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:33:17,977 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[32] -> Calc[33] -> transactions3[34]: Writer -> transactions3[34]: Committer (1/1) (97c522b1f57dfd1cbb73588b325b2a83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:33:17,979 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions[32] -> Calc[33] -> transactions3[34]: Writer -> transactions3[34]: Committer (1/1) (attempt #0) with attempt id 97c522b1f57dfd1cbb73588b325b2a83_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id dda87ce59a1038bfb671cacec791828b
2025-10-31 19:33:18,014 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[32] -> Calc[33] -> transactions3[34]: Writer -> transactions3[34]: Committer (1/1) (97c522b1f57dfd1cbb73588b325b2a83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:33:18,075 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions[32] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:33:18,075 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:33:18,076 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[32] -> Calc[33] -> transactions3[34]: Writer -> transactions3[34]: Committer (1/1) (97c522b1f57dfd1cbb73588b325b2a83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:44:49,723 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (79a3dbb653b3d41a4f27f0a67cc9f9fc).
2025-10-31 19:44:49,726 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (79a3dbb653b3d41a4f27f0a67cc9f9fc).
2025-10-31 19:44:49,729 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 79a3dbb653b3d41a4f27f0a67cc9f9fc was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:44:49,743 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_13 .
2025-10-31 19:44:49,744 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (79a3dbb653b3d41a4f27f0a67cc9f9fc).
2025-10-31 19:44:49,747 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (79a3dbb653b3d41a4f27f0a67cc9f9fc).
2025-10-31 19:44:49,752 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph afcfed34d85c27826db5f3fe39213f47 for job 79a3dbb653b3d41a4f27f0a67cc9f9fc.
2025-10-31 19:44:49,754 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (79a3dbb653b3d41a4f27f0a67cc9f9fc).
2025-10-31 19:44:49,754 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:44:49,763 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:44:49,763 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@58895965
2025-10-31 19:44:49,763 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:44:49,763 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:44:49,766 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:44:49,766 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@5471e435 for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (79a3dbb653b3d41a4f27f0a67cc9f9fc).
2025-10-31 19:44:49,768 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (79a3dbb653b3d41a4f27f0a67cc9f9fc) under job master id 00000000000000000000000000000000.
2025-10-31 19:44:49,768 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions2[35].
2025-10-31 19:44:49,769 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:44:49,770 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (79a3dbb653b3d41a4f27f0a67cc9f9fc) switched from state CREATED to RUNNING.
2025-10-31 19:44:49,770 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[35] -> Calc[36] -> Sink: Collect table sink (1/1) (afcfed34d85c27826db5f3fe39213f47_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:44:49,771 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:44:49,771 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-4709651841533359938-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:44:49,773 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:44:49,774 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_13 for job 79a3dbb653b3d41a4f27f0a67cc9f9fc.
2025-10-31 19:44:49,774 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_13 for job 79a3dbb653b3d41a4f27f0a67cc9f9fc.
2025-10-31 19:44:49,775 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:44:49,775 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 79a3dbb653b3d41a4f27f0a67cc9f9fc: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:44:49,777 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:44:49,777 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:44:49,777 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:44:49,777 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761920089777
2025-10-31 19:44:49,778 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:44:49,791 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [alerts-0]
2025-10-31 19:44:49,845 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 79a3dbb653b3d41a4f27f0a67cc9f9fc
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=0, taskHeapMemory=2 bytes, taskOffHeapMemory=0 bytes, managedMemory=0 bytes, networkMemory=2 bytes}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:44:49,846 WARN  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Could not fulfill resource requirements of job 79a3dbb653b3d41a4f27f0a67cc9f9fc.
2025-10-31 19:44:49,846 WARN  org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge [] - Could not acquire the minimum required resources, failing slot requests. Acquired: []. Current slot pool status: Registered TMs: 0, registered slots: 0 free slots: 0
2025-10-31 19:44:49,850 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[35] -> Calc[36] -> Sink: Collect table sink (1/1) (afcfed34d85c27826db5f3fe39213f47_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to FAILED on [unassigned resource].
org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:44:49,854 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution afcfed34d85c27826db5f3fe39213f47_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-10-31 19:44:49,856 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: transactions2[35].
2025-10-31 19:44:49,856 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (79a3dbb653b3d41a4f27f0a67cc9f9fc) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:44:49,863 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (79a3dbb653b3d41a4f27f0a67cc9f9fc) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:44:49,863 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 79a3dbb653b3d41a4f27f0a67cc9f9fc.
2025-10-31 19:44:49,866 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 79a3dbb653b3d41a4f27f0a67cc9f9fc
2025-10-31 19:44:49,867 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 79a3dbb653b3d41a4f27f0a67cc9f9fc reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51)
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130)
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969)
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162)
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399)
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226)
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636)
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 19:44:49,877 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (79a3dbb653b3d41a4f27f0a67cc9f9fc).
2025-10-31 19:44:49,877 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:44:49,878 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:44:49,878 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (79a3dbb653b3d41a4f27f0a67cc9f9fc).
2025-10-31 19:44:49,878 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_13 for job 79a3dbb653b3d41a4f27f0a67cc9f9fc from the resource manager.
2025-10-31 19:44:49,878 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions2[35].
2025-10-31 19:44:49,879 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-4709651841533359938-enumerator-admin-client unregistered
2025-10-31 19:44:49,882 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:44:49,882 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:44:49,882 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:44:49,882 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions2[35] closed.
2025-10-31 19:45:16,730 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (6ea2503ef4a8a3467dce3baae050fe41) switched from state RUNNING to CANCELLING.
2025-10-31 19:45:16,733 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (0fa840a28117ec86c3f68e5c65e59029_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:45:17,182 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> alerts[3]: Writer -> alerts[3]: Committer (1/1) (0fa840a28117ec86c3f68e5c65e59029_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:45:17,185 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.alerts (6ea2503ef4a8a3467dce3baae050fe41) switched from state CANCELLING to CANCELED.
2025-10-31 19:45:17,186 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 6ea2503ef4a8a3467dce3baae050fe41.
2025-10-31 19:45:17,186 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 6ea2503ef4a8a3467dce3baae050fe41
2025-10-31 19:45:17,188 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 6ea2503ef4a8a3467dce3baae050fe41 reached terminal state CANCELED.
2025-10-31 19:45:17,195 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'insert-into_default_catalog.default_database.alerts' (6ea2503ef4a8a3467dce3baae050fe41).
2025-10-31 19:45:17,196 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:45:17,196 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [b3f572ead95110f8d0c8850c7d7c14df].
2025-10-31 19:45:17,196 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions[1].
2025-10-31 19:45:17,197 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'insert-into_default_catalog.default_database.alerts' (6ea2503ef4a8a3467dce3baae050fe41).
2025-10-31 19:45:17,197 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'insert-into_default_catalog.default_database.alerts' (6ea2503ef4a8a3467dce3baae050fe41).
2025-10-31 19:45:17,197 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 6ea2503ef4a8a3467dce3baae050fe41 from the resource manager.
2025-10-31 19:45:17,198 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--8706818374987702430-enumerator-admin-client unregistered
2025-10-31 19:45:17,201 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:45:17,201 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:45:17,201 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:45:17,202 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions[1] closed.
2025-10-31 19:45:17,204 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot b3f572ead95110f8d0c8850c7d7c14df.
2025-10-31 19:45:22,275 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6919266241583439448-enumerator-admin-client] Node -1 disconnected.
2025-10-31 19:45:23,266 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (a5daedd0b794f13f6074f63d3b32dd87).
2025-10-31 19:45:23,266 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (a5daedd0b794f13f6074f63d3b32dd87).
2025-10-31 19:45:23,267 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job a5daedd0b794f13f6074f63d3b32dd87 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:45:23,269 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_14 .
2025-10-31 19:45:23,269 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (a5daedd0b794f13f6074f63d3b32dd87).
2025-10-31 19:45:23,270 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (a5daedd0b794f13f6074f63d3b32dd87).
2025-10-31 19:45:23,271 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 385f5e904b4648c295ddc7937c74fa96 for job a5daedd0b794f13f6074f63d3b32dd87.
2025-10-31 19:45:23,272 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (a5daedd0b794f13f6074f63d3b32dd87).
2025-10-31 19:45:23,272 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:45:23,275 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:45:23,275 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6aec8f45
2025-10-31 19:45:23,275 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:45:23,275 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:45:23,277 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:45:23,277 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@6b599dcd for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (a5daedd0b794f13f6074f63d3b32dd87).
2025-10-31 19:45:23,277 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (a5daedd0b794f13f6074f63d3b32dd87) under job master id 00000000000000000000000000000000.
2025-10-31 19:45:23,277 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions2[38].
2025-10-31 19:45:23,278 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:45:23,278 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (a5daedd0b794f13f6074f63d3b32dd87) switched from state CREATED to RUNNING.
2025-10-31 19:45:23,278 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[38] -> Calc[39] -> Sink: Collect table sink (1/1) (385f5e904b4648c295ddc7937c74fa96_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:45:23,278 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:45:23,278 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-4194902014026362284-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:45:23,279 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:45:23,279 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_14 for job a5daedd0b794f13f6074f63d3b32dd87.
2025-10-31 19:45:23,279 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_14 for job a5daedd0b794f13f6074f63d3b32dd87.
2025-10-31 19:45:23,279 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:45:23,280 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job a5daedd0b794f13f6074f63d3b32dd87: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:45:23,281 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:45:23,281 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:45:23,281 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:45:23,281 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761920123281
2025-10-31 19:45:23,281 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:45:23,290 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [alerts-0]
2025-10-31 19:45:23,345 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job a5daedd0b794f13f6074f63d3b32dd87
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:45:23,346 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot edb510695f8e5fbe8e07fba049a1a1b8 from localhost:49385-5990f3 for job a5daedd0b794f13f6074f63d3b32dd87 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:45:23,363 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[38] -> Calc[39] -> Sink: Collect table sink (1/1) (385f5e904b4648c295ddc7937c74fa96_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:45:23,374 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions2[38] -> Calc[39] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 385f5e904b4648c295ddc7937c74fa96_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id edb510695f8e5fbe8e07fba049a1a1b8
2025-10-31 19:45:23,398 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[38] -> Calc[39] -> Sink: Collect table sink (1/1) (385f5e904b4648c295ddc7937c74fa96_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:45:23,444 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:58672
2025-10-31 19:45:23,444 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions2[38] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:45:23,444 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:45:23,445 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[38] -> Calc[39] -> Sink: Collect table sink (1/1) (385f5e904b4648c295ddc7937c74fa96_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:45:23,546 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:45:27,442 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (a5daedd0b794f13f6074f63d3b32dd87) switched from state RUNNING to CANCELLING.
2025-10-31 19:45:27,442 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[38] -> Calc[39] -> Sink: Collect table sink (1/1) (385f5e904b4648c295ddc7937c74fa96_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:45:27,547 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Connection reset by peer
2025-10-31 19:45:27,657 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:45:27,776 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:45:27,886 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:45:27,907 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[38] -> Calc[39] -> Sink: Collect table sink (1/1) (385f5e904b4648c295ddc7937c74fa96_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:45:27,908 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job a5daedd0b794f13f6074f63d3b32dd87
2025-10-31 19:45:27,908 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000 (a5daedd0b794f13f6074f63d3b32dd87) switched from state CANCELLING to CANCELED.
2025-10-31 19:45:27,908 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job a5daedd0b794f13f6074f63d3b32dd87.
2025-10-31 19:45:27,909 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job a5daedd0b794f13f6074f63d3b32dd87 reached terminal state CANCELED.
2025-10-31 19:45:27,912 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (a5daedd0b794f13f6074f63d3b32dd87).
2025-10-31 19:45:27,912 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:45:27,912 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:45:27,912 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [edb510695f8e5fbe8e07fba049a1a1b8].
2025-10-31 19:45:27,913 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (a5daedd0b794f13f6074f63d3b32dd87).
2025-10-31 19:45:27,912 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions2[38].
2025-10-31 19:45:27,913 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 1000' (a5daedd0b794f13f6074f63d3b32dd87).
2025-10-31 19:45:27,913 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_14 for job a5daedd0b794f13f6074f63d3b32dd87 from the resource manager.
2025-10-31 19:45:27,913 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-4194902014026362284-enumerator-admin-client unregistered
2025-10-31 19:45:27,915 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:45:27,915 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:45:27,915 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:45:27,916 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot edb510695f8e5fbe8e07fba049a1a1b8.
2025-10-31 19:45:27,916 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions2[38] closed.
2025-10-31 19:45:37,863 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (fb11530a0a87f6a7b1c418d35c7af830).
2025-10-31 19:45:37,863 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (fb11530a0a87f6a7b1c418d35c7af830).
2025-10-31 19:45:37,864 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job fb11530a0a87f6a7b1c418d35c7af830 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:45:37,865 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_15 .
2025-10-31 19:45:37,866 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (fb11530a0a87f6a7b1c418d35c7af830).
2025-10-31 19:45:37,866 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (fb11530a0a87f6a7b1c418d35c7af830).
2025-10-31 19:45:37,867 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph ec7595903464828ef1817b43a8512125 for job fb11530a0a87f6a7b1c418d35c7af830.
2025-10-31 19:45:37,867 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (fb11530a0a87f6a7b1c418d35c7af830).
2025-10-31 19:45:37,867 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:45:37,871 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:45:37,871 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1bfbe7ac
2025-10-31 19:45:37,871 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:45:37,871 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:45:37,875 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:45:37,875 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@751c4fc5 for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (fb11530a0a87f6a7b1c418d35c7af830).
2025-10-31 19:45:37,875 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (fb11530a0a87f6a7b1c418d35c7af830) under job master id 00000000000000000000000000000000.
2025-10-31 19:45:37,876 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions2[41].
2025-10-31 19:45:37,876 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:45:37,876 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (fb11530a0a87f6a7b1c418d35c7af830) switched from state CREATED to RUNNING.
2025-10-31 19:45:37,876 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[41] -> Sink: Collect table sink (1/1) (ec7595903464828ef1817b43a8512125_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:45:37,876 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:45:37,877 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--3900976866472086564-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:45:37,877 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:45:37,877 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_15 for job fb11530a0a87f6a7b1c418d35c7af830.
2025-10-31 19:45:37,877 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_15 for job fb11530a0a87f6a7b1c418d35c7af830.
2025-10-31 19:45:37,877 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:45:37,878 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fb11530a0a87f6a7b1c418d35c7af830: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:45:37,878 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:45:37,878 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:45:37,878 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:45:37,878 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761920137878
2025-10-31 19:45:37,879 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:45:37,888 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [alerts-0]
2025-10-31 19:45:37,945 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fb11530a0a87f6a7b1c418d35c7af830
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:45:37,945 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 32035687a6741dcf3cc8cfb8f863a099 from localhost:49385-5990f3 for job fb11530a0a87f6a7b1c418d35c7af830 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:45:37,964 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[41] -> Sink: Collect table sink (1/1) (ec7595903464828ef1817b43a8512125_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:45:37,964 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions2[41] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id ec7595903464828ef1817b43a8512125_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 32035687a6741dcf3cc8cfb8f863a099
2025-10-31 19:45:37,980 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[41] -> Sink: Collect table sink (1/1) (ec7595903464828ef1817b43a8512125_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:45:37,991 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:57159
2025-10-31 19:45:37,991 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions2[41] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:45:37,991 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:45:37,991 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[41] -> Sink: Collect table sink (1/1) (ec7595903464828ef1817b43a8512125_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:45:38,035 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:45:41,149 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (fb11530a0a87f6a7b1c418d35c7af830) switched from state RUNNING to CANCELLING.
2025-10-31 19:45:41,149 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[41] -> Sink: Collect table sink (1/1) (ec7595903464828ef1817b43a8512125_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:45:41,254 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Connection reset by peer
2025-10-31 19:45:41,286 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[41] -> Sink: Collect table sink (1/1) (ec7595903464828ef1817b43a8512125_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:45:41,287 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (fb11530a0a87f6a7b1c418d35c7af830) switched from state CANCELLING to CANCELED.
2025-10-31 19:45:41,287 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job fb11530a0a87f6a7b1c418d35c7af830.
2025-10-31 19:45:41,287 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fb11530a0a87f6a7b1c418d35c7af830
2025-10-31 19:45:41,288 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job fb11530a0a87f6a7b1c418d35c7af830 reached terminal state CANCELED.
2025-10-31 19:45:41,289 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (fb11530a0a87f6a7b1c418d35c7af830).
2025-10-31 19:45:41,289 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:45:41,289 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions2[41].
2025-10-31 19:45:41,289 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:45:41,289 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [32035687a6741dcf3cc8cfb8f863a099].
2025-10-31 19:45:41,289 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (fb11530a0a87f6a7b1c418d35c7af830).
2025-10-31 19:45:41,290 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (fb11530a0a87f6a7b1c418d35c7af830).
2025-10-31 19:45:41,290 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--3900976866472086564-enumerator-admin-client unregistered
2025-10-31 19:45:41,290 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_15 for job fb11530a0a87f6a7b1c418d35c7af830 from the resource manager.
2025-10-31 19:45:41,291 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 32035687a6741dcf3cc8cfb8f863a099.
2025-10-31 19:45:41,292 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:45:41,292 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:45:41,292 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:45:41,292 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions2[41] closed.
2025-10-31 19:45:46,951 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (dacb49c82634102fb01efd2b0415ffb8).
2025-10-31 19:45:46,951 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (dacb49c82634102fb01efd2b0415ffb8).
2025-10-31 19:45:46,951 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job dacb49c82634102fb01efd2b0415ffb8 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:45:46,953 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_16 .
2025-10-31 19:45:46,953 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (dacb49c82634102fb01efd2b0415ffb8).
2025-10-31 19:45:46,954 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (dacb49c82634102fb01efd2b0415ffb8).
2025-10-31 19:45:46,954 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 50b072664120262dda27f11295c8c35e for job dacb49c82634102fb01efd2b0415ffb8.
2025-10-31 19:45:46,954 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (dacb49c82634102fb01efd2b0415ffb8).
2025-10-31 19:45:46,954 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:45:46,957 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:45:46,958 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@871a9ad
2025-10-31 19:45:46,958 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:45:46,958 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:45:46,960 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:45:46,960 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@71e9f0c9 for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (dacb49c82634102fb01efd2b0415ffb8).
2025-10-31 19:45:46,961 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (dacb49c82634102fb01efd2b0415ffb8) under job master id 00000000000000000000000000000000.
2025-10-31 19:45:46,961 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions2[43].
2025-10-31 19:45:46,961 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:45:46,961 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (dacb49c82634102fb01efd2b0415ffb8) switched from state CREATED to RUNNING.
2025-10-31 19:45:46,961 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[43] -> Sink: Collect table sink (1/1) (50b072664120262dda27f11295c8c35e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:45:46,962 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:45:46,963 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--8417969192187450526-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:45:46,964 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:45:46,964 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_16 for job dacb49c82634102fb01efd2b0415ffb8.
2025-10-31 19:45:46,965 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_16 for job dacb49c82634102fb01efd2b0415ffb8.
2025-10-31 19:45:46,965 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:45:46,965 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job dacb49c82634102fb01efd2b0415ffb8: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:45:46,965 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:45:46,965 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:45:46,965 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:45:46,965 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761920146965
2025-10-31 19:45:46,966 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:45:46,971 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [alerts-0]
2025-10-31 19:45:47,034 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job dacb49c82634102fb01efd2b0415ffb8
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:45:47,034 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 2e228d73a9409fa48f36c2c9ee0477f3 from localhost:49385-5990f3 for job dacb49c82634102fb01efd2b0415ffb8 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:45:47,044 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[43] -> Sink: Collect table sink (1/1) (50b072664120262dda27f11295c8c35e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:45:47,044 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions2[43] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 50b072664120262dda27f11295c8c35e_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 2e228d73a9409fa48f36c2c9ee0477f3
2025-10-31 19:45:47,061 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[43] -> Sink: Collect table sink (1/1) (50b072664120262dda27f11295c8c35e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:45:47,066 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:64595
2025-10-31 19:45:47,066 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions2[43] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:45:47,066 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:45:47,067 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[43] -> Sink: Collect table sink (1/1) (50b072664120262dda27f11295c8c35e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:45:47,120 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:45:50,701 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (dacb49c82634102fb01efd2b0415ffb8) switched from state RUNNING to CANCELLING.
2025-10-31 19:45:50,701 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[43] -> Sink: Collect table sink (1/1) (50b072664120262dda27f11295c8c35e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:45:50,810 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-10-31 19:45:50,878 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[43] -> Sink: Collect table sink (1/1) (50b072664120262dda27f11295c8c35e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:45:50,879 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (dacb49c82634102fb01efd2b0415ffb8) switched from state CANCELLING to CANCELED.
2025-10-31 19:45:50,879 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job dacb49c82634102fb01efd2b0415ffb8
2025-10-31 19:45:50,879 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job dacb49c82634102fb01efd2b0415ffb8.
2025-10-31 19:45:50,879 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job dacb49c82634102fb01efd2b0415ffb8 reached terminal state CANCELED.
2025-10-31 19:45:50,880 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (dacb49c82634102fb01efd2b0415ffb8).
2025-10-31 19:45:50,880 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:45:50,880 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions2[43].
2025-10-31 19:45:50,881 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:45:50,881 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [2e228d73a9409fa48f36c2c9ee0477f3].
2025-10-31 19:45:50,881 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (dacb49c82634102fb01efd2b0415ffb8).
2025-10-31 19:45:50,881 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (dacb49c82634102fb01efd2b0415ffb8).
2025-10-31 19:45:50,881 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_16 for job dacb49c82634102fb01efd2b0415ffb8 from the resource manager.
2025-10-31 19:45:50,881 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--8417969192187450526-enumerator-admin-client unregistered
2025-10-31 19:45:50,883 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:45:50,883 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:45:50,883 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:45:50,883 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions2[43] closed.
2025-10-31 19:45:50,905 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 2e228d73a9409fa48f36c2c9ee0477f3.
2025-10-31 19:46:01,991 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100' (5b3159c5d9851a7cda4ea378b70bd24a).
2025-10-31 19:46:01,991 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100' (5b3159c5d9851a7cda4ea378b70bd24a).
2025-10-31 19:46:01,992 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 5b3159c5d9851a7cda4ea378b70bd24a was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:46:01,994 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_17 .
2025-10-31 19:46:01,994 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100' (5b3159c5d9851a7cda4ea378b70bd24a).
2025-10-31 19:46:01,995 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100 (5b3159c5d9851a7cda4ea378b70bd24a).
2025-10-31 19:46:01,996 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 61f92026be6a3ff756a6aa84116974dd for job 5b3159c5d9851a7cda4ea378b70bd24a.
2025-10-31 19:46:01,996 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100 (5b3159c5d9851a7cda4ea378b70bd24a).
2025-10-31 19:46:01,996 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:46:02,002 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:46:02,002 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3176f182
2025-10-31 19:46:02,002 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:46:02,002 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:46:02,005 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:46:02,006 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@1a85f143 for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100 (5b3159c5d9851a7cda4ea378b70bd24a).
2025-10-31 19:46:02,006 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100' (5b3159c5d9851a7cda4ea378b70bd24a) under job master id 00000000000000000000000000000000.
2025-10-31 19:46:02,006 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions2[45].
2025-10-31 19:46:02,006 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:46:02,006 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100 (5b3159c5d9851a7cda4ea378b70bd24a) switched from state CREATED to RUNNING.
2025-10-31 19:46:02,007 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[45] -> Calc[46] -> Sink: Collect table sink (1/1) (61f92026be6a3ff756a6aa84116974dd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:46:02,007 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:46:02,007 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:46:02,007 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--884574702031149682-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:46:02,008 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_17 for job 5b3159c5d9851a7cda4ea378b70bd24a.
2025-10-31 19:46:02,008 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_17 for job 5b3159c5d9851a7cda4ea378b70bd24a.
2025-10-31 19:46:02,008 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:46:02,008 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 5b3159c5d9851a7cda4ea378b70bd24a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:46:02,010 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:46:02,010 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:46:02,010 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:46:02,010 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761920162010
2025-10-31 19:46:02,010 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:46:02,019 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [alerts-0]
2025-10-31 19:46:02,075 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 5b3159c5d9851a7cda4ea378b70bd24a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:46:02,075 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 57625242d8c9487117602d2774dddecd from localhost:49385-5990f3 for job 5b3159c5d9851a7cda4ea378b70bd24a with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:46:02,087 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[45] -> Calc[46] -> Sink: Collect table sink (1/1) (61f92026be6a3ff756a6aa84116974dd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:46:02,089 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions2[45] -> Calc[46] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 61f92026be6a3ff756a6aa84116974dd_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 57625242d8c9487117602d2774dddecd
2025-10-31 19:46:02,108 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[45] -> Calc[46] -> Sink: Collect table sink (1/1) (61f92026be6a3ff756a6aa84116974dd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:46:02,138 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:60132
2025-10-31 19:46:02,138 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions2[45] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:46:02,139 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:46:02,139 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[45] -> Calc[46] -> Sink: Collect table sink (1/1) (61f92026be6a3ff756a6aa84116974dd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:46:02,159 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:46:15,803 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100 (5b3159c5d9851a7cda4ea378b70bd24a) switched from state RUNNING to CANCELLING.
2025-10-31 19:46:15,803 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[45] -> Calc[46] -> Sink: Collect table sink (1/1) (61f92026be6a3ff756a6aa84116974dd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:46:15,909 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Connection reset by peer
2025-10-31 19:46:16,020 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:46:16,073 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[45] -> Calc[46] -> Sink: Collect table sink (1/1) (61f92026be6a3ff756a6aa84116974dd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:46:16,075 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100 (5b3159c5d9851a7cda4ea378b70bd24a) switched from state CANCELLING to CANCELED.
2025-10-31 19:46:16,075 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 5b3159c5d9851a7cda4ea378b70bd24a.
2025-10-31 19:46:16,075 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 5b3159c5d9851a7cda4ea378b70bd24a
2025-10-31 19:46:16,076 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 5b3159c5d9851a7cda4ea378b70bd24a reached terminal state CANCELED.
2025-10-31 19:46:16,078 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100' (5b3159c5d9851a7cda4ea378b70bd24a).
2025-10-31 19:46:16,078 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:46:16,078 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:46:16,078 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [57625242d8c9487117602d2774dddecd].
2025-10-31 19:46:16,078 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions2[45].
2025-10-31 19:46:16,078 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100' (5b3159c5d9851a7cda4ea378b70bd24a).
2025-10-31 19:46:16,079 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 100' (5b3159c5d9851a7cda4ea378b70bd24a).
2025-10-31 19:46:16,079 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_17 for job 5b3159c5d9851a7cda4ea378b70bd24a from the resource manager.
2025-10-31 19:46:16,079 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--884574702031149682-enumerator-admin-client unregistered
2025-10-31 19:46:16,085 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 57625242d8c9487117602d2774dddecd.
2025-10-31 19:46:16,085 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:46:16,085 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:46:16,085 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:46:16,085 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions2[45] closed.
2025-10-31 19:46:19,805 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (aa48aa94835f77741657e1e486079ef0).
2025-10-31 19:46:19,805 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (aa48aa94835f77741657e1e486079ef0).
2025-10-31 19:46:19,805 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job aa48aa94835f77741657e1e486079ef0 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:46:19,806 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_18 .
2025-10-31 19:46:19,806 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (aa48aa94835f77741657e1e486079ef0).
2025-10-31 19:46:19,807 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (aa48aa94835f77741657e1e486079ef0).
2025-10-31 19:46:19,807 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 3e4cae4d320df2dcbb67be1f4595d3f3 for job aa48aa94835f77741657e1e486079ef0.
2025-10-31 19:46:19,807 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (aa48aa94835f77741657e1e486079ef0).
2025-10-31 19:46:19,807 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:46:19,810 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:46:19,810 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3bb352f2
2025-10-31 19:46:19,810 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:46:19,810 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:46:19,813 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:46:19,813 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@4f843811 for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (aa48aa94835f77741657e1e486079ef0).
2025-10-31 19:46:19,813 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (aa48aa94835f77741657e1e486079ef0) under job master id 00000000000000000000000000000000.
2025-10-31 19:46:19,813 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions2[48].
2025-10-31 19:46:19,814 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:46:19,814 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (aa48aa94835f77741657e1e486079ef0) switched from state CREATED to RUNNING.
2025-10-31 19:46:19,814 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[48] -> Calc[49] -> Sink: Collect table sink (1/1) (3e4cae4d320df2dcbb67be1f4595d3f3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:46:19,814 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:46:19,816 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:46:19,816 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_18 for job aa48aa94835f77741657e1e486079ef0.
2025-10-31 19:46:19,815 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-1098377028252498208-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:46:19,816 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_18 for job aa48aa94835f77741657e1e486079ef0.
2025-10-31 19:46:19,816 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:46:19,817 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job aa48aa94835f77741657e1e486079ef0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:46:19,818 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:46:19,818 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:46:19,818 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:46:19,818 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761920179818
2025-10-31 19:46:19,818 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:46:19,827 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [alerts-0]
2025-10-31 19:46:19,884 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job aa48aa94835f77741657e1e486079ef0
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:46:19,884 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 775239320a5a0dbf72b72cec9d22d8a2 from localhost:49385-5990f3 for job aa48aa94835f77741657e1e486079ef0 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:46:19,891 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[48] -> Calc[49] -> Sink: Collect table sink (1/1) (3e4cae4d320df2dcbb67be1f4595d3f3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:46:19,891 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions2[48] -> Calc[49] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 3e4cae4d320df2dcbb67be1f4595d3f3_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 775239320a5a0dbf72b72cec9d22d8a2
2025-10-31 19:46:19,910 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[48] -> Calc[49] -> Sink: Collect table sink (1/1) (3e4cae4d320df2dcbb67be1f4595d3f3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:46:19,928 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:52503
2025-10-31 19:46:19,929 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions2[48] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:46:19,929 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:46:19,929 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[48] -> Calc[49] -> Sink: Collect table sink (1/1) (3e4cae4d320df2dcbb67be1f4595d3f3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:46:19,969 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:46:20,108 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (aa48aa94835f77741657e1e486079ef0) switched from state RUNNING to CANCELLING.
2025-10-31 19:46:20,108 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[48] -> Calc[49] -> Sink: Collect table sink (1/1) (3e4cae4d320df2dcbb67be1f4595d3f3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:46:20,215 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-10-31 19:46:20,329 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:46:20,444 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:46:20,479 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[48] -> Calc[49] -> Sink: Collect table sink (1/1) (3e4cae4d320df2dcbb67be1f4595d3f3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:46:20,479 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (aa48aa94835f77741657e1e486079ef0) switched from state CANCELLING to CANCELED.
2025-10-31 19:46:20,479 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job aa48aa94835f77741657e1e486079ef0.
2025-10-31 19:46:20,479 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job aa48aa94835f77741657e1e486079ef0
2025-10-31 19:46:20,480 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job aa48aa94835f77741657e1e486079ef0 reached terminal state CANCELED.
2025-10-31 19:46:20,481 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (aa48aa94835f77741657e1e486079ef0).
2025-10-31 19:46:20,482 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:46:20,482 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:46:20,482 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [775239320a5a0dbf72b72cec9d22d8a2].
2025-10-31 19:46:20,482 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (aa48aa94835f77741657e1e486079ef0).
2025-10-31 19:46:20,482 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (aa48aa94835f77741657e1e486079ef0).
2025-10-31 19:46:20,482 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_18 for job aa48aa94835f77741657e1e486079ef0 from the resource manager.
2025-10-31 19:46:20,482 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions2[48].
2025-10-31 19:46:20,482 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-1098377028252498208-enumerator-admin-client unregistered
2025-10-31 19:46:20,484 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 775239320a5a0dbf72b72cec9d22d8a2.
2025-10-31 19:46:20,484 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:46:20,484 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:46:20,484 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:46:20,485 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions2[48] closed.
2025-10-31 19:46:22,065 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (d66faa16eb49f2c23b1caf0c3df39e1b).
2025-10-31 19:46:22,065 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (d66faa16eb49f2c23b1caf0c3df39e1b).
2025-10-31 19:46:22,065 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job d66faa16eb49f2c23b1caf0c3df39e1b was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:46:22,066 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_19 .
2025-10-31 19:46:22,066 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (d66faa16eb49f2c23b1caf0c3df39e1b).
2025-10-31 19:46:22,069 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (d66faa16eb49f2c23b1caf0c3df39e1b).
2025-10-31 19:46:22,070 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 0c93ba3515cca3dcbe7d5cf0e2c66126 for job d66faa16eb49f2c23b1caf0c3df39e1b.
2025-10-31 19:46:22,070 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (d66faa16eb49f2c23b1caf0c3df39e1b).
2025-10-31 19:46:22,070 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:46:22,072 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:46:22,072 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5f4de3b
2025-10-31 19:46:22,072 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:46:22,072 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:46:22,074 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:46:22,074 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@31bac585 for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (d66faa16eb49f2c23b1caf0c3df39e1b).
2025-10-31 19:46:22,074 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (d66faa16eb49f2c23b1caf0c3df39e1b) under job master id 00000000000000000000000000000000.
2025-10-31 19:46:22,074 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions2[51].
2025-10-31 19:46:22,074 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:46:22,074 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (d66faa16eb49f2c23b1caf0c3df39e1b) switched from state CREATED to RUNNING.
2025-10-31 19:46:22,075 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[51] -> Calc[52] -> Sink: Collect table sink (1/1) (0c93ba3515cca3dcbe7d5cf0e2c66126_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:46:22,075 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:46:22,075 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:46:22,075 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--7454791524398965535-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:46:22,076 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_19 for job d66faa16eb49f2c23b1caf0c3df39e1b.
2025-10-31 19:46:22,076 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_19 for job d66faa16eb49f2c23b1caf0c3df39e1b.
2025-10-31 19:46:22,077 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:46:22,077 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job d66faa16eb49f2c23b1caf0c3df39e1b: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:46:22,077 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:46:22,077 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:46:22,077 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:46:22,077 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761920182077
2025-10-31 19:46:22,077 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:46:22,081 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [alerts-0]
2025-10-31 19:46:22,144 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job d66faa16eb49f2c23b1caf0c3df39e1b
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:46:22,145 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 59c13f1daf71cae932463378c460f4e1 from localhost:49385-5990f3 for job d66faa16eb49f2c23b1caf0c3df39e1b with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:46:22,161 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[51] -> Calc[52] -> Sink: Collect table sink (1/1) (0c93ba3515cca3dcbe7d5cf0e2c66126_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:46:22,162 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions2[51] -> Calc[52] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 0c93ba3515cca3dcbe7d5cf0e2c66126_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 59c13f1daf71cae932463378c460f4e1
2025-10-31 19:46:22,180 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[51] -> Calc[52] -> Sink: Collect table sink (1/1) (0c93ba3515cca3dcbe7d5cf0e2c66126_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:46:22,192 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:53793
2025-10-31 19:46:22,192 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions2[51] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:46:22,192 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:46:22,194 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[51] -> Calc[52] -> Sink: Collect table sink (1/1) (0c93ba3515cca3dcbe7d5cf0e2c66126_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:46:22,236 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:46:32,627 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (d66faa16eb49f2c23b1caf0c3df39e1b) switched from state RUNNING to CANCELLING.
2025-10-31 19:46:32,628 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[51] -> Calc[52] -> Sink: Collect table sink (1/1) (0c93ba3515cca3dcbe7d5cf0e2c66126_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:46:32,734 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-10-31 19:46:32,840 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:46:32,953 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:46:32,964 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[51] -> Calc[52] -> Sink: Collect table sink (1/1) (0c93ba3515cca3dcbe7d5cf0e2c66126_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:46:32,964 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0 (d66faa16eb49f2c23b1caf0c3df39e1b) switched from state CANCELLING to CANCELED.
2025-10-31 19:46:32,964 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job d66faa16eb49f2c23b1caf0c3df39e1b
2025-10-31 19:46:32,964 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job d66faa16eb49f2c23b1caf0c3df39e1b.
2025-10-31 19:46:32,965 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job d66faa16eb49f2c23b1caf0c3df39e1b reached terminal state CANCELED.
2025-10-31 19:46:32,967 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (d66faa16eb49f2c23b1caf0c3df39e1b).
2025-10-31 19:46:32,968 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:46:32,968 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:46:32,968 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [59c13f1daf71cae932463378c460f4e1].
2025-10-31 19:46:32,968 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (d66faa16eb49f2c23b1caf0c3df39e1b).
2025-10-31 19:46:32,968 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`
WHERE `transactions2`.`TransactionAmount` > 0' (d66faa16eb49f2c23b1caf0c3df39e1b).
2025-10-31 19:46:32,968 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_19 for job d66faa16eb49f2c23b1caf0c3df39e1b from the resource manager.
2025-10-31 19:46:32,968 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions2[51].
2025-10-31 19:46:32,969 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--7454791524398965535-enumerator-admin-client unregistered
2025-10-31 19:46:32,971 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 59c13f1daf71cae932463378c460f4e1.
2025-10-31 19:46:32,972 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:46:32,972 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:46:32,972 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:46:32,972 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions2[51] closed.
2025-10-31 19:46:35,085 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (a25903053abfb6563fec3c7d8e235a1f).
2025-10-31 19:46:35,085 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (a25903053abfb6563fec3c7d8e235a1f).
2025-10-31 19:46:35,086 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job a25903053abfb6563fec3c7d8e235a1f was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:46:35,087 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_20 .
2025-10-31 19:46:35,087 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (a25903053abfb6563fec3c7d8e235a1f).
2025-10-31 19:46:35,088 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (a25903053abfb6563fec3c7d8e235a1f).
2025-10-31 19:46:35,088 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph aabf28a0ca41f58d90a8e809f6dea6ac for job a25903053abfb6563fec3c7d8e235a1f.
2025-10-31 19:46:35,088 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (a25903053abfb6563fec3c7d8e235a1f).
2025-10-31 19:46:35,088 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:46:35,090 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:46:35,090 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@835ba6f
2025-10-31 19:46:35,090 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:46:35,090 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:46:35,093 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:46:35,093 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@601f7408 for SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (a25903053abfb6563fec3c7d8e235a1f).
2025-10-31 19:46:35,093 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (a25903053abfb6563fec3c7d8e235a1f) under job master id 00000000000000000000000000000000.
2025-10-31 19:46:35,093 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions2[54].
2025-10-31 19:46:35,093 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:46:35,093 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (a25903053abfb6563fec3c7d8e235a1f) switched from state CREATED to RUNNING.
2025-10-31 19:46:35,094 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[54] -> Sink: Collect table sink (1/1) (aabf28a0ca41f58d90a8e809f6dea6ac_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:46:35,094 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--1353623301175777634-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:46:35,094 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:46:35,094 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:46:35,094 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_20 for job a25903053abfb6563fec3c7d8e235a1f.
2025-10-31 19:46:35,095 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_20 for job a25903053abfb6563fec3c7d8e235a1f.
2025-10-31 19:46:35,095 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:46:35,095 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job a25903053abfb6563fec3c7d8e235a1f: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:46:35,095 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:46:35,095 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:46:35,095 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:46:35,095 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761920195095
2025-10-31 19:46:35,095 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:46:35,099 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [alerts-0]
2025-10-31 19:46:35,164 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job a25903053abfb6563fec3c7d8e235a1f
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:46:35,164 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 0af54b0c93bd649e1a8322eda0e4de6d from localhost:49385-5990f3 for job a25903053abfb6563fec3c7d8e235a1f with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:46:35,180 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[54] -> Sink: Collect table sink (1/1) (aabf28a0ca41f58d90a8e809f6dea6ac_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:46:35,181 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions2[54] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id aabf28a0ca41f58d90a8e809f6dea6ac_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 0af54b0c93bd649e1a8322eda0e4de6d
2025-10-31 19:46:35,201 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[54] -> Sink: Collect table sink (1/1) (aabf28a0ca41f58d90a8e809f6dea6ac_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:46:35,209 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:53290
2025-10-31 19:46:35,210 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions2[54] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:46:35,210 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:46:35,212 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[54] -> Sink: Collect table sink (1/1) (aabf28a0ca41f58d90a8e809f6dea6ac_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:46:35,249 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:57:09,461 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (a25903053abfb6563fec3c7d8e235a1f) switched from state RUNNING to CANCELLING.
2025-10-31 19:57:09,465 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[54] -> Sink: Collect table sink (1/1) (aabf28a0ca41f58d90a8e809f6dea6ac_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:57:09,537 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions2[54] -> Sink: Collect table sink (1/1) (aabf28a0ca41f58d90a8e809f6dea6ac_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:57:09,538 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job a25903053abfb6563fec3c7d8e235a1f
2025-10-31 19:57:09,539 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2` (a25903053abfb6563fec3c7d8e235a1f) switched from state CANCELLING to CANCELED.
2025-10-31 19:57:09,539 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job a25903053abfb6563fec3c7d8e235a1f.
2025-10-31 19:57:09,540 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job a25903053abfb6563fec3c7d8e235a1f reached terminal state CANCELED.
2025-10-31 19:57:09,551 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (a25903053abfb6563fec3c7d8e235a1f).
2025-10-31 19:57:09,552 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:57:09,552 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:57:09,553 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [0af54b0c93bd649e1a8322eda0e4de6d].
2025-10-31 19:57:09,553 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (a25903053abfb6563fec3c7d8e235a1f).
2025-10-31 19:57:09,553 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions2`.`TransactionID`, `transactions2`.`AccountID`, `transactions2`.`TransactionAmount`, `transactions2`.`TransactionDate`
FROM `default_catalog`.`default_database`.`transactions2` AS `transactions2`' (a25903053abfb6563fec3c7d8e235a1f).
2025-10-31 19:57:09,552 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions2[54].
2025-10-31 19:57:09,554 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_20 for job a25903053abfb6563fec3c7d8e235a1f from the resource manager.
2025-10-31 19:57:09,556 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--1353623301175777634-enumerator-admin-client unregistered
2025-10-31 19:57:09,560 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:57:09,560 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:57:09,560 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:57:09,560 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 0af54b0c93bd649e1a8322eda0e4de6d.
2025-10-31 19:57:09,560 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions2[54] closed.
2025-10-31 19:59:39,934 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz`' (d7fee36ade1c4ee3330be141314e87b4).
2025-10-31 19:59:39,935 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz`' (d7fee36ade1c4ee3330be141314e87b4).
2025-10-31 19:59:39,935 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job d7fee36ade1c4ee3330be141314e87b4 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 19:59:39,937 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_21 .
2025-10-31 19:59:39,938 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz`' (d7fee36ade1c4ee3330be141314e87b4).
2025-10-31 19:59:39,939 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz` (d7fee36ade1c4ee3330be141314e87b4).
2025-10-31 19:59:39,939 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 039fef35c4cd939a10bb95ff3404aff5 for job d7fee36ade1c4ee3330be141314e87b4.
2025-10-31 19:59:39,939 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz` (d7fee36ade1c4ee3330be141314e87b4).
2025-10-31 19:59:39,939 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 19:59:39,942 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 19:59:39,942 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@287be63d
2025-10-31 19:59:39,942 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 19:59:39,942 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 19:59:39,944 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 19:59:39,944 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@6e8acfcf for SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz` (d7fee36ade1c4ee3330be141314e87b4).
2025-10-31 19:59:39,944 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz`' (d7fee36ade1c4ee3330be141314e87b4) under job master id 00000000000000000000000000000000.
2025-10-31 19:59:39,944 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: xyz[56].
2025-10-31 19:59:39,944 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 19:59:39,944 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz` (d7fee36ade1c4ee3330be141314e87b4) switched from state CREATED to RUNNING.
2025-10-31 19:59:39,944 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyz[56] -> Sink: Collect table sink (1/1) (039fef35c4cd939a10bb95ff3404aff5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 19:59:39,945 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 19:59:39,945 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 19:59:39,945 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--8474412134001077911-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 19:59:39,946 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_21 for job d7fee36ade1c4ee3330be141314e87b4.
2025-10-31 19:59:39,946 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_21 for job d7fee36ade1c4ee3330be141314e87b4.
2025-10-31 19:59:39,947 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 19:59:39,947 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job d7fee36ade1c4ee3330be141314e87b4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 19:59:39,948 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 19:59:39,948 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 19:59:39,948 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 19:59:39,948 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761920979948
2025-10-31 19:59:39,948 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 19:59:39,963 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-0]
2025-10-31 19:59:40,007 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job d7fee36ade1c4ee3330be141314e87b4
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 19:59:40,008 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot adb0bfa5202fbc64b346fbb206103b1d from localhost:49385-5990f3 for job d7fee36ade1c4ee3330be141314e87b4 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 19:59:40,016 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyz[56] -> Sink: Collect table sink (1/1) (039fef35c4cd939a10bb95ff3404aff5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 19:59:40,018 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: xyz[56] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 039fef35c4cd939a10bb95ff3404aff5_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id adb0bfa5202fbc64b346fbb206103b1d
2025-10-31 19:59:40,040 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyz[56] -> Sink: Collect table sink (1/1) (039fef35c4cd939a10bb95ff3404aff5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 19:59:40,051 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:58768
2025-10-31 19:59:40,051 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyz[56] -> Sink: Collect table sink (1/1) (039fef35c4cd939a10bb95ff3404aff5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 19:59:40,051 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: xyz[56] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 19:59:40,052 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 19:59:40,101 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 19:59:48,418 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz` (d7fee36ade1c4ee3330be141314e87b4) switched from state RUNNING to CANCELLING.
2025-10-31 19:59:48,419 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyz[56] -> Sink: Collect table sink (1/1) (039fef35c4cd939a10bb95ff3404aff5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 19:59:48,528 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Connection reset by peer
2025-10-31 19:59:48,633 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:59:48,744 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 19:59:48,747 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyz[56] -> Sink: Collect table sink (1/1) (039fef35c4cd939a10bb95ff3404aff5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 19:59:48,747 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz` (d7fee36ade1c4ee3330be141314e87b4) switched from state CANCELLING to CANCELED.
2025-10-31 19:59:48,747 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job d7fee36ade1c4ee3330be141314e87b4
2025-10-31 19:59:48,747 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job d7fee36ade1c4ee3330be141314e87b4.
2025-10-31 19:59:48,749 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job d7fee36ade1c4ee3330be141314e87b4 reached terminal state CANCELED.
2025-10-31 19:59:48,752 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz`' (d7fee36ade1c4ee3330be141314e87b4).
2025-10-31 19:59:48,753 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 19:59:48,753 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 19:59:48,753 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [adb0bfa5202fbc64b346fbb206103b1d].
2025-10-31 19:59:48,753 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: xyz[56].
2025-10-31 19:59:48,753 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz`' (d7fee36ade1c4ee3330be141314e87b4).
2025-10-31 19:59:48,754 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `xyz`.`TransactionID`, `xyz`.`AccountID`, `xyz`.`TransactionAmount`, `xyz`.`TransactionDate`, `xyz`.`TransactionType`, `xyz`.`Location`, `xyz`.`DeviceID`, `xyz`.`IP Address`, `xyz`.`MerchantID`, `xyz`.`Channel`, `xyz`.`CustomerAge`, `xyz`.`CustomerOccupation`, `xyz`.`TransactionDuration`, `xyz`.`LoginAttempts`, `xyz`.`AccountBalance`, `xyz`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyz` AS `xyz`' (d7fee36ade1c4ee3330be141314e87b4).
2025-10-31 19:59:48,754 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_21 for job d7fee36ade1c4ee3330be141314e87b4 from the resource manager.
2025-10-31 19:59:48,754 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--8474412134001077911-enumerator-admin-client unregistered
2025-10-31 19:59:48,756 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 19:59:48,756 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 19:59:48,756 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 19:59:48,756 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot adb0bfa5202fbc64b346fbb206103b1d.
2025-10-31 19:59:48,756 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: xyz[56] closed.
2025-10-31 20:01:57,634 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza`' (c34893274053c0606f82d44bccde6e76).
2025-10-31 20:01:57,634 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza`' (c34893274053c0606f82d44bccde6e76).
2025-10-31 20:01:57,635 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job c34893274053c0606f82d44bccde6e76 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 20:01:57,637 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_22 .
2025-10-31 20:01:57,637 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza`' (c34893274053c0606f82d44bccde6e76).
2025-10-31 20:01:57,637 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza` (c34893274053c0606f82d44bccde6e76).
2025-10-31 20:01:57,638 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 602fedfe2100ce408af6a8672ea8d120 for job c34893274053c0606f82d44bccde6e76.
2025-10-31 20:01:57,639 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza` (c34893274053c0606f82d44bccde6e76).
2025-10-31 20:01:57,639 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 20:01:57,641 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 20:01:57,642 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6916065c
2025-10-31 20:01:57,642 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 20:01:57,642 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 20:01:57,643 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 20:01:57,643 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@19aa171b for SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza` (c34893274053c0606f82d44bccde6e76).
2025-10-31 20:01:57,643 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza`' (c34893274053c0606f82d44bccde6e76) under job master id 00000000000000000000000000000000.
2025-10-31 20:01:57,643 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: xyza[58].
2025-10-31 20:01:57,643 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 20:01:57,643 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza` (c34893274053c0606f82d44bccde6e76) switched from state CREATED to RUNNING.
2025-10-31 20:01:57,643 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyza[58] -> Sink: Collect table sink (1/1) (602fedfe2100ce408af6a8672ea8d120_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 20:01:57,644 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 20:01:57,644 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--321147874901959910-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 20:01:57,644 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 20:01:57,644 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_22 for job c34893274053c0606f82d44bccde6e76.
2025-10-31 20:01:57,644 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_22 for job c34893274053c0606f82d44bccde6e76.
2025-10-31 20:01:57,645 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 20:01:57,645 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job c34893274053c0606f82d44bccde6e76: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 20:01:57,646 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 20:01:57,646 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 20:01:57,646 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 20:01:57,646 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761921117646
2025-10-31 20:01:57,646 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 20:01:57,651 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-data-0]
2025-10-31 20:01:57,708 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job c34893274053c0606f82d44bccde6e76
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 20:01:57,708 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot cedc1cb143547411c8b019eeb9eedb3b from localhost:49385-5990f3 for job c34893274053c0606f82d44bccde6e76 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 20:01:57,724 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyza[58] -> Sink: Collect table sink (1/1) (602fedfe2100ce408af6a8672ea8d120_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 20:01:57,726 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: xyza[58] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 602fedfe2100ce408af6a8672ea8d120_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id cedc1cb143547411c8b019eeb9eedb3b
2025-10-31 20:01:57,744 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyza[58] -> Sink: Collect table sink (1/1) (602fedfe2100ce408af6a8672ea8d120_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 20:01:57,752 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:65291
2025-10-31 20:01:57,753 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: xyza[58] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 20:01:57,753 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-data-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 20:01:57,754 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyza[58] -> Sink: Collect table sink (1/1) (602fedfe2100ce408af6a8672ea8d120_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 20:01:57,795 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 20:06:23,782 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza` (c34893274053c0606f82d44bccde6e76) switched from state RUNNING to CANCELLING.
2025-10-31 20:06:23,787 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyza[58] -> Sink: Collect table sink (1/1) (602fedfe2100ce408af6a8672ea8d120_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 20:06:23,914 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-10-31 20:06:24,020 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 20:06:24,126 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 20:06:24,179 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: xyza[58] -> Sink: Collect table sink (1/1) (602fedfe2100ce408af6a8672ea8d120_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 20:06:24,186 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza` (c34893274053c0606f82d44bccde6e76) switched from state CANCELLING to CANCELED.
2025-10-31 20:06:24,187 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job c34893274053c0606f82d44bccde6e76.
2025-10-31 20:06:24,187 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job c34893274053c0606f82d44bccde6e76
2025-10-31 20:06:24,190 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job c34893274053c0606f82d44bccde6e76 reached terminal state CANCELED.
2025-10-31 20:06:24,197 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza`' (c34893274053c0606f82d44bccde6e76).
2025-10-31 20:06:24,199 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 20:06:24,199 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 20:06:24,199 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [cedc1cb143547411c8b019eeb9eedb3b].
2025-10-31 20:06:24,199 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza`' (c34893274053c0606f82d44bccde6e76).
2025-10-31 20:06:24,200 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `xyza`.`TransactionID`, `xyza`.`AccountID`, `xyza`.`TransactionAmount`, `xyza`.`TransactionDate`, `xyza`.`TransactionType`, `xyza`.`Location`, `xyza`.`DeviceID`, `xyza`.`IP Address`, `xyza`.`MerchantID`, `xyza`.`Channel`, `xyza`.`CustomerAge`, `xyza`.`CustomerOccupation`, `xyza`.`TransactionDuration`, `xyza`.`LoginAttempts`, `xyza`.`AccountBalance`, `xyza`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`xyza` AS `xyza`' (c34893274053c0606f82d44bccde6e76).
2025-10-31 20:06:24,200 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_22 for job c34893274053c0606f82d44bccde6e76 from the resource manager.
2025-10-31 20:06:24,199 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: xyza[58].
2025-10-31 20:06:24,205 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--321147874901959910-enumerator-admin-client unregistered
2025-10-31 20:06:24,206 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot cedc1cb143547411c8b019eeb9eedb3b.
2025-10-31 20:06:24,209 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 20:06:24,209 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 20:06:24,209 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 20:06:24,209 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: xyza[58] closed.
2025-10-31 20:10:09,125 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (1a5c5a6cc8e8aa8889b2b70d684fe166).
2025-10-31 20:10:09,126 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (1a5c5a6cc8e8aa8889b2b70d684fe166).
2025-10-31 20:10:09,128 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 1a5c5a6cc8e8aa8889b2b70d684fe166 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 20:10:09,141 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_23 .
2025-10-31 20:10:09,141 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (1a5c5a6cc8e8aa8889b2b70d684fe166).
2025-10-31 20:10:09,144 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (1a5c5a6cc8e8aa8889b2b70d684fe166).
2025-10-31 20:10:09,145 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 9241d8e51b4e05d2aa51315ed9abbe83 for job 1a5c5a6cc8e8aa8889b2b70d684fe166.
2025-10-31 20:10:09,146 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (1a5c5a6cc8e8aa8889b2b70d684fe166).
2025-10-31 20:10:09,147 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 20:10:09,153 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 20:10:09,153 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@27c70631
2025-10-31 20:10:09,153 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 20:10:09,153 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 20:10:09,157 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 20:10:09,158 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@7dea64e9 for SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (1a5c5a6cc8e8aa8889b2b70d684fe166).
2025-10-31 20:10:09,159 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (1a5c5a6cc8e8aa8889b2b70d684fe166) under job master id 00000000000000000000000000000000.
2025-10-31 20:10:09,159 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions5[60].
2025-10-31 20:10:09,159 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 20:10:09,159 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (1a5c5a6cc8e8aa8889b2b70d684fe166) switched from state CREATED to RUNNING.
2025-10-31 20:10:09,159 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[60] -> Sink: Collect table sink (1/1) (9241d8e51b4e05d2aa51315ed9abbe83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 20:10:09,160 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 20:10:09,161 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--7738220138421692308-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 20:10:09,162 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 20:10:09,162 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_23 for job 1a5c5a6cc8e8aa8889b2b70d684fe166.
2025-10-31 20:10:09,162 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_23 for job 1a5c5a6cc8e8aa8889b2b70d684fe166.
2025-10-31 20:10:09,165 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 20:10:09,166 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 1a5c5a6cc8e8aa8889b2b70d684fe166: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 20:10:09,167 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 20:10:09,167 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 20:10:09,167 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 20:10:09,167 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761921609167
2025-10-31 20:10:09,167 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 20:10:09,186 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-data-0]
2025-10-31 20:10:09,234 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 1a5c5a6cc8e8aa8889b2b70d684fe166
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 20:10:09,234 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 92e9b0a0f83b81527df503154f993906 from localhost:49385-5990f3 for job 1a5c5a6cc8e8aa8889b2b70d684fe166 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 20:10:09,280 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[60] -> Sink: Collect table sink (1/1) (9241d8e51b4e05d2aa51315ed9abbe83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 20:10:09,282 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions5[60] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 9241d8e51b4e05d2aa51315ed9abbe83_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 92e9b0a0f83b81527df503154f993906
2025-10-31 20:10:09,322 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[60] -> Sink: Collect table sink (1/1) (9241d8e51b4e05d2aa51315ed9abbe83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 20:10:09,349 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:63805
2025-10-31 20:10:09,349 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions5[60] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 20:10:09,350 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-data-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 20:10:09,350 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[60] -> Sink: Collect table sink (1/1) (9241d8e51b4e05d2aa51315ed9abbe83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 20:10:09,404 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 20:10:12,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (1a5c5a6cc8e8aa8889b2b70d684fe166) switched from state RUNNING to CANCELLING.
2025-10-31 20:10:12,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[60] -> Sink: Collect table sink (1/1) (9241d8e51b4e05d2aa51315ed9abbe83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 20:10:12,498 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-10-31 20:10:12,602 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 20:10:12,708 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 20:10:12,818 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 20:10:12,925 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 20:10:12,928 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[60] -> Sink: Collect table sink (1/1) (9241d8e51b4e05d2aa51315ed9abbe83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 20:10:12,929 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (1a5c5a6cc8e8aa8889b2b70d684fe166) switched from state CANCELLING to CANCELED.
2025-10-31 20:10:12,929 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 1a5c5a6cc8e8aa8889b2b70d684fe166
2025-10-31 20:10:12,929 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 1a5c5a6cc8e8aa8889b2b70d684fe166.
2025-10-31 20:10:12,931 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 1a5c5a6cc8e8aa8889b2b70d684fe166 reached terminal state CANCELED.
2025-10-31 20:10:12,936 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (1a5c5a6cc8e8aa8889b2b70d684fe166).
2025-10-31 20:10:12,936 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 20:10:12,936 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 20:10:12,936 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [92e9b0a0f83b81527df503154f993906].
2025-10-31 20:10:12,936 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (1a5c5a6cc8e8aa8889b2b70d684fe166).
2025-10-31 20:10:12,936 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (1a5c5a6cc8e8aa8889b2b70d684fe166).
2025-10-31 20:10:12,936 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions5[60].
2025-10-31 20:10:12,936 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_23 for job 1a5c5a6cc8e8aa8889b2b70d684fe166 from the resource manager.
2025-10-31 20:10:12,937 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--7738220138421692308-enumerator-admin-client unregistered
2025-10-31 20:10:12,938 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 20:10:12,938 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 20:10:12,938 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 20:10:12,938 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions5[60] closed.
2025-10-31 20:10:12,939 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 92e9b0a0f83b81527df503154f993906.
2025-10-31 20:15:03,895 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.transactions6' (9ed7b8453fd27d5a1186efe414abc768).
2025-10-31 20:15:03,896 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.transactions6' (9ed7b8453fd27d5a1186efe414abc768).
2025-10-31 20:15:03,897 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 9ed7b8453fd27d5a1186efe414abc768 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 20:15:03,900 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_24 .
2025-10-31 20:15:03,901 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.transactions6' (9ed7b8453fd27d5a1186efe414abc768).
2025-10-31 20:15:03,901 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.transactions6 (9ed7b8453fd27d5a1186efe414abc768).
2025-10-31 20:15:03,902 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 78ce313c8ff7e6344dc969083ed0f426 for job 9ed7b8453fd27d5a1186efe414abc768.
2025-10-31 20:15:03,902 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.transactions6 (9ed7b8453fd27d5a1186efe414abc768).
2025-10-31 20:15:03,902 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 20:15:03,907 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: transactions5[62] -> Calc[63] -> transactions6[64]: Writer -> transactions6[64]: Committer exceeded the 80 characters length limit and was truncated.
2025-10-31 20:15:03,909 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 20:15:03,909 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7616fa0
2025-10-31 20:15:03,909 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 20:15:03,909 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 20:15:03,913 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 20:15:03,913 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@6564ad26 for insert-into_default_catalog.default_database.transactions6 (9ed7b8453fd27d5a1186efe414abc768).
2025-10-31 20:15:03,914 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.transactions6' (9ed7b8453fd27d5a1186efe414abc768) under job master id 00000000000000000000000000000000.
2025-10-31 20:15:03,914 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions5[62].
2025-10-31 20:15:03,914 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 20:15:03,914 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.transactions6 (9ed7b8453fd27d5a1186efe414abc768) switched from state CREATED to RUNNING.
2025-10-31 20:15:03,914 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[62] -> Calc[63] -> transactions6[64]: Writer -> transactions6[64]: Committer (1/1) (78ce313c8ff7e6344dc969083ed0f426_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 20:15:03,914 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 20:15:03,915 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-548571575311059229-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 20:15:03,915 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 20:15:03,915 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_24 for job 9ed7b8453fd27d5a1186efe414abc768.
2025-10-31 20:15:03,916 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_24 for job 9ed7b8453fd27d5a1186efe414abc768.
2025-10-31 20:15:03,917 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 20:15:03,918 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 9ed7b8453fd27d5a1186efe414abc768: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 20:15:03,920 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 20:15:03,920 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 20:15:03,920 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 20:15:03,920 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761921903920
2025-10-31 20:15:03,921 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 20:15:03,980 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 9ed7b8453fd27d5a1186efe414abc768
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 20:15:03,980 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 27495a08f69b9126eb6dc3540d324832 from localhost:49385-5990f3 for job 9ed7b8453fd27d5a1186efe414abc768 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 20:15:03,994 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[62] -> Calc[63] -> transactions6[64]: Writer -> transactions6[64]: Committer (1/1) (78ce313c8ff7e6344dc969083ed0f426_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 20:15:03,996 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions5[62] -> Calc[63] -> transactions6[64]: Writer -> transactions6[64]: Committer (1/1) (attempt #0) with attempt id 78ce313c8ff7e6344dc969083ed0f426_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id 27495a08f69b9126eb6dc3540d324832
2025-10-31 20:15:04,012 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-data-0]
2025-10-31 20:15:04,028 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[62] -> Calc[63] -> transactions6[64]: Writer -> transactions6[64]: Committer (1/1) (78ce313c8ff7e6344dc969083ed0f426_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 20:15:04,073 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions5[62] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 20:15:04,073 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[62] -> Calc[63] -> transactions6[64]: Writer -> transactions6[64]: Committer (1/1) (78ce313c8ff7e6344dc969083ed0f426_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 20:15:04,073 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-data-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 20:16:31,181 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (3067e90abf45bd999844d4a59a5833c3).
2025-10-31 20:16:31,184 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (3067e90abf45bd999844d4a59a5833c3).
2025-10-31 20:16:31,188 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 3067e90abf45bd999844d4a59a5833c3 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 20:16:31,201 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_25 .
2025-10-31 20:16:31,205 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (3067e90abf45bd999844d4a59a5833c3).
2025-10-31 20:16:31,206 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (3067e90abf45bd999844d4a59a5833c3).
2025-10-31 20:16:31,209 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 18534f3c667e7261d827930520eb6d46 for job 3067e90abf45bd999844d4a59a5833c3.
2025-10-31 20:16:31,210 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (3067e90abf45bd999844d4a59a5833c3).
2025-10-31 20:16:31,210 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 20:16:31,227 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 20:16:31,227 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5d63c5ed
2025-10-31 20:16:31,227 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 20:16:31,227 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 20:16:31,267 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 20:16:31,270 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@3679410f for SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (3067e90abf45bd999844d4a59a5833c3).
2025-10-31 20:16:31,270 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (3067e90abf45bd999844d4a59a5833c3) under job master id 00000000000000000000000000000000.
2025-10-31 20:16:31,270 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions5[69].
2025-10-31 20:16:31,270 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 20:16:31,270 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (3067e90abf45bd999844d4a59a5833c3) switched from state CREATED to RUNNING.
2025-10-31 20:16:31,270 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[69] -> Sink: Collect table sink (1/1) (18534f3c667e7261d827930520eb6d46_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 20:16:31,271 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 20:16:31,275 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 20:16:31,275 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_25 for job 3067e90abf45bd999844d4a59a5833c3.
2025-10-31 20:16:31,275 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_25 for job 3067e90abf45bd999844d4a59a5833c3.
2025-10-31 20:16:31,279 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 20:16:31,276 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-2659820915398870794-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 20:16:31,279 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 3067e90abf45bd999844d4a59a5833c3: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 20:16:31,300 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 20:16:31,300 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 20:16:31,300 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 20:16:31,300 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761921991300
2025-10-31 20:16:31,301 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 20:16:31,323 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-data-0]
2025-10-31 20:16:31,350 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 3067e90abf45bd999844d4a59a5833c3
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=0, taskHeapMemory=2 bytes, taskOffHeapMemory=0 bytes, managedMemory=0 bytes, networkMemory=2 bytes}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 20:16:31,350 WARN  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Could not fulfill resource requirements of job 3067e90abf45bd999844d4a59a5833c3.
2025-10-31 20:16:31,350 WARN  org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge [] - Could not acquire the minimum required resources, failing slot requests. Acquired: []. Current slot pool status: Registered TMs: 0, registered slots: 0 free slots: 0
2025-10-31 20:16:31,366 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[69] -> Sink: Collect table sink (1/1) (18534f3c667e7261d827930520eb6d46_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to FAILED on [unassigned resource].
org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 20:16:31,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 18534f3c667e7261d827930520eb6d46_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-10-31 20:16:31,412 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: transactions5[69].
2025-10-31 20:16:31,413 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (3067e90abf45bd999844d4a59a5833c3) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 20:16:31,470 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (3067e90abf45bd999844d4a59a5833c3) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 20:16:31,478 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 3067e90abf45bd999844d4a59a5833c3.
2025-10-31 20:16:31,508 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 3067e90abf45bd999844d4a59a5833c3
2025-10-31 20:16:31,517 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 3067e90abf45bd999844d4a59a5833c3 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51)
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130)
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969)
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162)
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399)
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226)
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636)
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 20:16:31,560 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (3067e90abf45bd999844d4a59a5833c3).
2025-10-31 20:16:31,560 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 20:16:31,560 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 20:16:31,560 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (3067e90abf45bd999844d4a59a5833c3).
2025-10-31 20:16:31,560 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_25 for job 3067e90abf45bd999844d4a59a5833c3 from the resource manager.
2025-10-31 20:16:31,561 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions5[69].
2025-10-31 20:16:31,564 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-2659820915398870794-enumerator-admin-client unregistered
2025-10-31 20:16:31,578 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 20:16:31,578 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 20:16:31,578 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 20:16:31,578 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions5[69] closed.
2025-10-31 20:18:17,406 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.filtered_transactions (cd26c9845974958140a55e4f03b31f62) switched from state RUNNING to CANCELLING.
2025-10-31 20:18:17,407 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> filtered_transactions[3]: Writer -> filtered_transactions[3]: Committer (1/1) (7be2db6bef65caecd0a090d04fa7ba25_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 20:18:17,657 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[1] -> Calc[2] -> filtered_transactions[3]: Writer -> filtered_transactions[3]: Committer (1/1) (7be2db6bef65caecd0a090d04fa7ba25_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 20:18:17,659 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.filtered_transactions (cd26c9845974958140a55e4f03b31f62) switched from state CANCELLING to CANCELED.
2025-10-31 20:18:17,659 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job cd26c9845974958140a55e4f03b31f62.
2025-10-31 20:18:17,659 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job cd26c9845974958140a55e4f03b31f62
2025-10-31 20:18:17,660 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job cd26c9845974958140a55e4f03b31f62 reached terminal state CANCELED.
2025-10-31 20:18:17,666 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'insert-into_default_catalog.default_database.filtered_transactions' (cd26c9845974958140a55e4f03b31f62).
2025-10-31 20:18:17,666 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 20:18:17,667 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [6bce14e4e18e05b18abb18af469b92b9].
2025-10-31 20:18:17,666 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions[1].
2025-10-31 20:18:17,667 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'insert-into_default_catalog.default_database.filtered_transactions' (cd26c9845974958140a55e4f03b31f62).
2025-10-31 20:18:17,667 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'insert-into_default_catalog.default_database.filtered_transactions' (cd26c9845974958140a55e4f03b31f62).
2025-10-31 20:18:17,668 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job cd26c9845974958140a55e4f03b31f62 from the resource manager.
2025-10-31 20:18:17,668 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-5159150177618345690-enumerator-admin-client unregistered
2025-10-31 20:18:17,671 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 20:18:17,671 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 20:18:17,671 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 20:18:17,672 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions[1] closed.
2025-10-31 20:18:17,674 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 6bce14e4e18e05b18abb18af469b92b9.
2025-10-31 20:18:26,924 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (de7cbceea790594c5f46a51ac9c40ea4).
2025-10-31 20:18:26,925 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (de7cbceea790594c5f46a51ac9c40ea4).
2025-10-31 20:18:26,925 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job de7cbceea790594c5f46a51ac9c40ea4 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 20:18:26,928 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_26 .
2025-10-31 20:18:26,928 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (de7cbceea790594c5f46a51ac9c40ea4).
2025-10-31 20:18:26,928 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (de7cbceea790594c5f46a51ac9c40ea4).
2025-10-31 20:18:26,929 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 53fe7b79d707dfe84cd873ffdc72abd4 for job de7cbceea790594c5f46a51ac9c40ea4.
2025-10-31 20:18:26,929 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (de7cbceea790594c5f46a51ac9c40ea4).
2025-10-31 20:18:26,929 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 20:18:26,933 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 20:18:26,933 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@423b5d10
2025-10-31 20:18:26,933 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 20:18:26,933 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 20:18:26,936 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 20:18:26,937 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@27ccc9af for SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (de7cbceea790594c5f46a51ac9c40ea4).
2025-10-31 20:18:26,937 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (de7cbceea790594c5f46a51ac9c40ea4) under job master id 00000000000000000000000000000000.
2025-10-31 20:18:26,937 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions5[71].
2025-10-31 20:18:26,937 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 20:18:26,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (de7cbceea790594c5f46a51ac9c40ea4) switched from state CREATED to RUNNING.
2025-10-31 20:18:26,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[71] -> Sink: Collect table sink (1/1) (53fe7b79d707dfe84cd873ffdc72abd4_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 20:18:26,937 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 20:18:26,938 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource-463432834776350893-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 20:18:26,938 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 20:18:26,938 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_26 for job de7cbceea790594c5f46a51ac9c40ea4.
2025-10-31 20:18:26,938 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_26 for job de7cbceea790594c5f46a51ac9c40ea4.
2025-10-31 20:18:26,939 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 20:18:26,939 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job de7cbceea790594c5f46a51ac9c40ea4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 20:18:26,940 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 20:18:26,940 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 20:18:26,940 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 20:18:26,940 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761922106940
2025-10-31 20:18:26,941 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 20:18:26,949 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-data-0]
2025-10-31 20:18:27,005 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job de7cbceea790594c5f46a51ac9c40ea4
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 20:18:27,006 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot ebc9313f3f61062df128bcbee0d2b5ba from localhost:49385-5990f3 for job de7cbceea790594c5f46a51ac9c40ea4 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 20:18:27,018 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[71] -> Sink: Collect table sink (1/1) (53fe7b79d707dfe84cd873ffdc72abd4_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 20:18:27,020 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions5[71] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 53fe7b79d707dfe84cd873ffdc72abd4_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id ebc9313f3f61062df128bcbee0d2b5ba
2025-10-31 20:18:27,044 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[71] -> Sink: Collect table sink (1/1) (53fe7b79d707dfe84cd873ffdc72abd4_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 20:18:27,051 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:54728
2025-10-31 20:18:27,052 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions5[71] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 20:18:27,052 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-data-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 20:18:27,052 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[71] -> Sink: Collect table sink (1/1) (53fe7b79d707dfe84cd873ffdc72abd4_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 20:18:27,095 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 20:18:31,178 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (de7cbceea790594c5f46a51ac9c40ea4) switched from state RUNNING to CANCELLING.
2025-10-31 20:18:31,180 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[71] -> Sink: Collect table sink (1/1) (53fe7b79d707dfe84cd873ffdc72abd4_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 20:18:31,288 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-10-31 20:18:31,403 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 20:18:31,516 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-10-31 20:18:31,576 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[71] -> Sink: Collect table sink (1/1) (53fe7b79d707dfe84cd873ffdc72abd4_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 20:18:31,577 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5` (de7cbceea790594c5f46a51ac9c40ea4) switched from state CANCELLING to CANCELED.
2025-10-31 20:18:31,577 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job de7cbceea790594c5f46a51ac9c40ea4
2025-10-31 20:18:31,577 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job de7cbceea790594c5f46a51ac9c40ea4.
2025-10-31 20:18:31,578 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job de7cbceea790594c5f46a51ac9c40ea4 reached terminal state CANCELED.
2025-10-31 20:18:31,582 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (de7cbceea790594c5f46a51ac9c40ea4).
2025-10-31 20:18:31,582 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 20:18:31,582 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 20:18:31,582 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [ebc9313f3f61062df128bcbee0d2b5ba].
2025-10-31 20:18:31,582 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (de7cbceea790594c5f46a51ac9c40ea4).
2025-10-31 20:18:31,582 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions5`.`transaction_id`, `transactions5`.`user_id`, `transactions5`.`amount`, `transactions5`.`timestamp`, `transactions5`.`location`
FROM `default_catalog`.`default_database`.`transactions5` AS `transactions5`' (de7cbceea790594c5f46a51ac9c40ea4).
2025-10-31 20:18:31,582 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_26 for job de7cbceea790594c5f46a51ac9c40ea4 from the resource manager.
2025-10-31 20:18:31,582 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions5[71].
2025-10-31 20:18:31,583 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-463432834776350893-enumerator-admin-client unregistered
2025-10-31 20:18:31,584 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot ebc9313f3f61062df128bcbee0d2b5ba.
2025-10-31 20:18:31,585 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 20:18:31,585 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 20:18:31,585 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 20:18:31,586 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions5[71] closed.
2025-10-31 20:20:04,013 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node -1 disconnected.
2025-10-31 20:21:37,522 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.transactions6' (c40fbe729d7c0c3fb42b557f59af4d9b).
2025-10-31 20:21:37,523 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.transactions6' (c40fbe729d7c0c3fb42b557f59af4d9b).
2025-10-31 20:21:37,524 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job c40fbe729d7c0c3fb42b557f59af4d9b was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 20:21:37,528 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_27 .
2025-10-31 20:21:37,529 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.transactions6' (c40fbe729d7c0c3fb42b557f59af4d9b).
2025-10-31 20:21:37,530 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.transactions6 (c40fbe729d7c0c3fb42b557f59af4d9b).
2025-10-31 20:21:37,533 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 3e941875b483426820c557257a6e0ff6 for job c40fbe729d7c0c3fb42b557f59af4d9b.
2025-10-31 20:21:37,533 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.transactions6 (c40fbe729d7c0c3fb42b557f59af4d9b).
2025-10-31 20:21:37,533 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 20:21:37,538 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: transactions5[75] -> Calc[76] -> transactions6[77]: Writer -> transactions6[77]: Committer exceeded the 80 characters length limit and was truncated.
2025-10-31 20:21:37,540 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 20:21:37,540 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@4dd092d0
2025-10-31 20:21:37,540 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 20:21:37,540 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 20:21:37,542 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 20:21:37,543 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@434ac6dd for insert-into_default_catalog.default_database.transactions6 (c40fbe729d7c0c3fb42b557f59af4d9b).
2025-10-31 20:21:37,543 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.transactions6' (c40fbe729d7c0c3fb42b557f59af4d9b) under job master id 00000000000000000000000000000000.
2025-10-31 20:21:37,543 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions5[75].
2025-10-31 20:21:37,543 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 20:21:37,543 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.transactions6 (c40fbe729d7c0c3fb42b557f59af4d9b) switched from state CREATED to RUNNING.
2025-10-31 20:21:37,543 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[75] -> Calc[76] -> transactions6[77]: Writer -> transactions6[77]: Committer (1/1) (3e941875b483426820c557257a6e0ff6_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 20:21:37,544 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 20:21:37,544 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--3209706339673093487-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 20:21:37,544 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 20:21:37,545 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_27 for job c40fbe729d7c0c3fb42b557f59af4d9b.
2025-10-31 20:21:37,545 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_27 for job c40fbe729d7c0c3fb42b557f59af4d9b.
2025-10-31 20:21:37,545 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 20:21:37,545 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, commit.offsets.on.checkpoint, value.deserializer, enable.auto.commit, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 20:21:37,545 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job c40fbe729d7c0c3fb42b557f59af4d9b: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 20:21:37,546 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 20:21:37,546 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 20:21:37,546 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761922297545
2025-10-31 20:21:37,546 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null with partition discovery interval of 300000 ms.
2025-10-31 20:21:37,553 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [transactions-data-0]
2025-10-31 20:21:37,614 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job c40fbe729d7c0c3fb42b557f59af4d9b
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 20:21:37,614 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot f1279a6968c239837f4ad9a3b2970640 from localhost:49385-5990f3 for job c40fbe729d7c0c3fb42b557f59af4d9b with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 20:21:37,653 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[75] -> Calc[76] -> transactions6[77]: Writer -> transactions6[77]: Committer (1/1) (3e941875b483426820c557257a6e0ff6_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 20:21:37,654 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions5[75] -> Calc[76] -> transactions6[77]: Writer -> transactions6[77]: Committer (1/1) (attempt #0) with attempt id 3e941875b483426820c557257a6e0ff6_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id f1279a6968c239837f4ad9a3b2970640
2025-10-31 20:21:37,693 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[75] -> Calc[76] -> transactions6[77]: Writer -> transactions6[77]: Committer (1/1) (3e941875b483426820c557257a6e0ff6_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 20:21:37,735 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions5[75] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 20:21:37,735 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: transactions-data-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 20:21:37,735 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions5[75] -> Calc[76] -> transactions6[77]: Writer -> transactions6[77]: Committer (1/1) (3e941875b483426820c557257a6e0ff6_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 20:21:51,231 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (1db9a8f077e8d481464529051411bc1b).
2025-10-31 20:21:51,232 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (1db9a8f077e8d481464529051411bc1b).
2025-10-31 20:21:51,232 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 1db9a8f077e8d481464529051411bc1b was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 20:21:51,233 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_28 .
2025-10-31 20:21:51,234 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (1db9a8f077e8d481464529051411bc1b).
2025-10-31 20:21:51,234 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (1db9a8f077e8d481464529051411bc1b).
2025-10-31 20:21:51,235 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph fc4cdc115b83071a124fa3a380e47f83 for job 1db9a8f077e8d481464529051411bc1b.
2025-10-31 20:21:51,235 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (1db9a8f077e8d481464529051411bc1b).
2025-10-31 20:21:51,235 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 20:21:51,238 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 20:21:51,238 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@31ff8e38
2025-10-31 20:21:51,238 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 20:21:51,238 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 20:21:51,239 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 20:21:51,239 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@25ebb800 for SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (1db9a8f077e8d481464529051411bc1b).
2025-10-31 20:21:51,239 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (1db9a8f077e8d481464529051411bc1b) under job master id 00000000000000000000000000000000.
2025-10-31 20:21:51,239 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions6[78].
2025-10-31 20:21:51,239 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 20:21:51,239 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (1db9a8f077e8d481464529051411bc1b) switched from state CREATED to RUNNING.
2025-10-31 20:21:51,239 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions6[78] -> Sink: Collect table sink (1/1) (fc4cdc115b83071a124fa3a380e47f83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 20:21:51,239 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = my-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 20:21:51,239 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 20:21:51,240 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 20:21:51,240 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_28 for job 1db9a8f077e8d481464529051411bc1b.
2025-10-31 20:21:51,240 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 20:21:51,240 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 20:21:51,240 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 20:21:51,240 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761922311240
2025-10-31 20:21:51,240 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_28 for job 1db9a8f077e8d481464529051411bc1b.
2025-10-31 20:21:51,240 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group my-group with partition discovery interval of 300000 ms.
2025-10-31 20:21:51,240 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 20:21:51,240 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 1db9a8f077e8d481464529051411bc1b: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 20:21:51,243 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [filtered_transactions-0]
2025-10-31 20:21:51,306 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 1db9a8f077e8d481464529051411bc1b
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=0, taskHeapMemory=2 bytes, taskOffHeapMemory=0 bytes, managedMemory=0 bytes, networkMemory=2 bytes}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 20:21:51,306 WARN  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Could not fulfill resource requirements of job 1db9a8f077e8d481464529051411bc1b.
2025-10-31 20:21:51,306 WARN  org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge [] - Could not acquire the minimum required resources, failing slot requests. Acquired: []. Current slot pool status: Registered TMs: 0, registered slots: 0 free slots: 0
2025-10-31 20:21:51,307 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions6[78] -> Sink: Collect table sink (1/1) (fc4cdc115b83071a124fa3a380e47f83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to FAILED on [unassigned resource].
org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 20:21:51,307 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution fc4cdc115b83071a124fa3a380e47f83_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-10-31 20:21:51,307 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: transactions6[78].
2025-10-31 20:21:51,307 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (1db9a8f077e8d481464529051411bc1b) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 20:21:51,308 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (1db9a8f077e8d481464529051411bc1b) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) ~[?:?]
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226) ~[flink-dist-1.20.2.jar:1.20.2]
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) ~[?:?]
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 20:21:51,308 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 1db9a8f077e8d481464529051411bc1b.
2025-10-31 20:21:51,309 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 1db9a8f077e8d481464529051411bc1b
2025-10-31 20:21:51,309 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 1db9a8f077e8d481464529051411bc1b reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.UpdateSchedulerNgOnInternalFailuresListener.notifyTaskFailure(UpdateSchedulerNgOnInternalFailuresListener.java:51)
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.notifySchedulerNgAboutInternalTaskFailure(DefaultExecutionGraph.java:1665)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1190)
	at org.apache.flink.runtime.executiongraph.Execution.processFail(Execution.java:1130)
	at org.apache.flink.runtime.executiongraph.Execution.markFailed(Execution.java:969)
	at org.apache.flink.runtime.scheduler.DefaultExecutionOperations.markFailed(DefaultExecutionOperations.java:43)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.handleTaskDeploymentFailure(DefaultExecutionDeployer.java:330)
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignAllResourcesAndRegisterProducedPartitions$2(DefaultExecutionDeployer.java:169)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162)
	at org.apache.flink.runtime.jobmaster.slotpool.PendingRequest.failRequest(PendingRequest.java:88)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.cancelPendingRequests(DeclarativeSlotPoolBridge.java:185)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.failPendingRequests(DeclarativeSlotPoolBridge.java:411)
	at org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge.notifyNotEnoughResourcesAvailable(DeclarativeSlotPoolBridge.java:399)
	at org.apache.flink.runtime.jobmaster.JobMaster.notifyNotEnoughResourcesAvailable(JobMaster.java:961)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$0(PekkoRpcActor.java:310)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:309)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at org.apache.flink.runtime.scheduler.DefaultExecutionDeployer.lambda$assignResource$4(DefaultExecutionDeployer.java:226)
	... 40 more
Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636)
	... 38 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
2025-10-31 20:21:51,311 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (1db9a8f077e8d481464529051411bc1b).
2025-10-31 20:21:51,311 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-10-31 20:21:51,311 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 20:21:51,311 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (1db9a8f077e8d481464529051411bc1b).
2025-10-31 20:21:51,311 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions6[78].
2025-10-31 20:21:51,311 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_28 for job 1db9a8f077e8d481464529051411bc1b from the resource manager.
2025-10-31 20:21:51,311 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for my-group-enumerator-admin-client unregistered
2025-10-31 20:21:51,311 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 20:21:51,311 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 20:21:51,311 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 20:21:51,311 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions6[78] closed.
2025-10-31 20:22:17,976 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.transactions3 (8a9e212457525f9c96b11442e31c27ac) switched from state RUNNING to CANCELLING.
2025-10-31 20:22:17,978 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[32] -> Calc[33] -> transactions3[34]: Writer -> transactions3[34]: Committer (1/1) (97c522b1f57dfd1cbb73588b325b2a83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-10-31 20:22:18,506 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions[32] -> Calc[33] -> transactions3[34]: Writer -> transactions3[34]: Committer (1/1) (97c522b1f57dfd1cbb73588b325b2a83_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-10-31 20:22:18,511 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.transactions3 (8a9e212457525f9c96b11442e31c27ac) switched from state CANCELLING to CANCELED.
2025-10-31 20:22:18,511 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 8a9e212457525f9c96b11442e31c27ac.
2025-10-31 20:22:18,511 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 8a9e212457525f9c96b11442e31c27ac
2025-10-31 20:22:18,512 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 8a9e212457525f9c96b11442e31c27ac reached terminal state CANCELED.
2025-10-31 20:22:18,514 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'insert-into_default_catalog.default_database.transactions3' (8a9e212457525f9c96b11442e31c27ac).
2025-10-31 20:22:18,515 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-10-31 20:22:18,515 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [dda87ce59a1038bfb671cacec791828b].
2025-10-31 20:22:18,515 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'insert-into_default_catalog.default_database.transactions3' (8a9e212457525f9c96b11442e31c27ac).
2025-10-31 20:22:18,515 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions[32].
2025-10-31 20:22:18,515 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'insert-into_default_catalog.default_database.transactions3' (8a9e212457525f9c96b11442e31c27ac).
2025-10-31 20:22:18,515 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_12 for job 8a9e212457525f9c96b11442e31c27ac from the resource manager.
2025-10-31 20:22:18,516 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource-6919266241583439448-enumerator-admin-client unregistered
2025-10-31 20:22:18,517 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-10-31 20:22:18,517 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-31 20:22:18,517 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-10-31 20:22:18,517 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions[32] closed.
2025-10-31 20:22:18,518 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot dda87ce59a1038bfb671cacec791828b.
2025-10-31 20:22:23,160 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (17902f11259176e4b0511c4f70e253fe).
2025-10-31 20:22:23,160 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (17902f11259176e4b0511c4f70e253fe).
2025-10-31 20:22:23,162 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 17902f11259176e4b0511c4f70e253fe was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-10-31 20:22:23,168 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_29 .
2025-10-31 20:22:23,168 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (17902f11259176e4b0511c4f70e253fe).
2025-10-31 20:22:23,169 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (17902f11259176e4b0511c4f70e253fe).
2025-10-31 20:22:23,169 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 491e190e930d40469fd602309b3e5d88 for job 17902f11259176e4b0511c4f70e253fe.
2025-10-31 20:22:23,169 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (17902f11259176e4b0511c4f70e253fe).
2025-10-31 20:22:23,169 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-10-31 20:22:23,171 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-10-31 20:22:23,171 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@222efa5
2025-10-31 20:22:23,171 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-10-31 20:22:23,171 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-10-31 20:22:23,171 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-10-31 20:22:23,171 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@399e6d23 for SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (17902f11259176e4b0511c4f70e253fe).
2025-10-31 20:22:23,171 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (17902f11259176e4b0511c4f70e253fe) under job master id 00000000000000000000000000000000.
2025-10-31 20:22:23,171 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: transactions6[80].
2025-10-31 20:22:23,172 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-10-31 20:22:23,172 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (17902f11259176e4b0511c4f70e253fe) switched from state CREATED to RUNNING.
2025-10-31 20:22:23,172 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions6[80] -> Sink: Collect table sink (1/1) (491e190e930d40469fd602309b3e5d88_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-10-31 20:22:23,172 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-10-31 20:22:23,172 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = my-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-31 20:22:23,172 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-10-31 20:22:23,172 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_29 for job 17902f11259176e4b0511c4f70e253fe.
2025-10-31 20:22:23,173 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-10-31 20:22:23,173 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_29 for job 17902f11259176e4b0511c4f70e253fe.
2025-10-31 20:22:23,173 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-10-31 20:22:23,173 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-10-31 20:22:23,173 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1761922343173
2025-10-31 20:22:23,173 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-10-31 20:22:23,173 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group my-group with partition discovery interval of 300000 ms.
2025-10-31 20:22:23,173 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 17902f11259176e4b0511c4f70e253fe: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-10-31 20:22:23,178 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [filtered_transactions-0]
2025-10-31 20:22:23,236 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 17902f11259176e4b0511c4f70e253fe
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-10-31 20:22:23,236 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot c25a200ae27267e4f061c895827040dd from localhost:49385-5990f3 for job 17902f11259176e4b0511c4f70e253fe with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-10-31 20:22:23,247 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions6[80] -> Sink: Collect table sink (1/1) (491e190e930d40469fd602309b3e5d88_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-10-31 20:22:23,249 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: transactions6[80] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 491e190e930d40469fd602309b3e5d88_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:49385-5990f3 @ localhost (dataPort=49387) with allocation id c25a200ae27267e4f061c895827040dd
2025-10-31 20:22:23,266 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions6[80] -> Sink: Collect table sink (1/1) (491e190e930d40469fd602309b3e5d88_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-10-31 20:22:23,275 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:53209
2025-10-31 20:22:23,276 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: transactions6[80] registering reader for parallel task 0 (#0) @ localhost
2025-10-31 20:22:23,276 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions6[80] -> Sink: Collect table sink (1/1) (491e190e930d40469fd602309b3e5d88_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-10-31 20:22:23,276 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: filtered_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-10-31 20:22:23,345 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-10-31 20:37:55,346 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node -1 disconnected.
2025-10-31 20:38:40,960 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=my-group-enumerator-admin-client] Node -1 disconnected.
2025-10-31 20:41:22,108 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-10-31 20:43:30,575 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-31 22:02:21,253 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-10-31 23:32:56,545 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-10-31 23:33:06,960 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=my-group-enumerator-admin-client] Node 1 disconnected.
2025-10-31 23:42:27,967 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-10-31 23:43:13,575 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=my-group-enumerator-admin-client] Node 1 disconnected.
2025-10-31 23:45:54,333 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-01 10:06:11,124 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=my-group-enumerator-admin-client] Node 1 disconnected.
2025-11-01 10:20:25,872 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-01 13:09:10,813 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-01 13:31:27,558 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-01 14:11:31,586 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-01 14:15:56,405 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-01 16:38:11,252 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-01 16:44:01,207 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (17902f11259176e4b0511c4f70e253fe) switched from state RUNNING to CANCELLING.
2025-11-01 16:44:01,239 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions6[80] -> Sink: Collect table sink (1/1) (491e190e930d40469fd602309b3e5d88_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-01 16:44:01,583 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.io.EOFException
2025-11-01 16:44:01,709 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-01 16:44:01,817 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-01 16:44:01,929 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-01 16:44:02,040 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-01 16:44:02,081 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: transactions6[80] -> Sink: Collect table sink (1/1) (491e190e930d40469fd602309b3e5d88_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-01 16:44:02,098 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6` (17902f11259176e4b0511c4f70e253fe) switched from state CANCELLING to CANCELED.
2025-11-01 16:44:02,100 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 17902f11259176e4b0511c4f70e253fe.
2025-11-01 16:44:02,101 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 17902f11259176e4b0511c4f70e253fe
2025-11-01 16:44:02,143 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 17902f11259176e4b0511c4f70e253fe reached terminal state CANCELED.
2025-11-01 16:44:02,179 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (17902f11259176e4b0511c4f70e253fe).
2025-11-01 16:44:02,207 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-01 16:44:02,213 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-01 16:44:02,209 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: transactions6[80].
2025-11-01 16:44:02,217 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [c25a200ae27267e4f061c895827040dd].
2025-11-01 16:44:02,228 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:49385-5990f3 because: Stopping JobMaster for job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (17902f11259176e4b0511c4f70e253fe).
2025-11-01 16:44:02,228 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `transactions6`.`transaction_id`, `transactions6`.`user_id`, `transactions6`.`amount`, `transactions6`.`timestamp`, `transactions6`.`location`
FROM `default_catalog`.`default_database`.`transactions6` AS `transactions6`' (17902f11259176e4b0511c4f70e253fe).
2025-11-01 16:44:02,234 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_29 for job 17902f11259176e4b0511c4f70e253fe from the resource manager.
2025-11-01 16:44:02,246 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for my-group-enumerator-admin-client unregistered
2025-11-01 16:44:02,253 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-01 16:44:02,253 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-01 16:44:02,253 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-01 16:44:02,254 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: transactions6[80] closed.
2025-11-01 16:44:02,263 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot c25a200ae27267e4f061c895827040dd.
2025-11-01 21:37:14,699 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-02 00:29:40,547 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering TaskManager with ResourceID localhost:51348-d4ad3a (pekko.tcp://flink@localhost:51348/user/rpc/taskmanager_0) at ResourceManager
2025-11-02 00:29:40,562 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Registering task executor localhost:51348-d4ad3a under 8a07df4e731a90caf531e86218acbbf1 at the slot manager.
2025-11-02 11:29:26,108 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-02 11:32:15,195 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (c13da4a33490c38710720944674ae2e0).
2025-11-02 11:32:15,199 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (c13da4a33490c38710720944674ae2e0).
2025-11-02 11:32:15,211 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job c13da4a33490c38710720944674ae2e0 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 11:32:15,241 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_30 .
2025-11-02 11:32:15,243 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (c13da4a33490c38710720944674ae2e0).
2025-11-02 11:32:15,254 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (c13da4a33490c38710720944674ae2e0).
2025-11-02 11:32:15,261 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 0d30ec9c724bf40cac2ba44a41f017f8 for job c13da4a33490c38710720944674ae2e0.
2025-11-02 11:32:15,267 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (c13da4a33490c38710720944674ae2e0).
2025-11-02 11:32:15,267 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 11:32:15,307 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 11:32:15,307 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@26baaec6
2025-11-02 11:32:15,307 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 11:32:15,308 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 11:32:15,316 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 11:32:15,316 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@3b9d9e5a for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (c13da4a33490c38710720944674ae2e0).
2025-11-02 11:32:15,319 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (c13da4a33490c38710720944674ae2e0) under job master id 00000000000000000000000000000000.
2025-11-02 11:32:15,319 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Transactions[4].
2025-11-02 11:32:15,320 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 11:32:15,321 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (c13da4a33490c38710720944674ae2e0) switched from state CREATED to RUNNING.
2025-11-02 11:32:15,321 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[4] -> Sink: Collect table sink (1/1) (0d30ec9c724bf40cac2ba44a41f017f8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 11:32:15,323 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 11:32:15,324 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 11:32:15,326 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 11:32:15,326 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_30 for job c13da4a33490c38710720944674ae2e0.
2025-11-02 11:32:15,327 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_30 for job c13da4a33490c38710720944674ae2e0.
2025-11-02 11:32:15,329 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 11:32:15,329 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job c13da4a33490c38710720944674ae2e0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 11:32:15,334 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 11:32:15,335 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 11:32:15,335 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 11:32:15,335 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762063335334
2025-11-02 11:32:15,336 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 11:32:15,351 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 11:32:15,401 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job c13da4a33490c38710720944674ae2e0
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 11:32:15,404 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 4ac8a87d0a0f8feb34ef4f5cc35d831b from localhost:51348-d4ad3a for job c13da4a33490c38710720944674ae2e0 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 11:32:15,531 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[4] -> Sink: Collect table sink (1/1) (0d30ec9c724bf40cac2ba44a41f017f8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 11:32:15,533 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Transactions[4] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 0d30ec9c724bf40cac2ba44a41f017f8_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51348-d4ad3a @ localhost (dataPort=51350) with allocation id 4ac8a87d0a0f8feb34ef4f5cc35d831b
2025-11-02 11:32:15,658 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[4] -> Sink: Collect table sink (1/1) (0d30ec9c724bf40cac2ba44a41f017f8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 11:32:15,875 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:53644
2025-11-02 11:32:15,876 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Transactions[4] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 11:32:15,876 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]}
2025-11-02 11:32:15,882 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[4] -> Sink: Collect table sink (1/1) (0d30ec9c724bf40cac2ba44a41f017f8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 11:32:15,893 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 11:32:16,194 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[4] -> Sink: Collect table sink (1/1) (0d30ec9c724bf40cac2ba44a41f017f8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED on localhost:51348-d4ad3a @ localhost (dataPort=51350).
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-02 11:32:16,275 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job c13da4a33490c38710720944674ae2e0
2025-11-02 11:32:16,276 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: Transactions[4].
2025-11-02 11:32:16,277 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (c13da4a33490c38710720944674ae2e0) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor76.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-02 11:32:16,284 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (c13da4a33490c38710720944674ae2e0) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor76.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-02 11:32:16,284 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job c13da4a33490c38710720944674ae2e0.
2025-11-02 11:32:16,290 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job c13da4a33490c38710720944674ae2e0 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515)
	at jdk.internal.reflect.GeneratedMethodAccessor76.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224)
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165)
	... 6 more
2025-11-02 11:32:16,296 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (c13da4a33490c38710720944674ae2e0).
2025-11-02 11:32:16,296 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 11:32:16,296 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 11:32:16,296 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Transactions[4].
2025-11-02 11:32:16,296 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [4ac8a87d0a0f8feb34ef4f5cc35d831b].
2025-11-02 11:32:16,296 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51348-d4ad3a because: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (c13da4a33490c38710720944674ae2e0).
2025-11-02 11:32:16,296 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (c13da4a33490c38710720944674ae2e0).
2025-11-02 11:32:16,296 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 11:32:16,297 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_30 for job c13da4a33490c38710720944674ae2e0 from the resource manager.
2025-11-02 11:32:16,301 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 11:32:16,301 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 11:32:16,301 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 11:32:16,301 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Transactions[4] closed.
2025-11-02 11:32:16,302 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 4ac8a87d0a0f8feb34ef4f5cc35d831b.
2025-11-02 11:32:29,599 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (31578cbeb85d8874b1327edfdba9ec26).
2025-11-02 11:32:29,600 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (31578cbeb85d8874b1327edfdba9ec26).
2025-11-02 11:32:29,601 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 31578cbeb85d8874b1327edfdba9ec26 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 11:32:29,604 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_31 .
2025-11-02 11:32:29,604 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (31578cbeb85d8874b1327edfdba9ec26).
2025-11-02 11:32:29,605 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (31578cbeb85d8874b1327edfdba9ec26).
2025-11-02 11:32:29,606 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph ce7715f0576ba62c2e809813579a27b1 for job 31578cbeb85d8874b1327edfdba9ec26.
2025-11-02 11:32:29,606 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (31578cbeb85d8874b1327edfdba9ec26).
2025-11-02 11:32:29,607 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 11:32:29,614 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 11:32:29,614 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@18ce1f7a
2025-11-02 11:32:29,614 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 11:32:29,614 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 11:32:29,617 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 11:32:29,617 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@17b96d51 for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (31578cbeb85d8874b1327edfdba9ec26).
2025-11-02 11:32:29,617 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (31578cbeb85d8874b1327edfdba9ec26) under job master id 00000000000000000000000000000000.
2025-11-02 11:32:29,617 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Transactions[6].
2025-11-02 11:32:29,617 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 11:32:29,617 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (31578cbeb85d8874b1327edfdba9ec26) switched from state CREATED to RUNNING.
2025-11-02 11:32:29,618 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[6] -> Sink: Collect table sink (1/1) (ce7715f0576ba62c2e809813579a27b1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 11:32:29,618 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 11:32:29,618 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 11:32:29,619 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 11:32:29,619 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_31 for job 31578cbeb85d8874b1327edfdba9ec26.
2025-11-02 11:32:29,619 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_31 for job 31578cbeb85d8874b1327edfdba9ec26.
2025-11-02 11:32:29,620 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 11:32:29,620 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 31578cbeb85d8874b1327edfdba9ec26: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 11:32:29,621 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 11:32:29,621 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 11:32:29,621 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 11:32:29,621 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762063349621
2025-11-02 11:32:29,621 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 11:32:29,628 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 11:32:29,687 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 31578cbeb85d8874b1327edfdba9ec26
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 11:32:29,688 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 8a306d788132e03c9e945f779aa650fb from localhost:51348-d4ad3a for job 31578cbeb85d8874b1327edfdba9ec26 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 11:32:29,705 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[6] -> Sink: Collect table sink (1/1) (ce7715f0576ba62c2e809813579a27b1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 11:32:29,705 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Transactions[6] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id ce7715f0576ba62c2e809813579a27b1_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51348-d4ad3a @ localhost (dataPort=51350) with allocation id 8a306d788132e03c9e945f779aa650fb
2025-11-02 11:32:29,726 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[6] -> Sink: Collect table sink (1/1) (ce7715f0576ba62c2e809813579a27b1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 11:32:29,732 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:55011
2025-11-02 11:32:29,733 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Transactions[6] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 11:32:29,733 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]}
2025-11-02 11:32:29,733 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[6] -> Sink: Collect table sink (1/1) (ce7715f0576ba62c2e809813579a27b1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 11:32:29,758 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[6] -> Sink: Collect table sink (1/1) (ce7715f0576ba62c2e809813579a27b1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED on localhost:51348-d4ad3a @ localhost (dataPort=51350).
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-02 11:32:29,762 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 31578cbeb85d8874b1327edfdba9ec26
2025-11-02 11:32:29,763 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: Transactions[6].
2025-11-02 11:32:29,763 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (31578cbeb85d8874b1327edfdba9ec26) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor76.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-02 11:32:29,766 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (31578cbeb85d8874b1327edfdba9ec26) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor76.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-02 11:32:29,766 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 31578cbeb85d8874b1327edfdba9ec26.
2025-11-02 11:32:29,771 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 31578cbeb85d8874b1327edfdba9ec26 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515)
	at jdk.internal.reflect.GeneratedMethodAccessor76.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224)
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165)
	... 6 more
2025-11-02 11:32:29,775 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (31578cbeb85d8874b1327edfdba9ec26).
2025-11-02 11:32:29,776 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 11:32:29,776 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 11:32:29,776 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [8a306d788132e03c9e945f779aa650fb].
2025-11-02 11:32:29,776 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51348-d4ad3a because: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (31578cbeb85d8874b1327edfdba9ec26).
2025-11-02 11:32:29,776 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (31578cbeb85d8874b1327edfdba9ec26).
2025-11-02 11:32:29,776 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Transactions[6].
2025-11-02 11:32:29,776 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_31 for job 31578cbeb85d8874b1327edfdba9ec26 from the resource manager.
2025-11-02 11:32:29,777 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 11:32:29,779 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 11:32:29,779 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 11:32:29,779 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 11:32:29,779 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Transactions[6] closed.
2025-11-02 11:32:29,780 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 8a306d788132e03c9e945f779aa650fb.
2025-11-02 11:33:26,067 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (f4a317a3b14bb5e2fcc17beabecf3d59).
2025-11-02 11:33:26,068 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (f4a317a3b14bb5e2fcc17beabecf3d59).
2025-11-02 11:33:26,069 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job f4a317a3b14bb5e2fcc17beabecf3d59 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 11:33:26,072 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_32 .
2025-11-02 11:33:26,072 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (f4a317a3b14bb5e2fcc17beabecf3d59).
2025-11-02 11:33:26,073 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (f4a317a3b14bb5e2fcc17beabecf3d59).
2025-11-02 11:33:26,074 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 035a3a51559742efc96d682fff28bb41 for job f4a317a3b14bb5e2fcc17beabecf3d59.
2025-11-02 11:33:26,074 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (f4a317a3b14bb5e2fcc17beabecf3d59).
2025-11-02 11:33:26,074 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 11:33:26,079 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 11:33:26,079 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@491f1ab4
2025-11-02 11:33:26,079 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 11:33:26,079 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 11:33:26,082 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 11:33:26,082 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@73c4b99e for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (f4a317a3b14bb5e2fcc17beabecf3d59).
2025-11-02 11:33:26,083 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (f4a317a3b14bb5e2fcc17beabecf3d59) under job master id 00000000000000000000000000000000.
2025-11-02 11:33:26,083 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Transactions[8].
2025-11-02 11:33:26,083 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 11:33:26,083 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (f4a317a3b14bb5e2fcc17beabecf3d59) switched from state CREATED to RUNNING.
2025-11-02 11:33:26,083 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[8] -> Sink: Collect table sink (1/1) (035a3a51559742efc96d682fff28bb41_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 11:33:26,083 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 11:33:26,084 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 11:33:26,085 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 11:33:26,085 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_32 for job f4a317a3b14bb5e2fcc17beabecf3d59.
2025-11-02 11:33:26,086 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_32 for job f4a317a3b14bb5e2fcc17beabecf3d59.
2025-11-02 11:33:26,087 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 11:33:26,087 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 11:33:26,087 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job f4a317a3b14bb5e2fcc17beabecf3d59: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 11:33:26,087 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 11:33:26,087 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 11:33:26,087 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762063406087
2025-11-02 11:33:26,087 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 11:33:26,158 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job f4a317a3b14bb5e2fcc17beabecf3d59
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 11:33:26,158 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 2039afcc4a73957abbf397c9990fa931 from localhost:51348-d4ad3a for job f4a317a3b14bb5e2fcc17beabecf3d59 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 11:33:26,174 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[8] -> Sink: Collect table sink (1/1) (035a3a51559742efc96d682fff28bb41_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 11:33:26,177 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Transactions[8] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 035a3a51559742efc96d682fff28bb41_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51348-d4ad3a @ localhost (dataPort=51350) with allocation id 2039afcc4a73957abbf397c9990fa931
2025-11-02 11:33:26,196 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[8] -> Sink: Collect table sink (1/1) (035a3a51559742efc96d682fff28bb41_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 11:33:26,206 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:55120
2025-11-02 11:33:26,207 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Transactions[8] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 11:33:26,207 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[8] -> Sink: Collect table sink (1/1) (035a3a51559742efc96d682fff28bb41_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 11:33:26,232 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: Transactions[8]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [llm_t].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:65) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	... 3 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[?:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:62) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	... 3 more
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2025-11-02 11:33:26,242 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: Transactions[8] -> Sink: Collect table sink' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:651) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:259) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:432) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:445) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [llm_t].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:65) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	... 3 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[?:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:62) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	... 3 more
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2025-11-02 11:33:26,245 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (f4a317a3b14bb5e2fcc17beabecf3d59) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:140) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:324) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:669) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRunAsync$4(PekkoRpcActor.java:460) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRunAsync(PekkoRpcActor.java:460) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:225) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: Transactions[8] -> Sink: Collect table sink' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:651) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:259) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:432) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:445) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [llm_t].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:65) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[?:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:62) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2025-11-02 11:33:26,250 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[8] -> Sink: Collect table sink (1/1) (035a3a51559742efc96d682fff28bb41_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 11:33:26,256 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 11:33:26,257 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[8] -> Sink: Collect table sink (1/1) (035a3a51559742efc96d682fff28bb41_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 11:33:26,258 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job f4a317a3b14bb5e2fcc17beabecf3d59
2025-11-02 11:33:26,258 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (f4a317a3b14bb5e2fcc17beabecf3d59) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:140) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:324) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:669) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRunAsync$4(PekkoRpcActor.java:460) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRunAsync(PekkoRpcActor.java:460) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:225) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: Transactions[8] -> Sink: Collect table sink' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:651) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:259) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:432) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:445) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [llm_t].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:65) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[?:?]
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[?:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:62) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:56) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2025-11-02 11:33:26,258 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job f4a317a3b14bb5e2fcc17beabecf3d59.
2025-11-02 11:33:26,263 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job f4a317a3b14bb5e2fcc17beabecf3d59 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:140)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:324)
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:669)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRunAsync$4(PekkoRpcActor.java:460)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRunAsync(PekkoRpcActor.java:460)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:225)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: Transactions[8] -> Sink: Collect table sink' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:651)
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:259)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:432)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:445)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248)
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [llm_t].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:65)
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:56)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233)
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	... 3 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:62)
	... 9 more
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2025-11-02 11:33:26,265 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (f4a317a3b14bb5e2fcc17beabecf3d59).
2025-11-02 11:33:26,266 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 11:33:26,266 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 11:33:26,266 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [2039afcc4a73957abbf397c9990fa931].
2025-11-02 11:33:26,266 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51348-d4ad3a because: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (f4a317a3b14bb5e2fcc17beabecf3d59).
2025-11-02 11:33:26,266 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (f4a317a3b14bb5e2fcc17beabecf3d59).
2025-11-02 11:33:26,266 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_32 for job f4a317a3b14bb5e2fcc17beabecf3d59 from the resource manager.
2025-11-02 11:33:26,266 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Transactions[8].
2025-11-02 11:33:26,267 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 11:33:26,270 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 11:33:26,270 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 11:33:26,270 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 11:33:26,270 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 2039afcc4a73957abbf397c9990fa931.
2025-11-02 11:33:26,270 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Transactions[8] closed.
2025-11-02 11:39:56,496 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (54dfefd1d4a0277ba760e09218d99481).
2025-11-02 11:39:56,497 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (54dfefd1d4a0277ba760e09218d99481).
2025-11-02 11:39:56,498 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 54dfefd1d4a0277ba760e09218d99481 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 11:39:56,505 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_33 .
2025-11-02 11:39:56,505 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (54dfefd1d4a0277ba760e09218d99481).
2025-11-02 11:39:56,506 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (54dfefd1d4a0277ba760e09218d99481).
2025-11-02 11:39:56,507 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 6f19c30ad624d7ae87d5364893e0ba74 for job 54dfefd1d4a0277ba760e09218d99481.
2025-11-02 11:39:56,508 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (54dfefd1d4a0277ba760e09218d99481).
2025-11-02 11:39:56,508 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 11:39:56,512 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 11:39:56,512 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1ef8a3b6
2025-11-02 11:39:56,512 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 11:39:56,512 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 11:39:56,515 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 11:39:56,516 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@536e79bc for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (54dfefd1d4a0277ba760e09218d99481).
2025-11-02 11:39:56,516 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (54dfefd1d4a0277ba760e09218d99481) under job master id 00000000000000000000000000000000.
2025-11-02 11:39:56,516 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Transactions[10].
2025-11-02 11:39:56,516 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 11:39:56,516 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (54dfefd1d4a0277ba760e09218d99481) switched from state CREATED to RUNNING.
2025-11-02 11:39:56,516 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[10] -> Sink: Collect table sink (1/1) (6f19c30ad624d7ae87d5364893e0ba74_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 11:39:56,517 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 11:39:56,517 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 11:39:56,519 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 11:39:56,519 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_33 for job 54dfefd1d4a0277ba760e09218d99481.
2025-11-02 11:39:56,520 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_33 for job 54dfefd1d4a0277ba760e09218d99481.
2025-11-02 11:39:56,520 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 11:39:56,521 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 54dfefd1d4a0277ba760e09218d99481: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 11:39:56,522 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 11:39:56,522 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 11:39:56,522 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 11:39:56,522 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762063796522
2025-11-02 11:39:56,522 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 11:39:56,538 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 11:39:56,585 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 54dfefd1d4a0277ba760e09218d99481
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 11:39:56,585 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot f711d4e31e5aa3775025d7f0c87fbf92 from localhost:51348-d4ad3a for job 54dfefd1d4a0277ba760e09218d99481 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 11:39:56,601 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[10] -> Sink: Collect table sink (1/1) (6f19c30ad624d7ae87d5364893e0ba74_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 11:39:56,604 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Transactions[10] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 6f19c30ad624d7ae87d5364893e0ba74_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51348-d4ad3a @ localhost (dataPort=51350) with allocation id f711d4e31e5aa3775025d7f0c87fbf92
2025-11-02 11:39:56,628 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[10] -> Sink: Collect table sink (1/1) (6f19c30ad624d7ae87d5364893e0ba74_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 11:39:56,634 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:56233
2025-11-02 11:39:56,635 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Transactions[10] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 11:39:56,635 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-02 11:39:56,637 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[10] -> Sink: Collect table sink (1/1) (6f19c30ad624d7ae87d5364893e0ba74_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 11:39:56,673 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 11:40:01,274 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (54dfefd1d4a0277ba760e09218d99481) switched from state RUNNING to CANCELLING.
2025-11-02 11:40:01,276 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[10] -> Sink: Collect table sink (1/1) (6f19c30ad624d7ae87d5364893e0ba74_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 11:40:01,373 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Connection reset by peer
2025-11-02 11:40:01,485 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 11:40:01,599 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 11:40:01,699 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[10] -> Sink: Collect table sink (1/1) (6f19c30ad624d7ae87d5364893e0ba74_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 11:40:01,702 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (54dfefd1d4a0277ba760e09218d99481) switched from state CANCELLING to CANCELED.
2025-11-02 11:40:01,702 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 54dfefd1d4a0277ba760e09218d99481.
2025-11-02 11:40:01,702 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 54dfefd1d4a0277ba760e09218d99481
2025-11-02 11:40:01,706 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 54dfefd1d4a0277ba760e09218d99481 reached terminal state CANCELED.
2025-11-02 11:40:01,709 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (54dfefd1d4a0277ba760e09218d99481).
2025-11-02 11:40:01,711 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 11:40:01,711 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 11:40:01,711 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [f711d4e31e5aa3775025d7f0c87fbf92].
2025-11-02 11:40:01,711 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51348-d4ad3a because: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (54dfefd1d4a0277ba760e09218d99481).
2025-11-02 11:40:01,711 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Transactions[10].
2025-11-02 11:40:01,712 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IP Address`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (54dfefd1d4a0277ba760e09218d99481).
2025-11-02 11:40:01,712 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_33 for job 54dfefd1d4a0277ba760e09218d99481 from the resource manager.
2025-11-02 11:40:01,713 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 11:40:01,714 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot f711d4e31e5aa3775025d7f0c87fbf92.
2025-11-02 11:40:01,718 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 11:40:01,718 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 11:40:01,718 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 11:40:01,718 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Transactions[10] closed.
2025-11-02 12:17:34,773 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.fraud_alerts' (2854d4faae20780ed30e4759f1ad7d68).
2025-11-02 12:17:34,776 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.fraud_alerts' (2854d4faae20780ed30e4759f1ad7d68).
2025-11-02 12:17:34,780 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 2854d4faae20780ed30e4759f1ad7d68 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 12:17:34,791 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_34 .
2025-11-02 12:17:34,792 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.fraud_alerts' (2854d4faae20780ed30e4759f1ad7d68).
2025-11-02 12:17:34,794 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.fraud_alerts (2854d4faae20780ed30e4759f1ad7d68).
2025-11-02 12:17:34,796 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 63bbf80c304e9595965edd4f6c800709 for job 2854d4faae20780ed30e4759f1ad7d68.
2025-11-02 12:17:34,798 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.fraud_alerts (2854d4faae20780ed30e4759f1ad7d68).
2025-11-02 12:17:34,798 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 12:17:34,844 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 12:17:34,844 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@4ef17767
2025-11-02 12:17:34,844 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 12:17:34,844 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 12:17:34,851 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 12:17:34,851 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@4df17a1d for insert-into_default_catalog.default_database.fraud_alerts (2854d4faae20780ed30e4759f1ad7d68).
2025-11-02 12:17:34,852 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.fraud_alerts' (2854d4faae20780ed30e4759f1ad7d68) under job master id 00000000000000000000000000000000.
2025-11-02 12:17:34,852 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[12].
2025-11-02 12:17:34,853 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 12:17:34,853 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.fraud_alerts (2854d4faae20780ed30e4759f1ad7d68) switched from state CREATED to RUNNING.
2025-11-02 12:17:34,853 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[12] -> Calc[13] (1/1) (63bbf80c304e9595965edd4f6c800709_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 12:17:34,853 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[15] -> Calc[16] -> fraud_alerts[17]: Writer -> fraud_alerts[17]: Committer (1/1) (63bbf80c304e9595965edd4f6c800709_90bea66de1c231edf33913ecd54406c1_0_0) switched from CREATED to SCHEDULED.
2025-11-02 12:17:34,854 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [your-kafka-broker:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--2679653599669833098-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 12:17:34,855 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 12:17:34,857 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 12:17:34,857 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_34 for job 2854d4faae20780ed30e4759f1ad7d68.
2025-11-02 12:17:34,858 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_34 for job 2854d4faae20780ed30e4759f1ad7d68.
2025-11-02 12:17:34,859 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 12:17:34,859 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 2854d4faae20780ed30e4759f1ad7d68: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 12:17:34,928 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 2854d4faae20780ed30e4759f1ad7d68
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 12:17:34,928 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot f5136b69ef5ebaffbd1f9a8641add14d from localhost:51348-d4ad3a for job 2854d4faae20780ed30e4759f1ad7d68 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 12:17:34,975 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[12] -> Calc[13] (1/1) (63bbf80c304e9595965edd4f6c800709_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 12:17:34,977 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[12] -> Calc[13] (1/1) (attempt #0) with attempt id 63bbf80c304e9595965edd4f6c800709_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51348-d4ad3a @ localhost (dataPort=51350) with allocation id f5136b69ef5ebaffbd1f9a8641add14d
2025-11-02 12:17:34,980 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[15] -> Calc[16] -> fraud_alerts[17]: Writer -> fraud_alerts[17]: Committer (1/1) (63bbf80c304e9595965edd4f6c800709_90bea66de1c231edf33913ecd54406c1_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 12:17:34,980 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying GroupWindowAggregate[15] -> Calc[16] -> fraud_alerts[17]: Writer -> fraud_alerts[17]: Committer (1/1) (attempt #0) with attempt id 63bbf80c304e9595965edd4f6c800709_90bea66de1c231edf33913ecd54406c1_0_0 and vertex id 90bea66de1c231edf33913ecd54406c1_0 to localhost:51348-d4ad3a @ localhost (dataPort=51350) with allocation id f5136b69ef5ebaffbd1f9a8641add14d
2025-11-02 12:17:35,015 WARN  org.apache.kafka.clients.ClientUtils                         [] - Couldn't resolve server your-kafka-broker:9092 from bootstrap.servers as DNS resolution failed for your-kafka-broker
2025-11-02 12:17:35,016 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Uncaught exception in the SplitEnumerator for Source Source: bank_transactions[12] while starting the SplitEnumerator.. Triggering job failover.
org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:519) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:474) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:241) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:530) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:101) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:60) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:56) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:492) ~[kafka-clients-3.6.0.jar:?]
	... 14 more
2025-11-02 12:17:35,024 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: bank_transactions[12] -> Calc[13]' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:651) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:259) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:432) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:544) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:519) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:474) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:241) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:530) ~[flink-dist-1.20.2.jar:1.20.2]
	... 7 more
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:101) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:60) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:56) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:492) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:474) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:241) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:530) ~[flink-dist-1.20.2.jar:1.20.2]
	... 7 more
2025-11-02 12:17:35,025 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.fraud_alerts (2854d4faae20780ed30e4759f1ad7d68) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:140) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:324) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:669) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRunAsync$4(PekkoRpcActor.java:460) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRunAsync(PekkoRpcActor.java:460) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:225) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: bank_transactions[12] -> Calc[13]' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:651) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:259) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:432) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:544) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:519) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:474) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:241) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:530) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:101) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:60) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:56) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:492) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:474) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:241) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:530) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-02 12:17:35,028 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[12] -> Calc[13] (1/1) (63bbf80c304e9595965edd4f6c800709_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to CANCELING.
2025-11-02 12:17:35,028 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[15] -> Calc[16] -> fraud_alerts[17]: Writer -> fraud_alerts[17]: Committer (1/1) (63bbf80c304e9595965edd4f6c800709_90bea66de1c231edf33913ecd54406c1_0_0) switched from DEPLOYING to CANCELING.
2025-11-02 12:17:35,139 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[15] -> Calc[16] -> fraud_alerts[17]: Writer -> fraud_alerts[17]: Committer (1/1) (63bbf80c304e9595965edd4f6c800709_90bea66de1c231edf33913ecd54406c1_0_0) switched from CANCELING to CANCELED.
2025-11-02 12:17:35,160 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[12] -> Calc[13] (1/1) (63bbf80c304e9595965edd4f6c800709_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 12:17:35,161 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 2854d4faae20780ed30e4759f1ad7d68
2025-11-02 12:17:35,160 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.fraud_alerts (2854d4faae20780ed30e4759f1ad7d68) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:140) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:324) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:669) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRunAsync$4(PekkoRpcActor.java:460) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRunAsync(PekkoRpcActor.java:460) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:225) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: bank_transactions[12] -> Calc[13]' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:651) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:259) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:432) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:544) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:519) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:474) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:241) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:530) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:101) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:60) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:56) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:492) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:474) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:241) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:530) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-02 12:17:35,161 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 2854d4faae20780ed30e4759f1ad7d68.
2025-11-02 12:17:35,164 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 2854d4faae20780ed30e4759f1ad7d68 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:140)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:324)
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:669)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRunAsync$4(PekkoRpcActor.java:460)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRunAsync(PekkoRpcActor.java:460)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:225)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: bank_transactions[12] -> Calc[13]' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:651)
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:259)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:432)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:544)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:519)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:474)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:241)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:530)
	... 7 more
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:101)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:60)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:56)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:492)
	... 14 more
2025-11-02 12:17:35,168 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'insert-into_default_catalog.default_database.fraud_alerts' (2854d4faae20780ed30e4759f1ad7d68).
2025-11-02 12:17:35,169 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 12:17:35,169 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [f5136b69ef5ebaffbd1f9a8641add14d].
2025-11-02 12:17:35,169 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51348-d4ad3a because: Stopping JobMaster for job 'insert-into_default_catalog.default_database.fraud_alerts' (2854d4faae20780ed30e4759f1ad7d68).
2025-11-02 12:17:35,169 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'insert-into_default_catalog.default_database.fraud_alerts' (2854d4faae20780ed30e4759f1ad7d68).
2025-11-02 12:17:35,169 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_34 for job 2854d4faae20780ed30e4759f1ad7d68 from the resource manager.
2025-11-02 12:17:35,170 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[12].
2025-11-02 12:17:35,171 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[12] closed.
2025-11-02 12:17:35,173 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot f5136b69ef5ebaffbd1f9a8641add14d.
2025-11-02 12:43:19,181 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering TaskManager with ResourceID localhost:51798-3c06be (pekko.tcp://flink@localhost:51798/user/rpc/taskmanager_0) at ResourceManager
2025-11-02 12:43:19,199 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Registering task executor localhost:51798-3c06be under 64b6099e851d175858a7a51a969eedfb at the slot manager.
2025-11-02 12:53:31,724 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:31,726 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:31,730 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 80f504723ff184ba0643ea886ce901d6 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 12:53:31,739 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_35 .
2025-11-02 12:53:31,743 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:31,747 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:31,751 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 7b25c827e676b51de3655bfc6f1064cf for job 80f504723ff184ba0643ea886ce901d6.
2025-11-02 12:53:31,752 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:31,752 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 12:53:31,764 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 12:53:31,765 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3c8658fa
2025-11-02 12:53:31,765 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 12:53:31,765 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 12:53:31,771 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 12:53:31,771 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@652d6726 for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:31,772 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (80f504723ff184ba0643ea886ce901d6) under job master id 00000000000000000000000000000000.
2025-11-02 12:53:31,772 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[1].
2025-11-02 12:53:31,773 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 12:53:31,773 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (80f504723ff184ba0643ea886ce901d6) switched from state CREATED to RUNNING.
2025-11-02 12:53:31,773 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1) (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 12:53:31,775 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 12:53:31,776 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 12:53:31,779 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 12:53:31,782 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_35 for job 80f504723ff184ba0643ea886ce901d6.
2025-11-02 12:53:31,783 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_35 for job 80f504723ff184ba0643ea886ce901d6.
2025-11-02 12:53:31,784 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 12:53:31,785 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 80f504723ff184ba0643ea886ce901d6: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 12:53:31,789 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 12:53:31,789 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 12:53:31,789 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 12:53:31,789 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762068211789
2025-11-02 12:53:31,791 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 12:53:31,848 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 12:53:31,851 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 80f504723ff184ba0643ea886ce901d6
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 12:53:31,852 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 8f564bc07c4ff9820a291817dd4a22c6 from localhost:51798-3c06be for job 80f504723ff184ba0643ea886ce901d6 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 12:53:31,907 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1) (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 12:53:31,910 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 8f564bc07c4ff9820a291817dd4a22c6
2025-11-02 12:53:32,027 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1) (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 12:53:32,336 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:52259
2025-11-02 12:53:32,336 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[1] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 12:53:32,337 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: 2512, StoppingOffset: -9223372036854775808]]}
2025-11-02 12:53:32,344 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1) (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 12:53:32,407 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 12:53:42,094 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (80f504723ff184ba0643ea886ce901d6) switched from state RUNNING to CANCELLING.
2025-11-02 12:53:42,096 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1) (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 12:53:42,189 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-02 12:53:42,300 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 12:53:42,369 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1) (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 12:53:42,371 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (80f504723ff184ba0643ea886ce901d6) switched from state CANCELLING to CANCELED.
2025-11-02 12:53:42,372 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 80f504723ff184ba0643ea886ce901d6.
2025-11-02 12:53:42,372 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 80f504723ff184ba0643ea886ce901d6
2025-11-02 12:53:42,374 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 80f504723ff184ba0643ea886ce901d6 reached terminal state CANCELED.
2025-11-02 12:53:42,379 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:42,383 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 12:53:42,383 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 12:53:42,383 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [8f564bc07c4ff9820a291817dd4a22c6].
2025-11-02 12:53:42,383 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[1].
2025-11-02 12:53:42,384 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:42,384 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:42,384 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 12:53:42,385 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_35 for job 80f504723ff184ba0643ea886ce901d6 from the resource manager.
2025-11-02 12:53:42,388 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 12:53:42,388 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 12:53:42,388 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 12:53:42,388 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 8f564bc07c4ff9820a291817dd4a22c6.
2025-11-02 12:53:42,389 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[1] closed.
2025-11-02 12:54:28,799 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (2685b258c7515725c49793198333b210).
2025-11-02 12:54:28,800 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (2685b258c7515725c49793198333b210).
2025-11-02 12:54:28,801 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 2685b258c7515725c49793198333b210 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 12:54:28,808 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_36 .
2025-11-02 12:54:28,809 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (2685b258c7515725c49793198333b210).
2025-11-02 12:54:28,810 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (2685b258c7515725c49793198333b210).
2025-11-02 12:54:28,811 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph a5d4f6bf2621cec298c41300648d1b6e for job 2685b258c7515725c49793198333b210.
2025-11-02 12:54:28,811 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (2685b258c7515725c49793198333b210).
2025-11-02 12:54:28,811 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 12:54:28,815 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 12:54:28,815 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@649e916b
2025-11-02 12:54:28,815 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 12:54:28,815 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 12:54:28,819 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 12:54:28,820 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@3d9310 for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (2685b258c7515725c49793198333b210).
2025-11-02 12:54:28,820 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (2685b258c7515725c49793198333b210) under job master id 00000000000000000000000000000000.
2025-11-02 12:54:28,820 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[4].
2025-11-02 12:54:28,820 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 12:54:28,820 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (2685b258c7515725c49793198333b210) switched from state CREATED to RUNNING.
2025-11-02 12:54:28,821 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1) (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 12:54:28,822 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 12:54:28,823 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 12:54:28,825 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 12:54:28,825 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_36 for job 2685b258c7515725c49793198333b210.
2025-11-02 12:54:28,826 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_36 for job 2685b258c7515725c49793198333b210.
2025-11-02 12:54:28,827 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 12:54:28,827 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 2685b258c7515725c49793198333b210: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 12:54:28,827 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 12:54:28,827 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 12:54:28,827 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 12:54:28,827 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762068268827
2025-11-02 12:54:28,828 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 12:54:28,834 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 12:54:28,891 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 2685b258c7515725c49793198333b210
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 12:54:28,891 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 4d34c17f85d29d44d6864d55de689dc1 from localhost:51798-3c06be for job 2685b258c7515725c49793198333b210 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 12:54:28,908 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1) (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 12:54:28,909 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 4d34c17f85d29d44d6864d55de689dc1
2025-11-02 12:54:28,941 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1) (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 12:54:28,986 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:54138
2025-11-02 12:54:28,986 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[4] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 12:54:28,987 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: 2512, StoppingOffset: -9223372036854775808]]}
2025-11-02 12:54:28,987 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1) (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 12:54:29,084 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 12:54:33,499 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (2685b258c7515725c49793198333b210) switched from state RUNNING to CANCELLING.
2025-11-02 12:54:33,500 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1) (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 12:54:33,611 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-02 12:54:33,721 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 12:54:33,836 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 12:54:33,940 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1) (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 12:54:33,941 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (2685b258c7515725c49793198333b210) switched from state CANCELLING to CANCELED.
2025-11-02 12:54:33,941 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 2685b258c7515725c49793198333b210
2025-11-02 12:54:33,941 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 2685b258c7515725c49793198333b210.
2025-11-02 12:54:33,944 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 2685b258c7515725c49793198333b210 reached terminal state CANCELED.
2025-11-02 12:54:33,949 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (2685b258c7515725c49793198333b210).
2025-11-02 12:54:33,949 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 12:54:33,950 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 12:54:33,949 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[4].
2025-11-02 12:54:33,950 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [4d34c17f85d29d44d6864d55de689dc1].
2025-11-02 12:54:33,950 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (2685b258c7515725c49793198333b210).
2025-11-02 12:54:33,950 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (2685b258c7515725c49793198333b210).
2025-11-02 12:54:33,950 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_36 for job 2685b258c7515725c49793198333b210 from the resource manager.
2025-11-02 12:54:33,950 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 12:54:33,956 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 12:54:33,957 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 12:54:33,957 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 12:54:33,958 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 4d34c17f85d29d44d6864d55de689dc1.
2025-11-02 12:54:33,958 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[4] closed.
2025-11-02 12:55:33,329 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:33,331 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:33,331 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 126e74c2134b9493921a8ae0844ed194 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 12:55:33,335 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_37 .
2025-11-02 12:55:33,335 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:33,336 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:33,337 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 385d6f9509c57754c94f15d7c9289c3f for job 126e74c2134b9493921a8ae0844ed194.
2025-11-02 12:55:33,338 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:33,338 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 12:55:33,344 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 12:55:33,344 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1a05c269
2025-11-02 12:55:33,344 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 12:55:33,344 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 12:55:33,348 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 12:55:33,348 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@7c8b091a for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:33,348 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (126e74c2134b9493921a8ae0844ed194) under job master id 00000000000000000000000000000000.
2025-11-02 12:55:33,348 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[7].
2025-11-02 12:55:33,349 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 12:55:33,349 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (126e74c2134b9493921a8ae0844ed194) switched from state CREATED to RUNNING.
2025-11-02 12:55:33,349 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1) (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 12:55:33,349 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 12:55:33,349 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 12:55:33,350 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 12:55:33,351 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_37 for job 126e74c2134b9493921a8ae0844ed194.
2025-11-02 12:55:33,352 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_37 for job 126e74c2134b9493921a8ae0844ed194.
2025-11-02 12:55:33,353 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 12:55:33,353 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 126e74c2134b9493921a8ae0844ed194: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 12:55:33,354 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 12:55:33,354 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 12:55:33,354 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 12:55:33,354 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762068333354
2025-11-02 12:55:33,354 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 12:55:33,370 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 12:55:33,421 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 126e74c2134b9493921a8ae0844ed194
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 12:55:33,421 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 64887d28de6a381ea410a2accba83a4d from localhost:51798-3c06be for job 126e74c2134b9493921a8ae0844ed194 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 12:55:33,443 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1) (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 12:55:33,448 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 64887d28de6a381ea410a2accba83a4d
2025-11-02 12:55:33,482 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1) (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 12:55:33,524 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:50327
2025-11-02 12:55:33,525 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[7] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 12:55:33,525 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: 2512, StoppingOffset: -9223372036854775808]]}
2025-11-02 12:55:33,525 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1) (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 12:55:33,616 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 12:55:52,198 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (126e74c2134b9493921a8ae0844ed194) switched from state RUNNING to CANCELLING.
2025-11-02 12:55:52,200 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1) (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 12:55:52,310 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-02 12:55:52,417 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 12:55:52,529 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 12:55:52,640 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 12:55:52,688 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1) (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 12:55:52,690 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (126e74c2134b9493921a8ae0844ed194) switched from state CANCELLING to CANCELED.
2025-11-02 12:55:52,691 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 126e74c2134b9493921a8ae0844ed194.
2025-11-02 12:55:52,691 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 126e74c2134b9493921a8ae0844ed194
2025-11-02 12:55:52,693 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 126e74c2134b9493921a8ae0844ed194 reached terminal state CANCELED.
2025-11-02 12:55:52,714 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:52,715 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 12:55:52,716 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 12:55:52,715 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[7].
2025-11-02 12:55:52,716 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [64887d28de6a381ea410a2accba83a4d].
2025-11-02 12:55:52,716 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:52,716 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:52,717 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_37 for job 126e74c2134b9493921a8ae0844ed194 from the resource manager.
2025-11-02 12:55:52,718 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 12:55:52,721 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 12:55:52,721 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 12:55:52,721 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 12:55:52,721 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[7] closed.
2025-11-02 12:55:52,722 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 64887d28de6a381ea410a2accba83a4d.
2025-11-02 12:59:42,270 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,272 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,273 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 09809b3b03a1a6ed281e1006fdddd76c was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 12:59:42,278 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_38 .
2025-11-02 12:59:42,278 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,280 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,282 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 6f3250b52b2031ec032e28f00f999acc for job 09809b3b03a1a6ed281e1006fdddd76c.
2025-11-02 12:59:42,283 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,283 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 12:59:42,289 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 12:59:42,289 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@135fbcc1
2025-11-02 12:59:42,289 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 12:59:42,289 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 12:59:42,293 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 12:59:42,293 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@491bdd4 for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,294 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (09809b3b03a1a6ed281e1006fdddd76c) under job master id 00000000000000000000000000000000.
2025-11-02 12:59:42,294 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[10].
2025-11-02 12:59:42,294 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 12:59:42,294 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (09809b3b03a1a6ed281e1006fdddd76c) switched from state CREATED to RUNNING.
2025-11-02 12:59:42,294 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1) (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 12:59:42,296 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 12:59:42,296 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 12:59:42,300 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 12:59:42,300 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_38 for job 09809b3b03a1a6ed281e1006fdddd76c.
2025-11-02 12:59:42,301 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_38 for job 09809b3b03a1a6ed281e1006fdddd76c.
2025-11-02 12:59:42,301 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 12:59:42,301 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 09809b3b03a1a6ed281e1006fdddd76c: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 12:59:42,303 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 12:59:42,303 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 12:59:42,303 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 12:59:42,303 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762068582303
2025-11-02 12:59:42,303 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 12:59:42,315 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 12:59:42,370 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 09809b3b03a1a6ed281e1006fdddd76c
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 12:59:42,371 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 7f407ce7244a47a1b4401e7b33432bfd from localhost:51798-3c06be for job 09809b3b03a1a6ed281e1006fdddd76c with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 12:59:42,395 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1) (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 12:59:42,403 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 7f407ce7244a47a1b4401e7b33432bfd
2025-11-02 12:59:42,440 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1) (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 12:59:42,493 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:56435
2025-11-02 12:59:42,494 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[10] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 12:59:42,495 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]}
2025-11-02 12:59:42,498 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1) (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 12:59:42,553 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 12:59:42,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1) (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED on localhost:51798-3c06be @ localhost (dataPort=51800).
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-02 12:59:42,578 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 09809b3b03a1a6ed281e1006fdddd76c
2025-11-02 12:59:42,579 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: bank_transactions[10].
2025-11-02 12:59:42,580 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (09809b3b03a1a6ed281e1006fdddd76c) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor76.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-02 12:59:42,587 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (09809b3b03a1a6ed281e1006fdddd76c) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at jdk.internal.reflect.GeneratedMethodAccessor76.invoke(Unknown Source) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akka292994a4-406f-49e0-b1e7-4a8a321391ba.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-02 12:59:42,588 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 09809b3b03a1a6ed281e1006fdddd76c.
2025-11-02 12:59:42,592 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 09809b3b03a1a6ed281e1006fdddd76c reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515)
	at jdk.internal.reflect.GeneratedMethodAccessor76.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224)
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165)
	... 6 more
2025-11-02 12:59:42,601 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,601 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 12:59:42,601 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 12:59:42,601 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [7f407ce7244a47a1b4401e7b33432bfd].
2025-11-02 12:59:42,601 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[10].
2025-11-02 12:59:42,602 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,602 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,602 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_38 for job 09809b3b03a1a6ed281e1006fdddd76c from the resource manager.
2025-11-02 12:59:42,602 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 12:59:42,604 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 12:59:42,604 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 12:59:42,604 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 12:59:42,604 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[10] closed.
2025-11-02 12:59:42,608 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 7f407ce7244a47a1b4401e7b33432bfd.
2025-11-02 13:13:40,017 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1f43bba76c5061de16f5812875844409).
2025-11-02 13:13:40,019 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1f43bba76c5061de16f5812875844409).
2025-11-02 13:13:40,020 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 1f43bba76c5061de16f5812875844409 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 13:13:40,024 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_39 .
2025-11-02 13:13:40,024 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1f43bba76c5061de16f5812875844409).
2025-11-02 13:13:40,025 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1f43bba76c5061de16f5812875844409).
2025-11-02 13:13:40,026 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 06841ece88fc8d766cba91f6147dec95 for job 1f43bba76c5061de16f5812875844409.
2025-11-02 13:13:40,026 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1f43bba76c5061de16f5812875844409).
2025-11-02 13:13:40,026 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 13:13:40,033 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 13:13:40,033 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@78b3c5a2
2025-11-02 13:13:40,033 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 13:13:40,034 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 13:13:40,038 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 13:13:40,038 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@6561083d for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1f43bba76c5061de16f5812875844409).
2025-11-02 13:13:40,038 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1f43bba76c5061de16f5812875844409) under job master id 00000000000000000000000000000000.
2025-11-02 13:13:40,038 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[13].
2025-11-02 13:13:40,039 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 13:13:40,039 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1f43bba76c5061de16f5812875844409) switched from state CREATED to RUNNING.
2025-11-02 13:13:40,039 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1) (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 13:13:40,039 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 13:13:40,040 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 13:13:40,040 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 13:13:40,040 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_39 for job 1f43bba76c5061de16f5812875844409.
2025-11-02 13:13:40,040 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_39 for job 1f43bba76c5061de16f5812875844409.
2025-11-02 13:13:40,042 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 13:13:40,042 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 1f43bba76c5061de16f5812875844409: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 13:13:40,043 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 13:13:40,043 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 13:13:40,043 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 13:13:40,043 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762069420043
2025-11-02 13:13:40,043 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 13:13:40,058 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 13:13:40,106 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 1f43bba76c5061de16f5812875844409
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 13:13:40,108 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot f1d1a44c0cf0ccf4c9edc51f81a7661d from localhost:51798-3c06be for job 1f43bba76c5061de16f5812875844409 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 13:13:40,149 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1) (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 13:13:40,151 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id f1d1a44c0cf0ccf4c9edc51f81a7661d
2025-11-02 13:13:40,200 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1) (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 13:13:40,276 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:57610
2025-11-02 13:13:40,276 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[13] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 13:13:40,277 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-02 13:13:40,279 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1) (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 13:13:40,307 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 13:14:36,610 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1f43bba76c5061de16f5812875844409) switched from state RUNNING to CANCELLING.
2025-11-02 13:14:36,613 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1) (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 13:14:36,711 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-02 13:14:36,841 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 13:14:36,952 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 13:14:37,069 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1) (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 13:14:37,072 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1f43bba76c5061de16f5812875844409) switched from state CANCELLING to CANCELED.
2025-11-02 13:14:37,072 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 1f43bba76c5061de16f5812875844409.
2025-11-02 13:14:37,072 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 1f43bba76c5061de16f5812875844409
2025-11-02 13:14:37,073 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 13:14:37,077 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 1f43bba76c5061de16f5812875844409 reached terminal state CANCELED.
2025-11-02 13:14:37,087 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1f43bba76c5061de16f5812875844409).
2025-11-02 13:14:37,088 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 13:14:37,088 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 13:14:37,088 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[13].
2025-11-02 13:14:37,088 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [f1d1a44c0cf0ccf4c9edc51f81a7661d].
2025-11-02 13:14:37,089 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1f43bba76c5061de16f5812875844409).
2025-11-02 13:14:37,089 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1f43bba76c5061de16f5812875844409).
2025-11-02 13:14:37,090 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_39 for job 1f43bba76c5061de16f5812875844409 from the resource manager.
2025-11-02 13:14:37,091 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 13:14:37,098 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 13:14:37,098 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 13:14:37,098 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 13:14:37,099 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[13] closed.
2025-11-02 13:14:37,101 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot f1d1a44c0cf0ccf4c9edc51f81a7661d.
2025-11-02 13:22:04,320 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:22:04,322 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:22:04,324 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 1890a8be8901f754b52677d4e62fe9bf was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 13:22:04,349 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_40 .
2025-11-02 13:22:04,350 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:22:04,352 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:22:04,353 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 366586b74ab088312f21755b977d588c for job 1890a8be8901f754b52677d4e62fe9bf.
2025-11-02 13:22:04,355 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:22:04,355 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 13:22:04,362 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 13:22:04,362 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@57417e0e
2025-11-02 13:22:04,362 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 13:22:04,362 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 13:22:04,369 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 13:22:04,369 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@6eba64ba for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:22:04,370 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1890a8be8901f754b52677d4e62fe9bf) under job master id 00000000000000000000000000000000.
2025-11-02 13:22:04,370 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[16].
2025-11-02 13:22:04,370 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 13:22:04,370 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1890a8be8901f754b52677d4e62fe9bf) switched from state CREATED to RUNNING.
2025-11-02 13:22:04,370 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1) (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 13:22:04,371 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 13:22:04,371 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 13:22:04,373 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 13:22:04,374 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_40 for job 1890a8be8901f754b52677d4e62fe9bf.
2025-11-02 13:22:04,374 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_40 for job 1890a8be8901f754b52677d4e62fe9bf.
2025-11-02 13:22:04,375 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 13:22:04,375 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 13:22:04,375 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 1890a8be8901f754b52677d4e62fe9bf: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 13:22:04,375 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 13:22:04,375 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 13:22:04,375 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762069924375
2025-11-02 13:22:04,376 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 13:22:04,417 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 13:22:04,445 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 1890a8be8901f754b52677d4e62fe9bf
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 13:22:04,446 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 2f77c5ce1560584ff25f7e7eddb85327 from localhost:51798-3c06be for job 1890a8be8901f754b52677d4e62fe9bf with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 13:22:04,495 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1) (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 13:22:04,497 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 2f77c5ce1560584ff25f7e7eddb85327
2025-11-02 13:22:04,551 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1) (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 13:22:04,609 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:54917
2025-11-02 13:22:04,609 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[16] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 13:22:04,610 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-02 13:22:04,611 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1) (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 13:22:04,624 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 13:25:14,850 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1890a8be8901f754b52677d4e62fe9bf) switched from state RUNNING to CANCELLING.
2025-11-02 13:25:14,854 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1) (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 13:25:14,901 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1) (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 13:25:14,903 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (1890a8be8901f754b52677d4e62fe9bf) switched from state CANCELLING to CANCELED.
2025-11-02 13:25:14,904 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 1890a8be8901f754b52677d4e62fe9bf.
2025-11-02 13:25:14,904 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 1890a8be8901f754b52677d4e62fe9bf
2025-11-02 13:25:14,909 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 1890a8be8901f754b52677d4e62fe9bf reached terminal state CANCELED.
2025-11-02 13:25:14,922 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:25:14,923 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 13:25:14,924 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 13:25:14,924 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [2f77c5ce1560584ff25f7e7eddb85327].
2025-11-02 13:25:14,924 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[16].
2025-11-02 13:25:14,926 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 13:25:14,926 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:25:14,926 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:25:14,926 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_40 for job 1890a8be8901f754b52677d4e62fe9bf from the resource manager.
2025-11-02 13:25:14,927 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 13:25:14,927 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 13:25:14,927 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 13:25:14,927 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[16] closed.
2025-11-02 13:25:14,932 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 2f77c5ce1560584ff25f7e7eddb85327.
2025-11-02 13:25:33,731 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8124b88e7c19fc032991b3110433c546).
2025-11-02 13:25:33,732 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8124b88e7c19fc032991b3110433c546).
2025-11-02 13:25:33,734 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 8124b88e7c19fc032991b3110433c546 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 13:25:33,749 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_41 .
2025-11-02 13:25:33,749 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8124b88e7c19fc032991b3110433c546).
2025-11-02 13:25:33,751 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8124b88e7c19fc032991b3110433c546).
2025-11-02 13:25:33,753 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph def62ee32891c332d022c3d8ecf5b698 for job 8124b88e7c19fc032991b3110433c546.
2025-11-02 13:25:33,754 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8124b88e7c19fc032991b3110433c546).
2025-11-02 13:25:33,754 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 13:25:33,763 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 13:25:33,764 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@191789dd
2025-11-02 13:25:33,764 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 13:25:33,764 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 13:25:33,773 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 13:25:33,773 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@38c2b5b for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8124b88e7c19fc032991b3110433c546).
2025-11-02 13:25:33,774 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8124b88e7c19fc032991b3110433c546) under job master id 00000000000000000000000000000000.
2025-11-02 13:25:33,774 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[19].
2025-11-02 13:25:33,774 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 13:25:33,775 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8124b88e7c19fc032991b3110433c546) switched from state CREATED to RUNNING.
2025-11-02 13:25:33,775 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1) (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 13:25:33,775 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 13:25:33,777 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 13:25:33,779 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 13:25:33,780 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_41 for job 8124b88e7c19fc032991b3110433c546.
2025-11-02 13:25:33,781 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_41 for job 8124b88e7c19fc032991b3110433c546.
2025-11-02 13:25:33,783 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 13:25:33,783 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 8124b88e7c19fc032991b3110433c546: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 13:25:33,787 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 13:25:33,787 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 13:25:33,787 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 13:25:33,787 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762070133787
2025-11-02 13:25:33,787 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 13:25:33,820 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 13:25:33,855 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 8124b88e7c19fc032991b3110433c546
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 13:25:33,856 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot dc9fbc462e35e481c7cb8b80e858dc4e from localhost:51798-3c06be for job 8124b88e7c19fc032991b3110433c546 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 13:25:33,892 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1) (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 13:25:33,893 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id dc9fbc462e35e481c7cb8b80e858dc4e
2025-11-02 13:25:33,922 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1) (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 13:25:33,957 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:59748
2025-11-02 13:25:33,957 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[19] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 13:25:33,957 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-02 13:25:33,958 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1) (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 13:25:34,028 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 13:27:09,373 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8124b88e7c19fc032991b3110433c546) switched from state RUNNING to CANCELLING.
2025-11-02 13:27:09,377 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1) (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 13:27:09,406 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1) (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 13:27:09,407 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8124b88e7c19fc032991b3110433c546) switched from state CANCELLING to CANCELED.
2025-11-02 13:27:09,407 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 8124b88e7c19fc032991b3110433c546.
2025-11-02 13:27:09,407 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 8124b88e7c19fc032991b3110433c546
2025-11-02 13:27:09,408 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 8124b88e7c19fc032991b3110433c546 reached terminal state CANCELED.
2025-11-02 13:27:09,413 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8124b88e7c19fc032991b3110433c546).
2025-11-02 13:27:09,413 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 13:27:09,414 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 13:27:09,413 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[19].
2025-11-02 13:27:09,414 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [dc9fbc462e35e481c7cb8b80e858dc4e].
2025-11-02 13:27:09,414 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8124b88e7c19fc032991b3110433c546).
2025-11-02 13:27:09,414 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8124b88e7c19fc032991b3110433c546).
2025-11-02 13:27:09,414 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_41 for job 8124b88e7c19fc032991b3110433c546 from the resource manager.
2025-11-02 13:27:09,418 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 13:27:09,421 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 13:27:09,421 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 13:27:09,421 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 13:27:09,421 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[19] closed.
2025-11-02 13:27:09,421 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot dc9fbc462e35e481c7cb8b80e858dc4e.
2025-11-02 13:28:46,502 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:28:46,503 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:28:46,504 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 9ce75af44c8d7be188ded1d77bb5663a was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 13:28:46,511 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_42 .
2025-11-02 13:28:46,511 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:28:46,512 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:28:46,513 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph d76998f0227c85e070b2b7e6717e5f15 for job 9ce75af44c8d7be188ded1d77bb5663a.
2025-11-02 13:28:46,513 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:28:46,513 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 13:28:46,517 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 13:28:46,517 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@88a9d2c
2025-11-02 13:28:46,517 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 13:28:46,517 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 13:28:46,520 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 13:28:46,520 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@5bde58aa for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:28:46,520 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (9ce75af44c8d7be188ded1d77bb5663a) under job master id 00000000000000000000000000000000.
2025-11-02 13:28:46,520 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[22].
2025-11-02 13:28:46,521 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 13:28:46,521 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (9ce75af44c8d7be188ded1d77bb5663a) switched from state CREATED to RUNNING.
2025-11-02 13:28:46,521 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1) (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 13:28:46,521 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 13:28:46,522 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 13:28:46,522 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 13:28:46,522 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_42 for job 9ce75af44c8d7be188ded1d77bb5663a.
2025-11-02 13:28:46,524 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_42 for job 9ce75af44c8d7be188ded1d77bb5663a.
2025-11-02 13:28:46,525 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 13:28:46,525 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 9ce75af44c8d7be188ded1d77bb5663a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 13:28:46,527 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 13:28:46,527 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 13:28:46,527 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 13:28:46,527 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762070326527
2025-11-02 13:28:46,528 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 13:28:46,543 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 13:28:46,589 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 9ce75af44c8d7be188ded1d77bb5663a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 13:28:46,589 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot da7094712258826c18398b94072bc0f5 from localhost:51798-3c06be for job 9ce75af44c8d7be188ded1d77bb5663a with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 13:28:46,600 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1) (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 13:28:46,601 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id da7094712258826c18398b94072bc0f5
2025-11-02 13:28:46,621 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1) (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 13:28:46,645 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:57188
2025-11-02 13:28:46,645 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[22] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 13:28:46,645 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-02 13:28:46,645 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1) (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 13:28:46,685 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 13:30:13,631 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (9ce75af44c8d7be188ded1d77bb5663a) switched from state RUNNING to CANCELLING.
2025-11-02 13:30:13,634 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1) (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 13:30:13,749 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-02 13:30:13,866 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1) (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 13:30:13,867 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (9ce75af44c8d7be188ded1d77bb5663a) switched from state CANCELLING to CANCELED.
2025-11-02 13:30:13,868 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 9ce75af44c8d7be188ded1d77bb5663a.
2025-11-02 13:30:13,868 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 9ce75af44c8d7be188ded1d77bb5663a
2025-11-02 13:30:13,870 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 9ce75af44c8d7be188ded1d77bb5663a reached terminal state CANCELED.
2025-11-02 13:30:13,874 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:30:13,876 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 13:30:13,876 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 13:30:13,876 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [da7094712258826c18398b94072bc0f5].
2025-11-02 13:30:13,876 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[22].
2025-11-02 13:30:13,878 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:30:13,878 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate_str`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate_str`, `bank_transactions`.`tx_time`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:30:13,879 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_42 for job 9ce75af44c8d7be188ded1d77bb5663a from the resource manager.
2025-11-02 13:30:13,884 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 13:30:13,886 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 13:30:13,887 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 13:30:13,887 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 13:30:13,887 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot da7094712258826c18398b94072bc0f5.
2025-11-02 13:30:13,887 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[22] closed.
2025-11-02 14:47:44,730 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:47:44,730 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:47:44,732 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job fadc002549f91eabfdb4dd918b2ee79c was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 14:47:44,746 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_43 .
2025-11-02 14:47:44,746 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:47:44,748 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:47:44,750 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph a900131c66cb9177c683e34343d0ea50 for job fadc002549f91eabfdb4dd918b2ee79c.
2025-11-02 14:47:44,752 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:47:44,752 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 14:47:44,763 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 14:47:44,763 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@21f1a8e3
2025-11-02 14:47:44,763 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 14:47:44,763 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 14:47:44,767 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 14:47:44,768 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@545ae37 for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:47:44,769 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (fadc002549f91eabfdb4dd918b2ee79c) under job master id 00000000000000000000000000000000.
2025-11-02 14:47:44,769 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[25].
2025-11-02 14:47:44,770 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 14:47:44,770 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (fadc002549f91eabfdb4dd918b2ee79c) switched from state CREATED to RUNNING.
2025-11-02 14:47:44,770 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1) (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 14:47:44,771 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 14:47:44,772 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 14:47:44,774 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 14:47:44,774 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_43 for job fadc002549f91eabfdb4dd918b2ee79c.
2025-11-02 14:47:44,774 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_43 for job fadc002549f91eabfdb4dd918b2ee79c.
2025-11-02 14:47:44,775 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 14:47:44,775 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fadc002549f91eabfdb4dd918b2ee79c: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 14:47:44,777 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 14:47:44,777 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 14:47:44,777 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 14:47:44,777 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762075064777
2025-11-02 14:47:44,777 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 14:47:44,808 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 14:47:44,838 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fadc002549f91eabfdb4dd918b2ee79c
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 14:47:44,839 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 28a9c6706c40d485c7e71225f9b83e37 from localhost:51798-3c06be for job fadc002549f91eabfdb4dd918b2ee79c with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 14:47:44,877 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1) (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 14:47:44,885 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[25] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 28a9c6706c40d485c7e71225f9b83e37
2025-11-02 14:47:44,957 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1) (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 14:47:45,032 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:63089
2025-11-02 14:47:45,034 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[25] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 14:47:45,035 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-02 14:47:45,035 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1) (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 14:47:45,132 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 14:48:04,631 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (fadc002549f91eabfdb4dd918b2ee79c) switched from state RUNNING to CANCELLING.
2025-11-02 14:48:04,634 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1) (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 14:48:04,750 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-02 14:48:04,859 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 14:48:04,896 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1) (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 14:48:04,900 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (fadc002549f91eabfdb4dd918b2ee79c) switched from state CANCELLING to CANCELED.
2025-11-02 14:48:04,900 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job fadc002549f91eabfdb4dd918b2ee79c.
2025-11-02 14:48:04,901 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fadc002549f91eabfdb4dd918b2ee79c
2025-11-02 14:48:04,904 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job fadc002549f91eabfdb4dd918b2ee79c reached terminal state CANCELED.
2025-11-02 14:48:04,913 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:48:04,914 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 14:48:04,914 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[25].
2025-11-02 14:48:04,915 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 14:48:04,915 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [28a9c6706c40d485c7e71225f9b83e37].
2025-11-02 14:48:04,916 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:48:04,916 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:48:04,917 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_43 for job fadc002549f91eabfdb4dd918b2ee79c from the resource manager.
2025-11-02 14:48:04,918 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 14:48:04,923 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 14:48:04,923 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 14:48:04,924 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 14:48:04,924 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[25] closed.
2025-11-02 14:48:04,925 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 28a9c6706c40d485c7e71225f9b83e37.
2025-11-02 15:51:43,043 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions`' (74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:43,046 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions`' (74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:43,051 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 74fa4f277aa75c5f9a89a4a212077850 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 15:51:43,083 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_44 .
2025-11-02 15:51:43,085 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions`' (74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:43,090 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions` (74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:43,093 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph ed47b9ca3d5ec487debfcc723ce5400d for job 74fa4f277aa75c5f9a89a4a212077850.
2025-11-02 15:51:43,095 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions` (74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:43,095 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 15:51:43,111 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 15:51:43,111 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3e18e64
2025-11-02 15:51:43,111 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 15:51:43,111 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 15:51:43,117 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 15:51:43,117 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@590e9ae2 for SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions` (74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:43,118 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions`' (74fa4f277aa75c5f9a89a4a212077850) under job master id 00000000000000000000000000000000.
2025-11-02 15:51:43,118 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[27].
2025-11-02 15:51:43,118 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 15:51:43,118 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions` (74fa4f277aa75c5f9a89a4a212077850) switched from state CREATED to RUNNING.
2025-11-02 15:51:43,119 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-02 15:51:43,120 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 15:51:43,121 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 15:51:43,124 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 15:51:43,125 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_44 for job 74fa4f277aa75c5f9a89a4a212077850.
2025-11-02 15:51:43,125 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_44 for job 74fa4f277aa75c5f9a89a4a212077850.
2025-11-02 15:51:43,125 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 15:51:43,126 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 74fa4f277aa75c5f9a89a4a212077850: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 15:51:43,127 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 15:51:43,127 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 15:51:43,127 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 15:51:43,127 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762078903127
2025-11-02 15:51:43,127 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 15:51:43,178 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 15:51:43,197 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 74fa4f277aa75c5f9a89a4a212077850
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 15:51:43,198 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 154c7f4a5b165a568a95cc2c8761065f from localhost:51798-3c06be for job 74fa4f277aa75c5f9a89a4a212077850 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 15:51:43,291 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 15:51:43,296 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 154c7f4a5b165a568a95cc2c8761065f
2025-11-02 15:51:43,357 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:51:43,428 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:63244
2025-11-02 15:51:43,429 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[27] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 15:51:43,429 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-02 15:51:43,431 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:51:43,449 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-02 15:51:49,207 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions` (74fa4f277aa75c5f9a89a4a212077850) switched from state RUNNING to CANCELLING.
2025-11-02 15:51:49,207 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 15:51:49,314 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-02 15:51:49,419 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-02 15:51:49,517 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1) (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 15:51:49,518 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions` (74fa4f277aa75c5f9a89a4a212077850) switched from state CANCELLING to CANCELED.
2025-11-02 15:51:49,518 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 74fa4f277aa75c5f9a89a4a212077850
2025-11-02 15:51:49,518 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 74fa4f277aa75c5f9a89a4a212077850.
2025-11-02 15:51:49,521 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 74fa4f277aa75c5f9a89a4a212077850 reached terminal state CANCELED.
2025-11-02 15:51:49,528 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions`' (74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:49,529 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-02 15:51:49,529 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[27].
2025-11-02 15:51:49,529 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-02 15:51:49,529 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [154c7f4a5b165a568a95cc2c8761065f].
2025-11-02 15:51:49,529 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:51798-3c06be because: Stopping JobMaster for job 'SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions`' (74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:49,529 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0: Stopping JobMaster for job 'SELECT `high_value_transactions`.`TransactionID`, `high_value_transactions`.`AccountID`, `high_value_transactions`.`TransactionAmount`, `high_value_transactions`.`TransactionDate`, `high_value_transactions`.`TransactionType`, `high_value_transactions`.`Location`, `high_value_transactions`.`DeviceID`, `high_value_transactions`.`IP Address`, `high_value_transactions`.`MerchantID`, `high_value_transactions`.`Channel`, `high_value_transactions`.`CustomerAge`, `high_value_transactions`.`CustomerOccupation`, `high_value_transactions`.`TransactionDuration`, `high_value_transactions`.`LoginAttempts`, `high_value_transactions`.`AccountBalance`, `high_value_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`high_value_transactions` AS `high_value_transactions`' (74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:49,530 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_44 for job 74fa4f277aa75c5f9a89a4a212077850 from the resource manager.
2025-11-02 15:51:49,529 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-02 15:51:49,533 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 15:51:49,533 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 15:51:49,533 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 15:51:49,533 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[27] closed.
2025-11-02 15:51:49,535 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 154c7f4a5b165a568a95cc2c8761065f.
2025-11-02 15:56:32,512 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.fraud_alerts' (d566ac56bb78c1c0c311e4de6984739d).
2025-11-02 15:56:32,513 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.fraud_alerts' (d566ac56bb78c1c0c311e4de6984739d).
2025-11-02 15:56:32,514 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job d566ac56bb78c1c0c311e4de6984739d was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-02 15:56:32,517 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_45 .
2025-11-02 15:56:32,518 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.fraud_alerts' (d566ac56bb78c1c0c311e4de6984739d).
2025-11-02 15:56:32,519 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.fraud_alerts (d566ac56bb78c1c0c311e4de6984739d).
2025-11-02 15:56:32,520 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 0d3b8903738e8e7348741c39094ef702 for job d566ac56bb78c1c0c311e4de6984739d.
2025-11-02 15:56:32,520 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.fraud_alerts (d566ac56bb78c1c0c311e4de6984739d).
2025-11-02 15:56:32,520 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-02 15:56:32,525 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) exceeded the 80 characters length limit and was truncated.
2025-11-02 15:56:32,539 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-02 15:56:32,539 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@22cbc9f9
2025-11-02 15:56:32,539 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 15:56:32,539 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 15:56:32,542 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-02 15:56:32,542 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@8afd5cc for insert-into_default_catalog.default_database.fraud_alerts (d566ac56bb78c1c0c311e4de6984739d).
2025-11-02 15:56:32,543 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.fraud_alerts' (d566ac56bb78c1c0c311e4de6984739d) under job master id 00000000000000000000000000000000.
2025-11-02 15:56:32,543 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[30].
2025-11-02 15:56:32,543 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-02 15:56:32,543 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.fraud_alerts (d566ac56bb78c1c0c311e4de6984739d) switched from state CREATED to RUNNING.
2025-11-02 15:56:32,544 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1) (0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0) switched from CREATED to SCHEDULED.
2025-11-02 15:56:32,544 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[43] -> Calc[44] (1/1) (0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0) switched from CREATED to SCHEDULED.
2025-11-02 15:56:32,544 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GlobalWindowAggregate[36] -> Calc[37] (1/1) (0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0) switched from CREATED to SCHEDULED.
2025-11-02 15:56:32,544 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[39] -> Calc[40] (1/1) (0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0) switched from CREATED to SCHEDULED.
2025-11-02 15:56:32,544 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1) (0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from CREATED to SCHEDULED.
2025-11-02 15:56:32,544 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-02 15:56:32,544 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-02 15:56:32,545 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-02 15:56:32,546 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_45 for job d566ac56bb78c1c0c311e4de6984739d.
2025-11-02 15:56:32,546 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_45 for job d566ac56bb78c1c0c311e4de6984739d.
2025-11-02 15:56:32,547 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-02 15:56:32,547 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 15:56:32,547 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 15:56:32,547 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762079192547
2025-11-02 15:56:32,547 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-02 15:56:32,547 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-02 15:56:32,547 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job d566ac56bb78c1c0c311e4de6984739d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-02 15:56:32,566 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-02 15:56:32,615 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job d566ac56bb78c1c0c311e4de6984739d
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:51798-3c06be
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:51348-d4ad3a
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
	TaskManager localhost:49385-5990f3
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663295 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554434 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-02 15:56:32,616 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 48d622f1fd40077ef7a2adb02cae9703 from localhost:51798-3c06be for job d566ac56bb78c1c0c311e4de6984739d with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 15:56:32,637 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1) (0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 15:56:32,645 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1) (attempt #0) with attempt id 0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0 and vertex id 5da08a4269629ebce1b7dfad7a855276_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 48d622f1fd40077ef7a2adb02cae9703
2025-11-02 15:56:32,650 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[43] -> Calc[44] (1/1) (0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 15:56:32,650 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Join[43] -> Calc[44] (1/1) (attempt #0) with attempt id 0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0 and vertex id f903181e99c89a09cba2df29130e7591_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 48d622f1fd40077ef7a2adb02cae9703
2025-11-02 15:56:32,658 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GlobalWindowAggregate[36] -> Calc[37] (1/1) (0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 15:56:32,659 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying GlobalWindowAggregate[36] -> Calc[37] (1/1) (attempt #0) with attempt id 0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0 and vertex id 5e000441d5075bb085278cafa0ec71ad_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 48d622f1fd40077ef7a2adb02cae9703
2025-11-02 15:56:32,661 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[39] -> Calc[40] (1/1) (0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 15:56:32,661 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Join[39] -> Calc[40] (1/1) (attempt #0) with attempt id 0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0 and vertex id 4fda3f41f10225fc13b7996a1749e065_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 48d622f1fd40077ef7a2adb02cae9703
2025-11-02 15:56:32,663 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1) (0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-02 15:56:32,663 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1) (attempt #0) with attempt id 0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0 and vertex id c1426cf63a44e3f9acf0182406d6949f_0 to localhost:51798-3c06be @ localhost (dataPort=51800) with allocation id 48d622f1fd40077ef7a2adb02cae9703
2025-11-02 15:56:32,762 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GlobalWindowAggregate[36] -> Calc[37] (1/1) (0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,763 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[43] -> Calc[44] (1/1) (0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,765 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[39] -> Calc[40] (1/1) (0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,766 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1) (0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,771 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1) (0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,965 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[39] -> Calc[40] (1/1) (0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:56:32,970 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1) (0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:56:32,974 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[43] -> Calc[44] (1/1) (0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:56:33,003 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[30] registering reader for parallel task 0 (#0) @ localhost
2025-11-02 15:56:33,004 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-02 15:56:33,004 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1) (0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:56:33,007 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GlobalWindowAggregate[36] -> Calc[37] (1/1) (0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 16:01:32,577 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node -1 disconnected.
2025-11-02 19:03:03,399 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-03 08:42:37,136 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-03 20:45:23,837 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-03 20:46:57,337 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 16:11:09,464 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,018 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,018 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,018 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,018 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,139 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,139 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,139 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,139 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,139 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,139 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,139 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,139 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,240 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,240 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,341 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,341 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,341 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,341 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,341 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,341 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,544 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,544 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,544 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,544 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:20,544 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,544 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,544 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,544 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,050 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:21,050 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:21,050 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:21,050 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:21,050 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,050 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,050 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,050 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,756 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:21,757 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,757 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:21,757 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,858 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:21,858 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,858 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:21,858 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:22,765 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:22,765 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:22,766 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:22,766 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:22,866 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:22,866 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:22,868 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:22,868 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:25,409 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:25,409 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:25,409 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:25,409 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:25,409 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:25,409 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:25,409 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:25,409 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:26,317 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:26,317 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:26,319 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:26,319 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:26,418 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:26,418 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:26,420 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:26,420 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:27,228 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:27,228 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3209706339673093487-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:27,427 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:27,428 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:27,531 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:27,531 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-6127157721103620611-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:27,630 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Node 1 disconnected.
2025-11-04 17:13:27,630 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource-548571575311059229-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:27,721 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - RECEIVED SIGNAL 15: SIGTERM. Shutting down as requested.
2025-11-04 17:13:27,762 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Shutting StandaloneSessionClusterEntrypoint down with application status UNKNOWN. Diagnostics Cluster entrypoint has been closed externally..
2025-11-04 17:13:27,782 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Stopped BLOB server at 127.0.0.1:49383
