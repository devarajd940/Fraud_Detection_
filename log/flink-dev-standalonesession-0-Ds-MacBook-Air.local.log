2025-11-06 00:18:23,176 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2025-11-06 00:18:23,177 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Preconfiguration: 
2025-11-06 00:18:23,177 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - 


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx1073741824 -Xms1073741824 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D jobmanager.memory.off-heap.size=134217728b -D jobmanager.memory.jvm-overhead.min=201326592b -D jobmanager.memory.jvm-metaspace.size=268435456b -D jobmanager.memory.heap.size=1073741824b -D jobmanager.memory.jvm-overhead.max=201326592b
logs: INFO  [] - Using standard YAML parser to load flink configuration file from /Users/dev/Fraud_Detection/flink-1.20.2/conf/config.yaml.
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1728m
INFO  [] - Loading configuration property: taskmanager.bind-host, localhost
INFO  [] - Loading configuration property: jobmanager.execution.failover-strategy, region
INFO  [] - Loading configuration property: jobmanager.rpc.address, localhost
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1600m
INFO  [] - Loading configuration property: jobmanager.rpc.port, 6123
INFO  [] - Loading configuration property: rest.bind-address, localhost
INFO  [] - Loading configuration property: jobmanager.bind-host, localhost
INFO  [] - Loading configuration property: taskmanager.host, localhost
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 4
INFO  [] - Loading configuration property: rest.address, localhost
INFO  [] - Loading configuration property: env.java.opts.all, --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
INFO  [] - The derived from fraction jvm overhead memory (160.000mb (167772162 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final Master Memory configuration:
INFO  [] -   Total Process Memory: 1.563gb (1677721600 bytes)
INFO  [] -     Total Flink Memory: 1.125gb (1207959552 bytes)
INFO  [] -       JVM Heap:         1024.000mb (1073741824 bytes)
INFO  [] -       Off-heap:         128.000mb (134217728 bytes)
INFO  [] -     JVM Metaspace:      256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:       192.000mb (201326592 bytes)

2025-11-06 00:18:23,177 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2025-11-06 00:18:23,177 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Starting StandaloneSessionClusterEntrypoint (Version: 1.20.2, Scala: 2.12, Rev:1641cb9, Date:2025-06-12T21:40:37+02:00)
2025-11-06 00:18:23,177 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  OS current user: dev
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Current Hadoop/Kerberos user: <no hadoop dependency found>
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM: OpenJDK 64-Bit Server VM - Homebrew - 17/17.0.16+0
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Arch: aarch64
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Maximum heap size: 1024 MiBytes
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JAVA_HOME: /opt/homebrew/opt/openjdk@17
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  No Hadoop Dependency available
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM Options:
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xmx1073741824
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xms1073741824
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -XX:MaxMetaspaceSize=268435456
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -XX:+IgnoreUnrecognizedVMOptions
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=java.base/sun.net.util=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.lang=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.net=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.io=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.nio=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/sun.nio.ch=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.text=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.time=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.util=ALL-UNNAMED
2025-11-06 00:18:23,178 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.util.concurrent=ALL-UNNAMED
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog.file=/Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-standalonesession-0-Ds-MacBook-Air.local.log
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configuration=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/log4j.properties
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configurationFile=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/log4j.properties
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlogback.configurationFile=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/logback.xml
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Program Arguments:
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.off-heap.size=134217728b
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.min=201326592b
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-metaspace.size=268435456b
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.heap.size=1073741824b
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.max=201326592b
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --configDir
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     /Users/dev/Fraud_Detection/flink-1.20.2/conf
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --executionMode
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     cluster
2025-11-06 00:18:23,179 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Classpath: /Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-cep-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-connector-files-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-connector-kafka-3.4.0-1.20.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-csv-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-json-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-scala_2.12-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-api-java-uber-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-planner-loader-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-runtime-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/kafka-clients-3.6.0.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-1.2-api-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-api-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-core-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-slf4j-impl-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-dist-1.20.2.jar::::
2025-11-06 00:18:23,180 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2025-11-06 00:18:23,180 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2025-11-06 00:18:23,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Using standard YAML parser to load flink configuration file from /Users/dev/Fraud_Detection/flink-1.20.2/conf/config.yaml.
2025-11-06 00:18:23,201 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1728m
2025-11-06 00:18:23,201 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.bind-host, localhost
2025-11-06 00:18:23,201 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2025-11-06 00:18:23,201 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2025-11-06 00:18:23,201 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1600m
2025-11-06 00:18:23,201 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2025-11-06 00:18:23,201 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-address, localhost
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.bind-host, localhost
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.host, localhost
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 4
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.address, localhost
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: env.java.opts.all, --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.off-heap.size, 134217728b
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-overhead.min, 201326592b
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-metaspace.size, 268435456b
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.heap.size, 1073741824b
2025-11-06 00:18:23,202 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-overhead.max, 201326592b
2025-11-06 00:18:23,215 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Starting StandaloneSessionClusterEntrypoint.
2025-11-06 00:18:23,230 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install default filesystem.
2025-11-06 00:18:23,231 INFO  org.apache.flink.core.fs.FileSystem                          [] - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2025-11-06 00:18:23,242 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-statsd
2025-11-06 00:18:23,244 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-prometheus
2025-11-06 00:18:23,244 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-graphite
2025-11-06 00:18:23,244 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: external-resource-gpu
2025-11-06 00:18:23,244 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-jmx
2025-11-06 00:18:23,244 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-influx
2025-11-06 00:18:23,244 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-slf4j
2025-11-06 00:18:23,244 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-datadog
2025-11-06 00:18:23,253 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install security context.
2025-11-06 00:18:23,258 INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory [] - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.
2025-11-06 00:18:23,262 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/jaas-5085418964639623017.conf.
2025-11-06 00:18:23,264 INFO  org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory [] - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.
2025-11-06 00:18:23,265 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Initializing cluster services.
2025-11-06 00:18:23,270 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Using working directory: WorkingDirectory(/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/jm_ede46e489f1128012690fc49b9ca2914).
2025-11-06 00:18:23,422 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:6123, bind address localhost:6123.
2025-11-06 00:18:23,733 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-11-06 00:18:23,766 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-11-06 00:18:23,767 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-11-06 00:18:23,875 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink@localhost:6123]
2025-11-06 00:18:23,917 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink@localhost:6123
2025-11-06 00:18:23,923 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Loading delegation token providers
2025-11-06 00:18:23,924 INFO  org.apache.flink.runtime.security.token.hadoop.HadoopFSDelegationTokenProvider [] - Hadoop FS is not available (not packaged with this application): NoClassDefFoundError : "org/apache/hadoop/conf/Configuration".
2025-11-06 00:18:23,924 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hadoopfs loaded and initialized
2025-11-06 00:18:23,925 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hbase loaded and initialized
2025-11-06 00:18:23,925 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-11-06 00:18:23,925 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-11-06 00:18:23,925 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-11-06 00:18:23,925 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-11-06 00:18:23,925 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-11-06 00:18:23,925 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-11-06 00:18:23,925 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-11-06 00:18:23,925 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-11-06 00:18:23,925 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token providers loaded successfully
2025-11-06 00:18:23,926 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2025-11-06 00:18:23,926 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2025-11-06 00:18:23,926 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2025-11-06 00:18:23,926 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-11-06 00:18:23,926 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-11-06 00:18:23,926 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-11-06 00:18:23,926 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-11-06 00:18:23,926 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-11-06 00:18:23,926 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-11-06 00:18:23,926 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-11-06 00:18:23,927 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-11-06 00:18:23,927 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2025-11-06 00:18:23,927 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Checking provider and receiver instances consistency
2025-11-06 00:18:23,927 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Provider and receiver instances are consistent
2025-11-06 00:18:23,927 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Obtaining delegation tokens
2025-11-06 00:18:23,927 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation tokens obtained successfully
2025-11-06 00:18:23,927 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping notifications
2025-11-06 00:18:23,936 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Created BLOB server storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/jm_ede46e489f1128012690fc49b9ca2914/blobStorage
2025-11-06 00:18:23,938 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Started BLOB server at 127.0.0.1:58206 - max concurrent requests: 50 - max backlog: 1000
2025-11-06 00:18:23,944 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2025-11-06 00:18:23,944 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No trace reporter configured, no metrics will be exposed/reported.
2025-11-06 00:18:23,946 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2025-11-06 00:18:23,952 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-11-06 00:18:23,954 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-11-06 00:18:23,954 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-11-06 00:18:23,959 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink-metrics@localhost:58207]
2025-11-06 00:18:23,962 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink-metrics@localhost:58207
2025-11-06 00:18:23,967 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at pekko://flink-metrics/user/rpc/MetricQueryService .
2025-11-06 00:18:24,001 INFO  org.apache.flink.runtime.dispatcher.FileExecutionGraphInfoStore [] - Initializing FileExecutionGraphInfoStore: Storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/executionGraphStore-87617787-82e3-4dd7-bf03-b7d3cda01bd8, expiration time 3600000, maximum cache size 52428800 bytes.
2025-11-06 00:18:24,022 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Upload directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-web-bcc50c2f-b69b-4b8c-82d8-71698a60fee4/flink-web-upload does not exist. 
2025-11-06 00:18:24,023 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Created directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-web-bcc50c2f-b69b-4b8c-82d8-71698a60fee4/flink-web-upload for file uploads.
2025-11-06 00:18:24,024 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Starting rest endpoint.
2025-11-06 00:18:24,137 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component log file: /Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-standalonesession-0-Ds-MacBook-Air.local.log
2025-11-06 00:18:24,137 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component stdout file: /Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-standalonesession-0-Ds-MacBook-Air.local.out
2025-11-06 00:18:24,146 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Rest endpoint listening at 127.0.0.1:8081
2025-11-06 00:18:24,147 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - http://127.0.0.1:8081 was granted leadership with leaderSessionID=00000000-0000-0000-0000-000000000000
2025-11-06 00:18:24,148 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Web frontend listening at http://127.0.0.1:8081.
2025-11-06 00:18:24,155 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner [] - DefaultDispatcherRunner was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new DispatcherLeaderProcess.
2025-11-06 00:18:24,157 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Start SessionDispatcherLeaderProcess.
2025-11-06 00:18:24,157 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Starting resource manager service.
2025-11-06 00:18:24,158 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Resource manager service is granted leadership with session id 00000000-0000-0000-0000-000000000000.
2025-11-06 00:18:24,159 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Recover all persisted job graphs that are not finished, yet.
2025-11-06 00:18:24,160 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Successfully recovered 0 persisted job graphs.
2025-11-06 00:18:24,166 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at pekko://flink/user/rpc/dispatcher_0 .
2025-11-06 00:18:24,170 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at pekko://flink/user/rpc/resourcemanager_1 .
2025-11-06 00:18:24,173 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Starting the resource manager.
2025-11-06 00:18:24,177 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Starting the slot manager.
2025-11-06 00:18:24,177 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Starting tokens update task
2025-11-06 00:18:24,177 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping notifications
2025-11-06 00:18:24,177 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date
2025-11-06 00:18:25,123 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering TaskManager with ResourceID localhost:58208-561ceb (pekko.tcp://flink@localhost:58208/user/rpc/taskmanager_0) at ResourceManager
2025-11-06 00:18:25,139 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Registering task executor localhost:58208-561ceb under 0731f03369374112b1d640acdcd294cc at the slot manager.
2025-11-06 00:19:33,217 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,219 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,227 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 3d1eb7b24d44e5885efc6ab7672308f1 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-06 00:19:33,231 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_2 .
2025-11-06 00:19:33,235 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,249 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,263 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 26404d29448fb2b69526e4dd926b07e1 for job 3d1eb7b24d44e5885efc6ab7672308f1.
2025-11-06 00:19:33,271 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,271 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-06 00:19:33,305 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-06 00:19:33,308 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@44d1e8b0
2025-11-06 00:19:33,308 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:19:33,308 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:19:33,326 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-06 00:19:33,329 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@3811a628 for SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,334 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (3d1eb7b24d44e5885efc6ab7672308f1) under job master id 00000000000000000000000000000000.
2025-11-06 00:19:33,335 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Transactions[1].
2025-11-06 00:19:33,337 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-06 00:19:33,337 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (3d1eb7b24d44e5885efc6ab7672308f1) switched from state CREATED to RUNNING.
2025-11-06 00:19:33,342 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[1] -> Sink: Collect table sink (1/1) (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:19:33,351 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-06 00:19:33,351 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-06 00:19:33,353 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-06 00:19:33,354 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 3d1eb7b24d44e5885efc6ab7672308f1.
2025-11-06 00:19:33,356 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 3d1eb7b24d44e5885efc6ab7672308f1.
2025-11-06 00:19:33,356 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-06 00:19:33,357 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 3d1eb7b24d44e5885efc6ab7672308f1: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-06 00:19:33,374 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-06 00:19:33,374 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:19:33,374 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:19:33,374 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762368573374
2025-11-06 00:19:33,375 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-06 00:19:33,418 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 3d1eb7b24d44e5885efc6ab7672308f1
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:58208-561ceb
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-06 00:19:33,420 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 514a40386c6f271ee09789bb932c5d5e from localhost:58208-561ceb for job 3d1eb7b24d44e5885efc6ab7672308f1 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:19:33,466 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[1] -> Sink: Collect table sink (1/1) (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:19:33,468 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Transactions[1] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id 514a40386c6f271ee09789bb932c5d5e
2025-11-06 00:19:33,559 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[1] -> Sink: Collect table sink (1/1) (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:19:33,570 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-06 00:19:33,712 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:58413
2025-11-06 00:19:33,715 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Transactions[1] registering reader for parallel task 0 (#0) @ localhost
2025-11-06 00:19:33,717 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]}
2025-11-06 00:19:33,725 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[1] -> Sink: Collect table sink (1/1) (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:19:33,794 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-06 00:19:33,941 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Transactions[1] -> Sink: Collect table sink (1/1) (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED on localhost:58208-561ceb @ localhost (dataPort=58210).
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-06 00:19:33,954 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 3d1eb7b24d44e5885efc6ab7672308f1
2025-11-06 00:19:33,957 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: Transactions[1].
2025-11-06 00:19:33,958 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (3d1eb7b24d44e5885efc6ab7672308f1) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-06 00:19:33,960 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions` (3d1eb7b24d44e5885efc6ab7672308f1) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-06 00:19:33,961 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 3d1eb7b24d44e5885efc6ab7672308f1.
2025-11-06 00:19:33,965 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 3d1eb7b24d44e5885efc6ab7672308f1 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224)
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165)
	... 6 more
2025-11-06 00:19:33,976 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,977 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Transactions[1].
2025-11-06 00:19:33,978 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-06 00:19:33,978 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-06 00:19:33,979 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-06 00:19:33,980 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [514a40386c6f271ee09789bb932c5d5e].
2025-11-06 00:19:33,980 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:58208-561ceb because: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,981 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection ede46e489f1128012690fc49b9ca2914: Stopping JobMaster for job 'SELECT `Transactions`.`TransactionID`, `Transactions`.`AccountID`, `Transactions`.`TransactionAmount`, `Transactions`.`TransactionDate`, `Transactions`.`TransactionType`, `Transactions`.`Location`, `Transactions`.`DeviceID`, `Transactions`.`IPAddress`, `Transactions`.`MerchantID`, `Transactions`.`Channel`, `Transactions`.`CustomerAge`, `Transactions`.`CustomerOccupation`, `Transactions`.`TransactionDuration`, `Transactions`.`LoginAttempts`, `Transactions`.`AccountBalance`, `Transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`Transactions` AS `Transactions`' (3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,981 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:19:33,981 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:19:33,981 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:19:33,982 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 3d1eb7b24d44e5885efc6ab7672308f1 from the resource manager.
2025-11-06 00:19:33,982 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Transactions[1] closed.
2025-11-06 00:19:33,987 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 514a40386c6f271ee09789bb932c5d5e.
2025-11-06 00:29:46,327 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,327 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,328 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 8523860244483d33dcb88d4181aed1ac was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-06 00:29:46,330 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_3 .
2025-11-06 00:29:46,330 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,331 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,332 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 1965a48cce53713e15a553fa65e423d2 for job 8523860244483d33dcb88d4181aed1ac.
2025-11-06 00:29:46,332 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,332 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-06 00:29:46,335 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-06 00:29:46,335 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@183e114c
2025-11-06 00:29:46,335 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:29:46,335 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:29:46,336 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-06 00:29:46,336 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@5a0ac6ad for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,337 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8523860244483d33dcb88d4181aed1ac) under job master id 00000000000000000000000000000000.
2025-11-06 00:29:46,337 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[3].
2025-11-06 00:29:46,337 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-06 00:29:46,337 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8523860244483d33dcb88d4181aed1ac) switched from state CREATED to RUNNING.
2025-11-06 00:29:46,337 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[3] -> Sink: Collect table sink (1/1) (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:29:46,338 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-06 00:29:46,338 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-06 00:29:46,339 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-06 00:29:46,340 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job 8523860244483d33dcb88d4181aed1ac.
2025-11-06 00:29:46,340 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job 8523860244483d33dcb88d4181aed1ac.
2025-11-06 00:29:46,341 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-06 00:29:46,341 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 8523860244483d33dcb88d4181aed1ac: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-06 00:29:46,342 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-06 00:29:46,342 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:29:46,342 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:29:46,342 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762369186342
2025-11-06 00:29:46,343 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-06 00:29:46,352 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-06 00:29:46,412 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 8523860244483d33dcb88d4181aed1ac
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:58208-561ceb
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-06 00:29:46,413 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 50bee677f2badb8c7ff2503b8f1404ba from localhost:58208-561ceb for job 8523860244483d33dcb88d4181aed1ac with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:29:46,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[3] -> Sink: Collect table sink (1/1) (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:29:46,438 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[3] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id 50bee677f2badb8c7ff2503b8f1404ba
2025-11-06 00:29:46,466 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[3] -> Sink: Collect table sink (1/1) (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:29:46,480 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:59446
2025-11-06 00:29:46,480 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[3] registering reader for parallel task 0 (#0) @ localhost
2025-11-06 00:29:46,481 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]}
2025-11-06 00:29:46,482 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[3] -> Sink: Collect table sink (1/1) (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:29:46,505 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-06 00:29:46,522 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[3] -> Sink: Collect table sink (1/1) (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED on localhost:58208-561ceb @ localhost (dataPort=58210).
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-06 00:29:46,524 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 8523860244483d33dcb88d4181aed1ac
2025-11-06 00:29:46,525 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: bank_transactions[3].
2025-11-06 00:29:46,525 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8523860244483d33dcb88d4181aed1ac) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-06 00:29:46,527 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (8523860244483d33dcb88d4181aed1ac) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-06 00:29:46,527 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 8523860244483d33dcb88d4181aed1ac.
2025-11-06 00:29:46,529 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 8523860244483d33dcb88d4181aed1ac reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224)
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165)
	... 6 more
2025-11-06 00:29:46,532 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,533 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[3].
2025-11-06 00:29:46,533 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-06 00:29:46,533 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-06 00:29:46,534 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [50bee677f2badb8c7ff2503b8f1404ba].
2025-11-06 00:29:46,534 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:58208-561ceb because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,534 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection ede46e489f1128012690fc49b9ca2914: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,534 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job 8523860244483d33dcb88d4181aed1ac from the resource manager.
2025-11-06 00:29:46,534 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-06 00:29:46,537 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:29:46,537 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:29:46,537 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:29:46,538 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[3] closed.
2025-11-06 00:29:46,539 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 50bee677f2badb8c7ff2503b8f1404ba.
2025-11-06 00:34:39,629 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:39,630 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:39,631 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 10eb6caec79f41c59376b243828b6df4 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-06 00:34:39,633 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_4 .
2025-11-06 00:34:39,633 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:39,635 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:39,636 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 0a76de0710d2646d7c4e351b0a44c4cd for job 10eb6caec79f41c59376b243828b6df4.
2025-11-06 00:34:39,637 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:39,637 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-06 00:34:39,642 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-06 00:34:39,642 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@530b75de
2025-11-06 00:34:39,642 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:34:39,642 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:34:39,643 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-06 00:34:39,643 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@17e95a3 for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:39,643 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (10eb6caec79f41c59376b243828b6df4) under job master id 00000000000000000000000000000000.
2025-11-06 00:34:39,643 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[5].
2025-11-06 00:34:39,643 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-06 00:34:39,644 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (10eb6caec79f41c59376b243828b6df4) switched from state CREATED to RUNNING.
2025-11-06 00:34:39,644 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1) (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:34:39,644 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-06 00:34:39,644 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-06 00:34:39,646 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-06 00:34:39,646 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job 10eb6caec79f41c59376b243828b6df4.
2025-11-06 00:34:39,646 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-06 00:34:39,647 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:34:39,647 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:34:39,647 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762369479647
2025-11-06 00:34:39,647 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job 10eb6caec79f41c59376b243828b6df4.
2025-11-06 00:34:39,647 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-06 00:34:39,647 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-06 00:34:39,648 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 10eb6caec79f41c59376b243828b6df4: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-06 00:34:39,658 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-06 00:34:39,710 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 10eb6caec79f41c59376b243828b6df4
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:58208-561ceb
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-06 00:34:39,711 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot c7d866e63b870ee0be20445ba3c71283 from localhost:58208-561ceb for job 10eb6caec79f41c59376b243828b6df4 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:34:39,743 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1) (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:34:39,745 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[5] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id c7d866e63b870ee0be20445ba3c71283
2025-11-06 00:34:39,773 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1) (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:34:39,790 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:60015
2025-11-06 00:34:39,791 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[5] registering reader for parallel task 0 (#0) @ localhost
2025-11-06 00:34:39,791 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: 2512, StoppingOffset: -9223372036854775808]]}
2025-11-06 00:34:39,791 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1) (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:34:39,816 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-06 00:34:45,825 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (10eb6caec79f41c59376b243828b6df4) switched from state RUNNING to CANCELLING.
2025-11-06 00:34:45,825 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1) (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-06 00:34:45,928 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-06 00:34:46,040 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-06 00:34:46,155 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-06 00:34:46,250 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1) (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-06 00:34:46,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (10eb6caec79f41c59376b243828b6df4) switched from state CANCELLING to CANCELED.
2025-11-06 00:34:46,251 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 10eb6caec79f41c59376b243828b6df4.
2025-11-06 00:34:46,251 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 10eb6caec79f41c59376b243828b6df4
2025-11-06 00:34:46,252 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 10eb6caec79f41c59376b243828b6df4 reached terminal state CANCELED.
2025-11-06 00:34:46,257 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:46,258 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-06 00:34:46,258 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[5].
2025-11-06 00:34:46,258 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-06 00:34:46,259 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [c7d866e63b870ee0be20445ba3c71283].
2025-11-06 00:34:46,259 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:58208-561ceb because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:46,259 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection ede46e489f1128012690fc49b9ca2914: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:46,259 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job 10eb6caec79f41c59376b243828b6df4 from the resource manager.
2025-11-06 00:34:46,259 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-06 00:34:46,261 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:34:46,261 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:34:46,261 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:34:46,261 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[5] closed.
2025-11-06 00:34:46,263 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot c7d866e63b870ee0be20445ba3c71283.
2025-11-06 00:35:18,388 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:18,389 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:18,389 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job f8db9ac8636b2d020c59b3c865773346 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-06 00:35:18,390 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_5 .
2025-11-06 00:35:18,391 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:18,391 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:18,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 031d31755902136904cc276b9d0ccee8 for job f8db9ac8636b2d020c59b3c865773346.
2025-11-06 00:35:18,392 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:18,392 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-06 00:35:18,394 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-06 00:35:18,394 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@118233c0
2025-11-06 00:35:18,394 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:35:18,394 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:35:18,394 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-06 00:35:18,394 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@43f70282 for SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:18,395 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (f8db9ac8636b2d020c59b3c865773346) under job master id 00000000000000000000000000000000.
2025-11-06 00:35:18,395 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[7].
2025-11-06 00:35:18,395 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-06 00:35:18,395 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (f8db9ac8636b2d020c59b3c865773346) switched from state CREATED to RUNNING.
2025-11-06 00:35:18,395 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1) (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:35:18,395 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-06 00:35:18,395 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-06 00:35:18,396 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-06 00:35:18,396 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job f8db9ac8636b2d020c59b3c865773346.
2025-11-06 00:35:18,396 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job f8db9ac8636b2d020c59b3c865773346.
2025-11-06 00:35:18,397 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-06 00:35:18,397 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:35:18,397 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:35:18,397 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762369518397
2025-11-06 00:35:18,397 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-06 00:35:18,397 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job f8db9ac8636b2d020c59b3c865773346: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-06 00:35:18,397 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-06 00:35:18,406 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-06 00:35:18,461 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job f8db9ac8636b2d020c59b3c865773346
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:58208-561ceb
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-06 00:35:18,461 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 8720892abccdfd412244e31f3985bca0 from localhost:58208-561ceb for job f8db9ac8636b2d020c59b3c865773346 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:35:18,472 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1) (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:35:18,474 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[7] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id 031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id 8720892abccdfd412244e31f3985bca0
2025-11-06 00:35:18,487 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1) (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:35:18,497 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:62821
2025-11-06 00:35:18,498 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[7] registering reader for parallel task 0 (#0) @ localhost
2025-11-06 00:35:18,498 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-06 00:35:18,498 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1) (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:35:18,566 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-06 00:35:23,574 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (f8db9ac8636b2d020c59b3c865773346) switched from state RUNNING to CANCELLING.
2025-11-06 00:35:23,574 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1) (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-06 00:35:23,687 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-06 00:35:23,798 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-06 00:35:23,898 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1) (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-06 00:35:23,899 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions` (f8db9ac8636b2d020c59b3c865773346) switched from state CANCELLING to CANCELED.
2025-11-06 00:35:23,899 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job f8db9ac8636b2d020c59b3c865773346
2025-11-06 00:35:23,899 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job f8db9ac8636b2d020c59b3c865773346.
2025-11-06 00:35:23,900 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job f8db9ac8636b2d020c59b3c865773346 reached terminal state CANCELED.
2025-11-06 00:35:23,903 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:23,903 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-06 00:35:23,904 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-06 00:35:23,903 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: bank_transactions[7].
2025-11-06 00:35:23,904 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [8720892abccdfd412244e31f3985bca0].
2025-11-06 00:35:23,904 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:58208-561ceb because: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:23,904 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection ede46e489f1128012690fc49b9ca2914: Stopping JobMaster for job 'SELECT `bank_transactions`.`TransactionID`, `bank_transactions`.`AccountID`, `bank_transactions`.`TransactionAmount`, `bank_transactions`.`TransactionDate`, `bank_transactions`.`TransactionType`, `bank_transactions`.`Location`, `bank_transactions`.`DeviceID`, `bank_transactions`.`IP Address`, `bank_transactions`.`MerchantID`, `bank_transactions`.`Channel`, `bank_transactions`.`CustomerAge`, `bank_transactions`.`CustomerOccupation`, `bank_transactions`.`TransactionDuration`, `bank_transactions`.`LoginAttempts`, `bank_transactions`.`AccountBalance`, `bank_transactions`.`PreviousTransactionDate`
FROM `default_catalog`.`default_database`.`bank_transactions` AS `bank_transactions`' (f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:23,904 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-06 00:35:23,905 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job f8db9ac8636b2d020c59b3c865773346 from the resource manager.
2025-11-06 00:35:23,906 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:35:23,906 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:35:23,906 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:35:23,907 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: bank_transactions[7] closed.
2025-11-06 00:35:23,909 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot 8720892abccdfd412244e31f3985bca0.
2025-11-06 00:45:32,699 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,700 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,700 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job cd2386fda47b118106c8361b9776ae13 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-06 00:45:32,703 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_6 .
2025-11-06 00:45:32,703 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,704 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,704 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph fde20c2ad244ffbc14563ea9edb6c13a for job cd2386fda47b118106c8361b9776ae13.
2025-11-06 00:45:32,704 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,704 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-06 00:45:32,707 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-06 00:45:32,707 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@10441e3
2025-11-06 00:45:32,707 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:45:32,707 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:45:32,707 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-06 00:45:32,707 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@68621863 for SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,708 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (cd2386fda47b118106c8361b9776ae13) under job master id 00000000000000000000000000000000.
2025-11-06 00:45:32,708 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: fraud_alerts[11].
2025-11-06 00:45:32,708 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-06 00:45:32,708 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (cd2386fda47b118106c8361b9776ae13) switched from state CREATED to RUNNING.
2025-11-06 00:45:32,708 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[11] -> Sink: Collect table sink (1/1) (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:45:32,708 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-06 00:45:32,708 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-06 00:45:32,709 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-06 00:45:32,709 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job cd2386fda47b118106c8361b9776ae13.
2025-11-06 00:45:32,709 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job cd2386fda47b118106c8361b9776ae13.
2025-11-06 00:45:32,710 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-06 00:45:32,710 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job cd2386fda47b118106c8361b9776ae13: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-06 00:45:32,710 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-06 00:45:32,710 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:45:32,710 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:45:32,710 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762370132710
2025-11-06 00:45:32,710 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-06 00:45:32,719 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [fraud_alerts-0]
2025-11-06 00:45:32,780 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job cd2386fda47b118106c8361b9776ae13
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:58208-561ceb
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-06 00:45:32,780 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot b6d99023b0b70ffb267e39de305b24b9 from localhost:58208-561ceb for job cd2386fda47b118106c8361b9776ae13 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:45:32,801 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[11] -> Sink: Collect table sink (1/1) (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:45:32,806 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: fraud_alerts[11] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id b6d99023b0b70ffb267e39de305b24b9
2025-11-06 00:45:32,822 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[11] -> Sink: Collect table sink (1/1) (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:45:32,832 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:62298
2025-11-06 00:45:32,832 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: fraud_alerts[11] registering reader for parallel task 0 (#0) @ localhost
2025-11-06 00:45:32,833 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: fraud_alerts-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]}
2025-11-06 00:45:32,833 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[11] -> Sink: Collect table sink (1/1) (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:45:32,873 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-06 00:45:32,876 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[11] -> Sink: Collect table sink (1/1) (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED on localhost:58208-561ceb @ localhost (dataPort=58210).
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [fraud_alerts-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-06 00:45:32,877 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job cd2386fda47b118106c8361b9776ae13
2025-11-06 00:45:32,877 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: fraud_alerts[11].
2025-11-06 00:45:32,877 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (cd2386fda47b118106c8361b9776ae13) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [fraud_alerts-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-06 00:45:32,878 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (cd2386fda47b118106c8361b9776ae13) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.base/java.lang.reflect.Method.invoke(Method.java:569) ~[?:?]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174) ~[flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245) [flink-rpc-akkae9d9cfbf-3d61-47a1-bae2-343d156c1aad.jar:1.20.2]
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [fraud_alerts-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-11-06 00:45:32,879 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job cd2386fda47b118106c8361b9776ae13.
2025-11-06 00:45:32,880 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job cd2386fda47b118106c8361b9776ae13 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:219)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailureAndReport(ExecutionFailureHandler.java:166)
	at org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:121)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:281)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:272)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:265)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:788)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:765)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:515)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:318)
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:316)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:229)
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:88)
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:174)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:272)
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:233)
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:245)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [fraud_alerts-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727)
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224)
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165)
	... 6 more
2025-11-06 00:45:32,883 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,883 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-06 00:45:32,883 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-06 00:45:32,883 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [b6d99023b0b70ffb267e39de305b24b9].
2025-11-06 00:45:32,883 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: fraud_alerts[11].
2025-11-06 00:45:32,883 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:58208-561ceb because: Stopping JobMaster for job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,883 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection ede46e489f1128012690fc49b9ca2914: Stopping JobMaster for job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,884 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job cd2386fda47b118106c8361b9776ae13 from the resource manager.
2025-11-06 00:45:32,884 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-06 00:45:32,885 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:45:32,885 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:45:32,886 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:45:32,886 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot b6d99023b0b70ffb267e39de305b24b9.
2025-11-06 00:45:32,888 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: fraud_alerts[11] closed.
2025-11-06 00:47:40,196 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:47:40,197 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:47:40,197 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 6838c0282a56a12fd35a2c5439010c3f was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-06 00:47:40,200 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_7 .
2025-11-06 00:47:40,201 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:47:40,202 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:47:40,202 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph f718b06da9308ed319bd6ea70c037b61 for job 6838c0282a56a12fd35a2c5439010c3f.
2025-11-06 00:47:40,202 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:47:40,202 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-06 00:47:40,205 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-06 00:47:40,205 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3980d8cf
2025-11-06 00:47:40,205 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:47:40,205 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:47:40,205 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-06 00:47:40,205 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@4112a36d for SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:47:40,205 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (6838c0282a56a12fd35a2c5439010c3f) under job master id 00000000000000000000000000000000.
2025-11-06 00:47:40,206 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: fraud_alerts[13].
2025-11-06 00:47:40,206 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-06 00:47:40,206 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (6838c0282a56a12fd35a2c5439010c3f) switched from state CREATED to RUNNING.
2025-11-06 00:47:40,206 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1) (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:47:40,206 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-06 00:47:40,206 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-06 00:47:40,207 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-06 00:47:40,207 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_7 for job 6838c0282a56a12fd35a2c5439010c3f.
2025-11-06 00:47:40,208 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_7 for job 6838c0282a56a12fd35a2c5439010c3f.
2025-11-06 00:47:40,208 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-06 00:47:40,208 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:47:40,208 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:47:40,208 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762370260208
2025-11-06 00:47:40,208 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-06 00:47:40,208 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 6838c0282a56a12fd35a2c5439010c3f: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-06 00:47:40,208 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-06 00:47:40,219 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [fraud_alerts-0]
2025-11-06 00:47:40,272 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 6838c0282a56a12fd35a2c5439010c3f
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:58208-561ceb
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-06 00:47:40,273 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot c94dc1619f308efc85ce79c4e11625bf from localhost:58208-561ceb for job 6838c0282a56a12fd35a2c5439010c3f with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:47:40,289 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1) (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:47:40,290 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: fraud_alerts[13] -> Sink: Collect table sink (1/1) (attempt #0) with attempt id f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id c94dc1619f308efc85ce79c4e11625bf
2025-11-06 00:47:40,318 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1) (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:47:40,325 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Received sink socket server address: localhost/127.0.0.1:63252
2025-11-06 00:47:40,326 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: fraud_alerts[13] registering reader for parallel task 0 (#0) @ localhost
2025-11-06 00:47:40,326 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: fraud_alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-06 00:47:40,326 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1) (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:47:40,370 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Sink connection established
2025-11-06 00:48:16,344 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (6838c0282a56a12fd35a2c5439010c3f) switched from state RUNNING to CANCELLING.
2025-11-06 00:48:16,347 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1) (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-06 00:48:16,457 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.SocketException: Broken pipe
2025-11-06 00:48:16,567 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-06 00:48:16,675 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-06 00:48:16,785 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-06 00:48:16,908 WARN  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Collect sink coordinator encounters a CompletionException: java.net.ConnectException: Connection refused
2025-11-06 00:48:16,917 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1) (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-06 00:48:16,918 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts` (6838c0282a56a12fd35a2c5439010c3f) switched from state CANCELLING to CANCELED.
2025-11-06 00:48:16,918 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job 6838c0282a56a12fd35a2c5439010c3f
2025-11-06 00:48:16,918 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 6838c0282a56a12fd35a2c5439010c3f.
2025-11-06 00:48:16,919 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 6838c0282a56a12fd35a2c5439010c3f reached terminal state CANCELED.
2025-11-06 00:48:16,922 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:48:16,923 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkOperatorCoordinator [] - Closing the CollectSinkOperatorCoordinator.
2025-11-06 00:48:16,923 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2025-11-06 00:48:16,923 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: fraud_alerts[13].
2025-11-06 00:48:16,923 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [c94dc1619f308efc85ce79c4e11625bf].
2025-11-06 00:48:16,923 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:58208-561ceb because: Stopping JobMaster for job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:48:16,923 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection ede46e489f1128012690fc49b9ca2914: Stopping JobMaster for job 'SELECT `fraud_alerts`.`TransactionID`, `fraud_alerts`.`AccountID`, `fraud_alerts`.`TransactionAmount`, `fraud_alerts`.`TransactionDate`, `fraud_alerts`.`TransactionType`, `fraud_alerts`.`Location`, `fraud_alerts`.`DeviceID`, `fraud_alerts`.`IP Address`, `fraud_alerts`.`MerchantID`, `fraud_alerts`.`Channel`, `fraud_alerts`.`CustomerAge`, `fraud_alerts`.`CustomerOccupation`, `fraud_alerts`.`TransactionDuration`, `fraud_alerts`.`LoginAttempts`, `fraud_alerts`.`AccountBalance`, `fraud_alerts`.`PreviousTransactionDate`, `fraud_alerts`.`alert_type`, `fraud_alerts`.`alert_time`
FROM `default_catalog`.`default_database`.`fraud_alerts` AS `fraud_alerts`' (6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:48:16,923 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_7 for job 6838c0282a56a12fd35a2c5439010c3f from the resource manager.
2025-11-06 00:48:16,924 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for flink-consumer-group-enumerator-admin-client unregistered
2025-11-06 00:48:16,925 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:48:16,925 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:48:16,925 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:48:16,925 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: fraud_alerts[13] closed.
2025-11-06 00:48:16,928 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Freeing slot c94dc1619f308efc85ce79c4e11625bf.
2025-11-06 00:54:45,552 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'insert-into_default_catalog.default_database.fraud_alerts' (99cc4dbedc6b43cb38426cc7205f57a3).
2025-11-06 00:54:45,552 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'insert-into_default_catalog.default_database.fraud_alerts' (99cc4dbedc6b43cb38426cc7205f57a3).
2025-11-06 00:54:45,553 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job 99cc4dbedc6b43cb38426cc7205f57a3 was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2025-11-06 00:54:45,560 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_8 .
2025-11-06 00:54:45,561 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'insert-into_default_catalog.default_database.fraud_alerts' (99cc4dbedc6b43cb38426cc7205f57a3).
2025-11-06 00:54:45,561 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.fraud_alerts (99cc4dbedc6b43cb38426cc7205f57a3).
2025-11-06 00:54:45,562 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 902f24fb1630037e82f9c6c8929192fc for job 99cc4dbedc6b43cb38426cc7205f57a3.
2025-11-06 00:54:45,563 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.fraud_alerts (99cc4dbedc6b43cb38426cc7205f57a3).
2025-11-06 00:54:45,563 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2025-11-06 00:54:45,564 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) exceeded the 80 characters length limit and was truncated.
2025-11-06 00:54:45,570 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2025-11-06 00:54:45,571 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@18e789ad
2025-11-06 00:54:45,571 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:54:45,571 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:54:45,571 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2025-11-06 00:54:45,571 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.RestartPipelinedRegionFailoverStrategy@3b90ad83 for insert-into_default_catalog.default_database.fraud_alerts (99cc4dbedc6b43cb38426cc7205f57a3).
2025-11-06 00:54:45,572 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'insert-into_default_catalog.default_database.fraud_alerts' (99cc4dbedc6b43cb38426cc7205f57a3) under job master id 00000000000000000000000000000000.
2025-11-06 00:54:45,572 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: bank_transactions[15].
2025-11-06 00:54:45,572 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2025-11-06 00:54:45,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.fraud_alerts (99cc4dbedc6b43cb38426cc7205f57a3) switched from state CREATED to RUNNING.
2025-11-06 00:54:45,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1) (902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:54:45,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[28] -> Calc[29] (1/1) (902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:54:45,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GlobalWindowAggregate[21] -> Calc[22] (1/1) (902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:54:45,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[24] -> Calc[25] (1/1) (902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:54:45,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1) (902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from CREATED to SCHEDULED.
2025-11-06 00:54:45,573 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2025-11-06 00:54:45,573 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-11-06 00:54:45,574 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2025-11-06 00:54:45,575 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_8 for job 99cc4dbedc6b43cb38426cc7205f57a3.
2025-11-06 00:54:45,575 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2025-11-06 00:54:45,575 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:54:45,575 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:54:45,575 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762370685575
2025-11-06 00:54:45,575 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group flink-consumer-group with partition discovery interval of 300000 ms.
2025-11-06 00:54:45,575 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_8 for job 99cc4dbedc6b43cb38426cc7205f57a3.
2025-11-06 00:54:45,575 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2025-11-06 00:54:45,576 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job 99cc4dbedc6b43cb38426cc7205f57a3: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2025-11-06 00:54:45,585 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [bank_transactions-0]
2025-11-06 00:54:45,642 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job 99cc4dbedc6b43cb38426cc7205f57a3
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager localhost:58208-561ceb
		Available: ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
		Total:     ResourceProfile{cpuCores=4, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}
2025-11-06 00:54:45,643 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 7a957edf10c763bbcd16ec3f75c61723 from localhost:58208-561ceb for job 99cc4dbedc6b43cb38426cc7205f57a3 with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:54:45,657 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1) (902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:54:45,660 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1) (attempt #0) with attempt id 902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0 and vertex id 5da08a4269629ebce1b7dfad7a855276_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id 7a957edf10c763bbcd16ec3f75c61723
2025-11-06 00:54:45,660 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[28] -> Calc[29] (1/1) (902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:54:45,660 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Join[28] -> Calc[29] (1/1) (attempt #0) with attempt id 902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0 and vertex id f903181e99c89a09cba2df29130e7591_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id 7a957edf10c763bbcd16ec3f75c61723
2025-11-06 00:54:45,670 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GlobalWindowAggregate[21] -> Calc[22] (1/1) (902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:54:45,670 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying GlobalWindowAggregate[21] -> Calc[22] (1/1) (attempt #0) with attempt id 902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0 and vertex id 5e000441d5075bb085278cafa0ec71ad_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id 7a957edf10c763bbcd16ec3f75c61723
2025-11-06 00:54:45,671 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[24] -> Calc[25] (1/1) (902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:54:45,671 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Join[24] -> Calc[25] (1/1) (attempt #0) with attempt id 902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0 and vertex id 4fda3f41f10225fc13b7996a1749e065_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id 7a957edf10c763bbcd16ec3f75c61723
2025-11-06 00:54:45,672 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1) (902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from SCHEDULED to DEPLOYING.
2025-11-06 00:54:45,672 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1) (attempt #0) with attempt id 902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0 and vertex id c1426cf63a44e3f9acf0182406d6949f_0 to localhost:58208-561ceb @ localhost (dataPort=58210) with allocation id 7a957edf10c763bbcd16ec3f75c61723
2025-11-06 00:54:45,727 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1) (902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,728 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[28] -> Calc[29] (1/1) (902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,728 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GlobalWindowAggregate[21] -> Calc[22] (1/1) (902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,728 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[24] -> Calc[25] (1/1) (902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,730 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1) (902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,858 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1) (902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,860 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[24] -> Calc[25] (1/1) (902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,866 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Join[28] -> Calc[29] (1/1) (902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,886 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GlobalWindowAggregate[21] -> Calc[22] (1/1) (902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,886 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: bank_transactions[15] registering reader for parallel task 0 (#0) @ localhost
2025-11-06 00:54:45,886 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1) (902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,886 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2025-11-06 02:17:11,525 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node -1 disconnected.
2025-11-07 08:34:13,918 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=flink-consumer-group-enumerator-admin-client] Node 1 disconnected.
