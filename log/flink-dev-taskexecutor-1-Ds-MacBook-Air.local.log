2025-11-02 12:43:18,157 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-11-02 12:43:18,158 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Preconfiguration: 
2025-11-02 12:43:18,158 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - 


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx536870902 -Xms536870902 -XX:MaxDirectMemorySize=268435458 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D taskmanager.memory.network.min=134217730b -D taskmanager.cpu.cores=4.0 -D taskmanager.memory.task.off-heap.size=0b -D taskmanager.memory.jvm-metaspace.size=268435456b -D external-resources=none -D taskmanager.memory.jvm-overhead.min=201326592b -D taskmanager.memory.framework.off-heap.size=134217728b -D taskmanager.memory.network.max=134217730b -D taskmanager.memory.framework.heap.size=134217728b -D taskmanager.memory.managed.size=536870920b -D taskmanager.memory.task.heap.size=402653174b -D taskmanager.numberOfTaskSlots=4 -D taskmanager.memory.jvm-overhead.max=201326592b
logs: INFO  [] - Using standard YAML parser to load flink configuration file from /Users/dev/Fraud_Detection/flink-1.20.2/conf/config.yaml.
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1728m
INFO  [] - Loading configuration property: taskmanager.bind-host, localhost
INFO  [] - Loading configuration property: jobmanager.execution.failover-strategy, region
INFO  [] - Loading configuration property: jobmanager.rpc.address, localhost
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1600m
INFO  [] - Loading configuration property: jobmanager.rpc.port, 6123
INFO  [] - Loading configuration property: rest.bind-address, localhost
INFO  [] - Loading configuration property: jobmanager.bind-host, localhost
INFO  [] - Loading configuration property: taskmanager.host, localhost
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 4
INFO  [] - Loading configuration property: rest.address, localhost
INFO  [] - Loading configuration property: env.java.opts.all, --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
INFO  [] - The derived from fraction jvm overhead memory (172.800mb (181193935 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final TaskExecutor Memory configuration:
INFO  [] -   Total Process Memory:          1.688gb (1811939328 bytes)
INFO  [] -     Total Flink Memory:          1.250gb (1342177280 bytes)
INFO  [] -       Total JVM Heap Memory:     512.000mb (536870902 bytes)
INFO  [] -         Framework:               128.000mb (134217728 bytes)
INFO  [] -         Task:                    384.000mb (402653174 bytes)
INFO  [] -       Total Off-heap Memory:     768.000mb (805306378 bytes)
INFO  [] -         Managed:                 512.000mb (536870920 bytes)
INFO  [] -         Total JVM Direct Memory: 256.000mb (268435458 bytes)
INFO  [] -           Framework:             128.000mb (134217728 bytes)
INFO  [] -           Task:                  0 bytes
INFO  [] -           Network:               128.000mb (134217730 bytes)
INFO  [] -     JVM Metaspace:               256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:                192.000mb (201326592 bytes)

2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Starting TaskManager (Version: 1.20.2, Scala: 2.12, Rev:1641cb9, Date:2025-06-12T21:40:37+02:00)
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  OS current user: dev
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Current Hadoop/Kerberos user: <no hadoop dependency found>
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM: OpenJDK 64-Bit Server VM - Homebrew - 17/17.0.16+0
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Arch: aarch64
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Maximum heap size: 512 MiBytes
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JAVA_HOME: /opt/homebrew/opt/openjdk@17
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  No Hadoop Dependency available
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM Options:
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xmx536870902
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xms536870902
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxDirectMemorySize=268435458
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxMetaspaceSize=268435456
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:+IgnoreUnrecognizedVMOptions
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=java.base/sun.net.util=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.lang=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.net=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.io=ALL-UNNAMED
2025-11-02 12:43:18,159 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.nio=ALL-UNNAMED
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/sun.nio.ch=ALL-UNNAMED
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.text=ALL-UNNAMED
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.time=ALL-UNNAMED
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.util=ALL-UNNAMED
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.util.concurrent=ALL-UNNAMED
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog.file=/Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-taskexecutor-1-Ds-MacBook-Air.local.log
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configuration=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/log4j.properties
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configurationFile=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/log4j.properties
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlogback.configurationFile=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/logback.xml
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Program Arguments:
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --configDir
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     /Users/dev/Fraud_Detection/flink-1.20.2/conf
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.min=134217730b
2025-11-02 12:43:18,160 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.cpu.cores=4.0
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.off-heap.size=0b
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-metaspace.size=268435456b
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     external-resources=none
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.min=201326592b
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.off-heap.size=134217728b
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.max=134217730b
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.heap.size=134217728b
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.managed.size=536870920b
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.heap.size=402653174b
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.numberOfTaskSlots=4
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.max=201326592b
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Classpath: /Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-cep-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-connector-files-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-connector-kafka-3.4.0-1.20.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-csv-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-json-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-scala_2.12-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-api-java-uber-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-planner-loader-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-runtime-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/kafka-clients-3.6.0.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-1.2-api-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-api-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-core-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-slf4j-impl-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-dist-1.20.2.jar::::
2025-11-02 12:43:18,161 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-11-02 12:43:18,162 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2025-11-02 12:43:18,163 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Maximum number of open file descriptors is 1048576.
2025-11-02 12:43:18,166 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Using standard YAML parser to load flink configuration file from /Users/dev/Fraud_Detection/flink-1.20.2/conf/config.yaml.
2025-11-02 12:43:18,183 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1728m
2025-11-02 12:43:18,183 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.bind-host, localhost
2025-11-02 12:43:18,183 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2025-11-02 12:43:18,183 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2025-11-02 12:43:18,183 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1600m
2025-11-02 12:43:18,183 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2025-11-02 12:43:18,183 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-address, localhost
2025-11-02 12:43:18,183 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.bind-host, localhost
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.host, localhost
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 4
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.address, localhost
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: env.java.opts.all, --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.network.min, 134217730b
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.jvm-metaspace.size, 268435456b
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.task.off-heap.size, 0b
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.cpu.cores, 4.0
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: external-resources, none
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.jvm-overhead.min, 201326592b
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.framework.off-heap.size, 134217728b
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.network.max, 134217730b
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.framework.heap.size, 134217728b
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.managed.size, 536870920b
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.task.heap.size, 402653174b
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.numberOfTaskSlots, 4
2025-11-02 12:43:18,184 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.jvm-overhead.max, 201326592b
2025-11-02 12:43:18,197 INFO  org.apache.flink.core.fs.FileSystem                          [] - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2025-11-02 12:43:18,204 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-statsd
2025-11-02 12:43:18,205 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-prometheus
2025-11-02 12:43:18,205 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-graphite
2025-11-02 12:43:18,205 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: external-resource-gpu
2025-11-02 12:43:18,205 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-jmx
2025-11-02 12:43:18,205 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-influx
2025-11-02 12:43:18,205 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-slf4j
2025-11-02 12:43:18,206 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-datadog
2025-11-02 12:43:18,212 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - StateChangelogStorageLoader initialized with shortcut names {memory,filesystem}.
2025-11-02 12:43:18,212 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-11-02 12:43:18,212 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-11-02 12:43:18,212 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-11-02 12:43:18,212 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-11-02 12:43:18,212 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-11-02 12:43:18,212 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-11-02 12:43:18,212 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-11-02 12:43:18,213 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-11-02 12:43:18,213 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - StateChangelogStorageLoader initialized with shortcut names {memory,filesystem}.
2025-11-02 12:43:18,217 INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory [] - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.
2025-11-02 12:43:18,226 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/jaas-15836783201960068911.conf.
2025-11-02 12:43:18,228 INFO  org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory [] - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.
2025-11-02 12:43:18,356 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using configured hostname/address for TaskManager: localhost.
2025-11-02 12:43:18,371 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2025-11-02 12:43:18,601 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-11-02 12:43:18,612 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-11-02 12:43:18,613 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-11-02 12:43:18,722 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink@localhost:51798]
2025-11-02 12:43:18,758 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink@localhost:51798
2025-11-02 12:43:18,766 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using working directory: WorkingDirectory(/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/tm_localhost:51798-3c06be)
2025-11-02 12:43:18,770 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2025-11-02 12:43:18,770 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No trace reporter configured, no metrics will be exposed/reported.
2025-11-02 12:43:18,772 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2025-11-02 12:43:18,780 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-11-02 12:43:18,783 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-11-02 12:43:18,783 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-11-02 12:43:18,787 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink-metrics@localhost:51799]
2025-11-02 12:43:18,790 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink-metrics@localhost:51799
2025-11-02 12:43:18,797 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at pekko://flink-metrics/user/rpc/MetricQueryService_localhost:51798-3c06be .
2025-11-02 12:43:18,802 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/tm_localhost:51798-3c06be/blobStorage
2025-11-02 12:43:18,803 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/tm_localhost:51798-3c06be/blobStorage
2025-11-02 12:43:18,805 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2025-11-02 12:43:18,805 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2025-11-02 12:43:18,806 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2025-11-02 12:43:18,806 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2025-11-02 12:43:18,806 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-11-02 12:43:18,807 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-11-02 12:43:18,807 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-11-02 12:43:18,807 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-11-02 12:43:18,807 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-11-02 12:43:18,807 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-11-02 12:43:18,807 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-11-02 12:43:18,807 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-11-02 12:43:18,807 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2025-11-02 12:43:18,807 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: localhost:51798-3c06be
2025-11-02 12:43:18,844 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T': total 228 GB, usable 25 GB (10.96% usable)
2025-11-02 12:43:18,846 INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager         [] - Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:
	/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-io-626b58c3-b8e6-4be2-ab2a-3e9055884092
2025-11-02 12:43:18,850 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: localhost/127.0.0.1, server port range: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 4 (manual), number of client threads: 4 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2025-11-02 12:43:18,854 INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory [] - Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:
	/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-netty-shuffle-7039d7ba-3273-49da-95b1-22f06241818b
2025-11-02 12:43:18,880 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 128 MB for network buffer pool (number of memory segments: 4096, bytes per segment: 32768).
2025-11-02 12:43:18,886 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2025-11-02 12:43:18,892 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using NIO.
2025-11-02 12:43:18,892 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 6 ms).
2025-11-02 12:43:18,893 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using NIO.
2025-11-02 12:43:18,893 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 0 ms). Listening on SocketAddress /127.0.0.1:51800.
2025-11-02 12:43:18,893 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - TaskManager data connection initialized successfully; listening internally on port: 51800
2025-11-02 12:43:18,894 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2025-11-02 12:43:18,915 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at pekko://flink/user/rpc/taskmanager_0 .
2025-11-02 12:43:18,922 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2025-11-02 12:43:18,923 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-dist-cache-e6b001b0-31ef-4554-92dd-fdd8da7d4126
2025-11-02 12:43:18,923 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000).
2025-11-02 12:43:19,156 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2025-11-02 12:43:19,191 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_* under registration id 64b6099e851d175858a7a51a969eedfb.
2025-11-02 12:53:31,862 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 8f564bc07c4ff9820a291817dd4a22c6 for job 80f504723ff184ba0643ea886ce901d6 from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 12:53:31,869 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 8f564bc07c4ff9820a291817dd4a22c6 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 12:53:31,875 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 80f504723ff184ba0643ea886ce901d6 for job leader monitoring.
2025-11-02 12:53:31,876 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_35 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 12:53:31,889 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 12:53:31,902 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_35 for job 80f504723ff184ba0643ea886ce901d6.
2025-11-02 12:53:31,902 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 80f504723ff184ba0643ea886ce901d6.
2025-11-02 12:53:31,903 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 80f504723ff184ba0643ea886ce901d6.
2025-11-02 12:53:31,918 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 8f564bc07c4ff9820a291817dd4a22c6.
2025-11-02 12:53:31,929 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 8f564bc07c4ff9820a291817dd4a22c6.
2025-11-02 12:53:31,947 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 12:53:31,956 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 80f504723ff184ba0643ea886ce901d6
2025-11-02 12:53:31,963 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 8f564bc07c4ff9820a291817dd4a22c6.
2025-11-02 12:53:31,964 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 12:53:31,967 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 12:53:31,968 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 80f504723ff184ba0643ea886ce901d6/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-29f7c1694d93352393e44ef35aa94c31 from localhost/127.0.0.1:49383
2025-11-02 12:53:32,015 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6f696276
2025-11-02 12:53:32,015 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 12:53:32,016 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 12:53:32,023 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 12:53:32,303 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@545945d4
2025-11-02 12:53:32,328 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 12:53:32,332 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:52259
2025-11-02 12:53:32,334 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1c936231
2025-11-02 12:53:32,334 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@23934ea8
2025-11-02 12:53:32,339 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 12:53:32,341 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: 2512, StoppingOffset: -9223372036854775808]]
2025-11-02 12:53:32,356 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 12:53:32,397 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 12:53:32,399 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 12:53:32,399 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 12:53:32,399 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762068212397
2025-11-02 12:53:32,405 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 12:53:32,409 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-02 12:53:32,410 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 12:53:32,412 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = bf01d13f-c5d4-49d7-bb19-1363b5e7d999, offset = 0
2025-11-02 12:53:32,412 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to offset 2512 for partition bank_transactions-0
2025-11-02 12:53:32,534 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 12:53:42,099 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:53:42,100 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 12:53:42,100 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:53:42,107 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 12:53:42,107 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-02 12:53:42,109 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 12:53:42,110 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 12:53:42,351 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 12:53:42,352 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 12:53:42,352 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 12:53:42,356 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 12:53:42,357 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 12:53:42,363 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 12:53:42,363 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 (7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:53:42,364 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[1] -> Calc[2] -> Sink: Collect table sink (1/1)#0 7b25c827e676b51de3655bfc6f1064cf_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 12:53:42,387 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:4, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 8f564bc07c4ff9820a291817dd4a22c6, jobId: 80f504723ff184ba0643ea886ce901d6).
2025-11-02 12:53:42,387 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 80f504723ff184ba0643ea886ce901d6 from job leader monitoring.
2025-11-02 12:53:42,388 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 80f504723ff184ba0643ea886ce901d6.
2025-11-02 12:54:28,894 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 4d34c17f85d29d44d6864d55de689dc1 for job 2685b258c7515725c49793198333b210 from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 12:54:28,899 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 4d34c17f85d29d44d6864d55de689dc1 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 12:54:28,899 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 2685b258c7515725c49793198333b210 for job leader monitoring.
2025-11-02 12:54:28,899 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_36 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 12:54:28,903 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 12:54:28,906 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_36 for job 2685b258c7515725c49793198333b210.
2025-11-02 12:54:28,906 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 2685b258c7515725c49793198333b210.
2025-11-02 12:54:28,906 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 2685b258c7515725c49793198333b210.
2025-11-02 12:54:28,914 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4d34c17f85d29d44d6864d55de689dc1.
2025-11-02 12:54:28,922 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4d34c17f85d29d44d6864d55de689dc1.
2025-11-02 12:54:28,923 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 12:54:28,923 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 2685b258c7515725c49793198333b210
2025-11-02 12:54:28,923 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 4d34c17f85d29d44d6864d55de689dc1.
2025-11-02 12:54:28,924 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 12:54:28,926 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 12:54:28,927 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 2685b258c7515725c49793198333b210/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-100478d8d06b29ad52de812aef391e15 from localhost/127.0.0.1:49383
2025-11-02 12:54:28,939 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6306b1c5
2025-11-02 12:54:28,939 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 12:54:28,939 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 12:54:28,939 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 12:54:28,982 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@70bd2994
2025-11-02 12:54:28,983 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 12:54:28,983 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:54138
2025-11-02 12:54:28,983 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7ef081b9
2025-11-02 12:54:28,983 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2d9a4733
2025-11-02 12:54:28,984 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 12:54:28,997 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: 2512, StoppingOffset: -9223372036854775808]]
2025-11-02 12:54:28,998 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 12:54:29,002 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 12:54:29,002 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 12:54:29,002 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 12:54:29,002 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762068269002
2025-11-02 12:54:29,002 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 12:54:29,003 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 12:54:29,003 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to offset 2512 for partition bank_transactions-0
2025-11-02 12:54:29,009 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 12:54:29,084 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-02 12:54:29,085 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = 0befceb0-7ff6-4725-85bf-95d00ba6c54a, offset = 0
2025-11-02 12:54:33,508 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:54:33,508 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 12:54:33,509 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:54:33,510 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 12:54:33,510 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-02 12:54:33,510 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 12:54:33,510 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 12:54:33,929 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 12:54:33,930 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 12:54:33,930 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 12:54:33,932 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 12:54:33,933 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 12:54:33,933 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 12:54:33,934 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 (a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:54:33,934 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[4] -> Calc[5] -> Sink: Collect table sink (1/1)#0 a5d4f6bf2621cec298c41300648d1b6e_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 12:54:33,951 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:5, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 4d34c17f85d29d44d6864d55de689dc1, jobId: 2685b258c7515725c49793198333b210).
2025-11-02 12:54:33,952 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 2685b258c7515725c49793198333b210 from job leader monitoring.
2025-11-02 12:54:33,952 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 2685b258c7515725c49793198333b210.
2025-11-02 12:55:33,429 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 64887d28de6a381ea410a2accba83a4d for job 126e74c2134b9493921a8ae0844ed194 from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 12:55:33,431 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 64887d28de6a381ea410a2accba83a4d with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 12:55:33,431 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 126e74c2134b9493921a8ae0844ed194 for job leader monitoring.
2025-11-02 12:55:33,431 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_37 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 12:55:33,438 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 12:55:33,442 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_37 for job 126e74c2134b9493921a8ae0844ed194.
2025-11-02 12:55:33,442 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 126e74c2134b9493921a8ae0844ed194.
2025-11-02 12:55:33,442 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 126e74c2134b9493921a8ae0844ed194.
2025-11-02 12:55:33,453 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 64887d28de6a381ea410a2accba83a4d.
2025-11-02 12:55:33,460 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 64887d28de6a381ea410a2accba83a4d.
2025-11-02 12:55:33,462 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 12:55:33,462 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 126e74c2134b9493921a8ae0844ed194
2025-11-02 12:55:33,462 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 64887d28de6a381ea410a2accba83a4d.
2025-11-02 12:55:33,463 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 12:55:33,463 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 12:55:33,465 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 126e74c2134b9493921a8ae0844ed194/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-8625cb36ca70a4da9593ebb310d2694f from localhost/127.0.0.1:49383
2025-11-02 12:55:33,480 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@481d4690
2025-11-02 12:55:33,480 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 12:55:33,480 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 12:55:33,480 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 12:55:33,521 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@f009406
2025-11-02 12:55:33,521 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 12:55:33,522 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:50327
2025-11-02 12:55:33,522 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1789d6d3
2025-11-02 12:55:33,522 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5617ea4e
2025-11-02 12:55:33,523 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 12:55:33,531 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: 2512, StoppingOffset: -9223372036854775808]]
2025-11-02 12:55:33,532 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 12:55:33,537 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 12:55:33,537 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 12:55:33,537 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 12:55:33,537 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762068333537
2025-11-02 12:55:33,538 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 12:55:33,539 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 12:55:33,539 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to offset 2512 for partition bank_transactions-0
2025-11-02 12:55:33,542 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 12:55:33,616 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-02 12:55:33,617 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = e95300ef-59dc-47bb-8a40-58562b712d2d, offset = 0
2025-11-02 12:55:52,205 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:55:52,205 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 12:55:52,205 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:55:52,207 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 12:55:52,207 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-02 12:55:52,207 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 12:55:52,207 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 12:55:52,677 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 12:55:52,678 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 12:55:52,678 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 12:55:52,681 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 12:55:52,682 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 12:55:52,683 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 12:55:52,683 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 (385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:55:52,684 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[7] -> Calc[8] -> Sink: Collect table sink (1/1)#0 385d6f9509c57754c94f15d7c9289c3f_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 12:55:52,720 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:6, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 64887d28de6a381ea410a2accba83a4d, jobId: 126e74c2134b9493921a8ae0844ed194).
2025-11-02 12:55:52,721 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 126e74c2134b9493921a8ae0844ed194 from job leader monitoring.
2025-11-02 12:55:52,721 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 126e74c2134b9493921a8ae0844ed194.
2025-11-02 12:59:42,376 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 7f407ce7244a47a1b4401e7b33432bfd for job 09809b3b03a1a6ed281e1006fdddd76c from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 12:59:42,379 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 7f407ce7244a47a1b4401e7b33432bfd with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 12:59:42,380 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 09809b3b03a1a6ed281e1006fdddd76c for job leader monitoring.
2025-11-02 12:59:42,380 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_38 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 12:59:42,387 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 12:59:42,393 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_38 for job 09809b3b03a1a6ed281e1006fdddd76c.
2025-11-02 12:59:42,394 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 09809b3b03a1a6ed281e1006fdddd76c.
2025-11-02 12:59:42,394 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 09809b3b03a1a6ed281e1006fdddd76c.
2025-11-02 12:59:42,408 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7f407ce7244a47a1b4401e7b33432bfd.
2025-11-02 12:59:42,419 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7f407ce7244a47a1b4401e7b33432bfd.
2025-11-02 12:59:42,421 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 12:59:42,421 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 09809b3b03a1a6ed281e1006fdddd76c
2025-11-02 12:59:42,421 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1)#0 (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 7f407ce7244a47a1b4401e7b33432bfd.
2025-11-02 12:59:42,422 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1)#0 (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 12:59:42,422 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1)#0 (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 12:59:42,423 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 09809b3b03a1a6ed281e1006fdddd76c/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-8609aa01c8586a26af0f9587ed30326d from localhost/127.0.0.1:49383
2025-11-02 12:59:42,438 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@aa6a6b0
2025-11-02 12:59:42,438 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 12:59:42,438 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 12:59:42,439 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1)#0 (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 12:59:42,488 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7c111b7e
2025-11-02 12:59:42,489 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 12:59:42,489 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:56435
2025-11-02 12:59:42,491 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@aaefc0a
2025-11-02 12:59:42,492 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@78a09fb0
2025-11-02 12:59:42,495 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1)#0 (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 12:59:42,503 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]
2025-11-02 12:59:42,508 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 12:59:42,512 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 12:59:42,513 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 12:59:42,513 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 12:59:42,513 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762068582513
2025-11-02 12:59:42,513 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 12:59:42,515 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 12:59:42,522 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 12:59:42,525 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null)
2025-11-02 12:59:42,545 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Found no committed offset for partition bank_transactions-0
2025-11-02 12:59:42,545 ERROR org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Received uncaught exception.
java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) [flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	... 6 more
2025-11-02 12:59:42,551 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 12:59:42,551 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 12:59:42,551 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 12:59:42,551 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 12:59:42,551 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 12:59:42,551 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 12:59:42,552 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 12:59:42,552 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 12:59:42,552 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1)#0 (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) [flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) [flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) [flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-02 12:59:42,553 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1)#0 (6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 12:59:42,558 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FAILED to JobManager for task Source: bank_transactions[10] -> Calc[11] -> Sink: Collect table sink (1/1)#0 6f3250b52b2031ec032e28f00f999acc_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 12:59:42,604 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:7, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 7f407ce7244a47a1b4401e7b33432bfd, jobId: 09809b3b03a1a6ed281e1006fdddd76c).
2025-11-02 12:59:42,607 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 09809b3b03a1a6ed281e1006fdddd76c from job leader monitoring.
2025-11-02 12:59:42,607 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 09809b3b03a1a6ed281e1006fdddd76c.
2025-11-02 13:13:40,115 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request f1d1a44c0cf0ccf4c9edc51f81a7661d for job 1f43bba76c5061de16f5812875844409 from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 13:13:40,123 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for f1d1a44c0cf0ccf4c9edc51f81a7661d with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 13:13:40,124 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 1f43bba76c5061de16f5812875844409 for job leader monitoring.
2025-11-02 13:13:40,124 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_39 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 13:13:40,139 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 13:13:40,146 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_39 for job 1f43bba76c5061de16f5812875844409.
2025-11-02 13:13:40,146 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 1f43bba76c5061de16f5812875844409.
2025-11-02 13:13:40,146 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 1f43bba76c5061de16f5812875844409.
2025-11-02 13:13:40,168 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f1d1a44c0cf0ccf4c9edc51f81a7661d.
2025-11-02 13:13:40,174 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 13:13:40,175 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 1f43bba76c5061de16f5812875844409
2025-11-02 13:13:40,175 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id f1d1a44c0cf0ccf4c9edc51f81a7661d.
2025-11-02 13:13:40,176 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f1d1a44c0cf0ccf4c9edc51f81a7661d.
2025-11-02 13:13:40,176 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 13:13:40,177 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 13:13:40,180 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 1f43bba76c5061de16f5812875844409/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-f04e4cde6b597261ab26b26c410aa574 from localhost/127.0.0.1:49383
2025-11-02 13:13:40,198 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@748f13af
2025-11-02 13:13:40,198 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 13:13:40,198 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 13:13:40,199 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 13:13:40,272 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@51a30d11
2025-11-02 13:13:40,274 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 13:13:40,275 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:57610
2025-11-02 13:13:40,275 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@977e32b
2025-11-02 13:13:40,275 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2cb56004
2025-11-02 13:13:40,276 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 13:13:40,286 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-02 13:13:40,289 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 13:13:40,301 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 13:13:40,301 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 13:13:40,301 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 13:13:40,301 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762069420301
2025-11-02 13:13:40,302 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 13:13:40,303 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 13:13:40,307 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-02 13:13:40,307 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition bank_transactions-0
2025-11-02 13:13:40,307 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = 769f4759-8b6c-44c0-ab16-cde61a822fa3, offset = 0
2025-11-02 13:13:40,316 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 13:13:40,348 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition bank_transactions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
2025-11-02 13:14:36,619 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:14:36,620 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 13:14:36,621 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:14:36,623 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 13:14:36,624 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-02 13:14:36,624 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 13:14:36,624 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 13:14:37,055 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 13:14:37,055 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 13:14:37,055 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 13:14:37,057 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 13:14:37,057 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 13:14:37,058 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 13:14:37,058 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 (06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:14:37,059 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[13] -> Calc[14] -> Sink: Collect table sink (1/1)#0 06841ece88fc8d766cba91f6147dec95_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 13:14:37,099 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:8, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: f1d1a44c0cf0ccf4c9edc51f81a7661d, jobId: 1f43bba76c5061de16f5812875844409).
2025-11-02 13:14:37,099 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 1f43bba76c5061de16f5812875844409 from job leader monitoring.
2025-11-02 13:14:37,100 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 1f43bba76c5061de16f5812875844409.
2025-11-02 13:22:04,462 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 2f77c5ce1560584ff25f7e7eddb85327 for job 1890a8be8901f754b52677d4e62fe9bf from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 13:22:04,471 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 2f77c5ce1560584ff25f7e7eddb85327 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 13:22:04,474 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 1890a8be8901f754b52677d4e62fe9bf for job leader monitoring.
2025-11-02 13:22:04,474 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_40 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 13:22:04,483 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 13:22:04,491 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_40 for job 1890a8be8901f754b52677d4e62fe9bf.
2025-11-02 13:22:04,491 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 1890a8be8901f754b52677d4e62fe9bf.
2025-11-02 13:22:04,491 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 1890a8be8901f754b52677d4e62fe9bf.
2025-11-02 13:22:04,505 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 2f77c5ce1560584ff25f7e7eddb85327.
2025-11-02 13:22:04,524 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 2f77c5ce1560584ff25f7e7eddb85327.
2025-11-02 13:22:04,532 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 13:22:04,533 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 1890a8be8901f754b52677d4e62fe9bf
2025-11-02 13:22:04,533 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 2f77c5ce1560584ff25f7e7eddb85327.
2025-11-02 13:22:04,534 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 13:22:04,534 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 13:22:04,536 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 1890a8be8901f754b52677d4e62fe9bf/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-91c64311f0e15f2fb012d0675d9d7559 from localhost/127.0.0.1:49383
2025-11-02 13:22:04,549 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6426661d
2025-11-02 13:22:04,549 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 13:22:04,549 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 13:22:04,550 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 13:22:04,606 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@33aa7dd3
2025-11-02 13:22:04,608 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 13:22:04,608 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:54917
2025-11-02 13:22:04,608 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7b690f96
2025-11-02 13:22:04,608 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@10a66ad2
2025-11-02 13:22:04,610 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 13:22:04,621 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-02 13:22:04,624 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-02 13:22:04,624 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = ce064e09-8439-4a38-8556-0ddeab0874cd, offset = 0
2025-11-02 13:22:04,628 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 13:22:04,634 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 13:22:04,634 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 13:22:04,634 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 13:22:04,634 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762069924634
2025-11-02 13:22:04,634 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 13:22:04,635 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 13:22:04,635 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition bank_transactions-0
2025-11-02 13:22:04,642 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 13:22:04,658 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition bank_transactions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
2025-11-02 13:25:14,858 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:25:14,859 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 13:25:14,859 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:25:14,863 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 13:25:14,863 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-02 13:25:14,863 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 13:25:14,863 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 13:25:14,892 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 13:25:14,892 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 13:25:14,892 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 13:25:14,894 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 13:25:14,894 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 13:25:14,895 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 13:25:14,895 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 (366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:25:14,895 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[16] -> Calc[17] -> Sink: Collect table sink (1/1)#0 366586b74ab088312f21755b977d588c_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 13:25:14,930 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:9, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 2f77c5ce1560584ff25f7e7eddb85327, jobId: 1890a8be8901f754b52677d4e62fe9bf).
2025-11-02 13:25:14,931 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 1890a8be8901f754b52677d4e62fe9bf from job leader monitoring.
2025-11-02 13:25:14,931 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 1890a8be8901f754b52677d4e62fe9bf.
2025-11-02 13:25:33,868 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request dc9fbc462e35e481c7cb8b80e858dc4e for job 8124b88e7c19fc032991b3110433c546 from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 13:25:33,870 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for dc9fbc462e35e481c7cb8b80e858dc4e with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 13:25:33,871 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 8124b88e7c19fc032991b3110433c546 for job leader monitoring.
2025-11-02 13:25:33,872 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_41 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 13:25:33,881 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 13:25:33,888 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_41 for job 8124b88e7c19fc032991b3110433c546.
2025-11-02 13:25:33,888 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 8124b88e7c19fc032991b3110433c546.
2025-11-02 13:25:33,889 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 8124b88e7c19fc032991b3110433c546.
2025-11-02 13:25:33,897 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot dc9fbc462e35e481c7cb8b80e858dc4e.
2025-11-02 13:25:33,908 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot dc9fbc462e35e481c7cb8b80e858dc4e.
2025-11-02 13:25:33,912 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 13:25:33,912 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 8124b88e7c19fc032991b3110433c546
2025-11-02 13:25:33,912 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id dc9fbc462e35e481c7cb8b80e858dc4e.
2025-11-02 13:25:33,912 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 13:25:33,913 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 13:25:33,913 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 8124b88e7c19fc032991b3110433c546/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-20509509eab3be87b4669542361d8b87 from localhost/127.0.0.1:49383
2025-11-02 13:25:33,921 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@30b68a07
2025-11-02 13:25:33,921 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 13:25:33,921 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 13:25:33,921 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 13:25:33,952 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2b64ee2e
2025-11-02 13:25:33,953 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 13:25:33,955 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:59748
2025-11-02 13:25:33,955 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@525509e0
2025-11-02 13:25:33,955 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@70c42c41
2025-11-02 13:25:33,956 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 13:25:33,962 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-02 13:25:33,965 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 13:25:33,968 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 13:25:33,968 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 13:25:33,968 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 13:25:33,968 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762070133968
2025-11-02 13:25:33,969 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 13:25:33,969 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 13:25:33,969 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition bank_transactions-0
2025-11-02 13:25:33,972 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 13:25:33,983 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition bank_transactions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
2025-11-02 13:25:34,029 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-02 13:25:34,029 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = 84ae85ac-28d8-4791-b4a4-a339d658fab6, offset = 0
2025-11-02 13:27:09,380 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:27:09,380 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 13:27:09,380 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:27:09,382 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 13:27:09,382 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-02 13:27:09,383 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 13:27:09,383 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 13:27:09,402 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 13:27:09,402 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 13:27:09,402 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 13:27:09,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 13:27:09,403 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 13:27:09,404 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 13:27:09,404 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 (def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:27:09,404 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[19] -> Calc[20] -> Sink: Collect table sink (1/1)#0 def62ee32891c332d022c3d8ecf5b698_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 13:27:09,420 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:10, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: dc9fbc462e35e481c7cb8b80e858dc4e, jobId: 8124b88e7c19fc032991b3110433c546).
2025-11-02 13:27:09,420 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 8124b88e7c19fc032991b3110433c546 from job leader monitoring.
2025-11-02 13:27:09,420 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 8124b88e7c19fc032991b3110433c546.
2025-11-02 13:28:46,591 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request da7094712258826c18398b94072bc0f5 for job 9ce75af44c8d7be188ded1d77bb5663a from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 13:28:46,593 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for da7094712258826c18398b94072bc0f5 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 13:28:46,593 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 9ce75af44c8d7be188ded1d77bb5663a for job leader monitoring.
2025-11-02 13:28:46,593 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_42 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 13:28:46,596 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 13:28:46,598 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_42 for job 9ce75af44c8d7be188ded1d77bb5663a.
2025-11-02 13:28:46,599 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 9ce75af44c8d7be188ded1d77bb5663a.
2025-11-02 13:28:46,599 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 9ce75af44c8d7be188ded1d77bb5663a.
2025-11-02 13:28:46,605 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot da7094712258826c18398b94072bc0f5.
2025-11-02 13:28:46,611 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot da7094712258826c18398b94072bc0f5.
2025-11-02 13:28:46,612 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 13:28:46,612 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 9ce75af44c8d7be188ded1d77bb5663a
2025-11-02 13:28:46,613 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id da7094712258826c18398b94072bc0f5.
2025-11-02 13:28:46,613 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 13:28:46,613 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 13:28:46,614 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 9ce75af44c8d7be188ded1d77bb5663a/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-b55af5d402d21e3664630c0c1aac075e from localhost/127.0.0.1:49383
2025-11-02 13:28:46,620 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@180c04f2
2025-11-02 13:28:46,620 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 13:28:46,620 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 13:28:46,620 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 13:28:46,643 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6be30e02
2025-11-02 13:28:46,643 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 13:28:46,643 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:57188
2025-11-02 13:28:46,644 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@36365622
2025-11-02 13:28:46,644 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@12092df3
2025-11-02 13:28:46,644 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 13:28:46,649 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-02 13:28:46,649 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 13:28:46,653 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 13:28:46,653 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 13:28:46,653 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 13:28:46,653 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762070326653
2025-11-02 13:28:46,654 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 13:28:46,655 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 13:28:46,655 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition bank_transactions-0
2025-11-02 13:28:46,657 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 13:28:46,670 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition bank_transactions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
2025-11-02 13:28:46,756 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-02 13:28:46,756 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = cdc177cf-2279-4702-962f-8e7bcbffebad, offset = 0
2025-11-02 13:30:13,637 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:30:13,638 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 13:30:13,638 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:30:13,642 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 13:30:13,642 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-02 13:30:13,643 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 13:30:13,643 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 13:30:13,857 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 13:30:13,857 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 13:30:13,857 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 13:30:13,862 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 13:30:13,862 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 13:30:13,862 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 13:30:13,862 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 (d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 13:30:13,863 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[22] -> Calc[23] -> Sink: Collect table sink (1/1)#0 d76998f0227c85e070b2b7e6717e5f15_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 13:30:13,885 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:11, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: da7094712258826c18398b94072bc0f5, jobId: 9ce75af44c8d7be188ded1d77bb5663a).
2025-11-02 13:30:13,886 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 9ce75af44c8d7be188ded1d77bb5663a from job leader monitoring.
2025-11-02 13:30:13,886 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 9ce75af44c8d7be188ded1d77bb5663a.
2025-11-02 14:47:44,844 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 28a9c6706c40d485c7e71225f9b83e37 for job fadc002549f91eabfdb4dd918b2ee79c from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 14:47:44,853 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 28a9c6706c40d485c7e71225f9b83e37 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 14:47:44,856 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job fadc002549f91eabfdb4dd918b2ee79c for job leader monitoring.
2025-11-02 14:47:44,856 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_43 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 14:47:44,868 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 14:47:44,875 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_43 for job fadc002549f91eabfdb4dd918b2ee79c.
2025-11-02 14:47:44,875 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job fadc002549f91eabfdb4dd918b2ee79c.
2025-11-02 14:47:44,875 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job fadc002549f91eabfdb4dd918b2ee79c.
2025-11-02 14:47:44,912 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 28a9c6706c40d485c7e71225f9b83e37.
2025-11-02 14:47:44,918 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 14:47:44,918 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id fadc002549f91eabfdb4dd918b2ee79c
2025-11-02 14:47:44,919 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 28a9c6706c40d485c7e71225f9b83e37.
2025-11-02 14:47:44,921 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 28a9c6706c40d485c7e71225f9b83e37.
2025-11-02 14:47:44,920 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 14:47:44,923 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 14:47:44,928 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading fadc002549f91eabfdb4dd918b2ee79c/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-1a6404a4f7caef5c29f3829699948db1 from localhost/127.0.0.1:49383
2025-11-02 14:47:44,952 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@b945688
2025-11-02 14:47:44,953 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 14:47:44,953 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 14:47:44,954 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 14:47:45,020 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1bd6100a
2025-11-02 14:47:45,025 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 14:47:45,028 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:63089
2025-11-02 14:47:45,029 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6f1666e6
2025-11-02 14:47:45,032 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 14:47:45,093 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-02 14:47:45,096 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 14:47:45,108 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 14:47:45,108 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 14:47:45,108 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 14:47:45,108 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762075065108
2025-11-02 14:47:45,110 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 14:47:45,110 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 14:47:45,111 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition bank_transactions-0
2025-11-02 14:47:45,117 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 14:47:45,132 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-02 14:47:45,132 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = e1fafc6c-8e1a-4a10-8846-9a3407e1200d, offset = 0
2025-11-02 14:47:45,153 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition bank_transactions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
2025-11-02 14:48:04,637 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 14:48:04,637 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 14:48:04,637 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 14:48:04,639 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 14:48:04,639 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-02 14:48:04,639 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 14:48:04,639 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 14:48:04,888 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 14:48:04,888 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 14:48:04,889 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 14:48:04,892 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 14:48:04,893 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 14:48:04,893 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 14:48:04,893 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 (a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 14:48:04,893 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[25] -> Sink: Collect table sink (1/1)#0 a900131c66cb9177c683e34343d0ea50_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 14:48:04,921 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:12, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 28a9c6706c40d485c7e71225f9b83e37, jobId: fadc002549f91eabfdb4dd918b2ee79c).
2025-11-02 14:48:04,924 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job fadc002549f91eabfdb4dd918b2ee79c from job leader monitoring.
2025-11-02 14:48:04,924 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job fadc002549f91eabfdb4dd918b2ee79c.
2025-11-02 15:51:43,222 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 154c7f4a5b165a568a95cc2c8761065f for job 74fa4f277aa75c5f9a89a4a212077850 from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 15:51:43,241 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 154c7f4a5b165a568a95cc2c8761065f with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 15:51:43,246 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 74fa4f277aa75c5f9a89a4a212077850 for job leader monitoring.
2025-11-02 15:51:43,247 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_44 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 15:51:43,280 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 15:51:43,288 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_44 for job 74fa4f277aa75c5f9a89a4a212077850.
2025-11-02 15:51:43,289 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 74fa4f277aa75c5f9a89a4a212077850.
2025-11-02 15:51:43,289 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 74fa4f277aa75c5f9a89a4a212077850.
2025-11-02 15:51:43,300 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 154c7f4a5b165a568a95cc2c8761065f.
2025-11-02 15:51:43,313 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 154c7f4a5b165a568a95cc2c8761065f.
2025-11-02 15:51:43,324 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 15:51:43,325 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 74fa4f277aa75c5f9a89a4a212077850
2025-11-02 15:51:43,326 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 154c7f4a5b165a568a95cc2c8761065f.
2025-11-02 15:51:43,327 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-02 15:51:43,331 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-02 15:51:43,336 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 74fa4f277aa75c5f9a89a4a212077850/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-a2139e54074d39ecbad5f6fa4ae4e845 from localhost/127.0.0.1:49383
2025-11-02 15:51:43,354 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@72d3073f
2025-11-02 15:51:43,354 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 15:51:43,354 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 15:51:43,355 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:51:43,424 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@60d1e33b
2025-11-02 15:51:43,426 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-02 15:51:43,427 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:63244
2025-11-02 15:51:43,427 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7234d625
2025-11-02 15:51:43,428 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6e878aa1
2025-11-02 15:51:43,429 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:51:43,436 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-02 15:51:43,441 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 15:51:43,449 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-02 15:51:43,450 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = 444a955b-6547-46e9-8948-4808c62e04e7, offset = 0
2025-11-02 15:51:43,450 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 15:51:43,450 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 15:51:43,450 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 15:51:43,450 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762078903450
2025-11-02 15:51:43,451 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 15:51:43,452 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 15:51:43,452 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition bank_transactions-0
2025-11-02 15:51:43,461 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 15:51:43,903 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition bank_transactions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
2025-11-02 15:51:49,208 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 15:51:49,208 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-02 15:51:49,208 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 15:51:49,210 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-02 15:51:49,210 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-02 15:51:49,210 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-02 15:51:49,210 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-02 15:51:49,500 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 15:51:49,500 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 15:51:49,501 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 15:51:49,505 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-02 15:51:49,505 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-02 15:51:49,506 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-02 15:51:49,506 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 (ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-02 15:51:49,506 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[27] -> Calc[28] -> Sink: Collect table sink (1/1)#0 ed47b9ca3d5ec487debfcc723ce5400d_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-02 15:51:49,532 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:13, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 154c7f4a5b165a568a95cc2c8761065f, jobId: 74fa4f277aa75c5f9a89a4a212077850).
2025-11-02 15:51:49,534 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 74fa4f277aa75c5f9a89a4a212077850 from job leader monitoring.
2025-11-02 15:51:49,534 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 74fa4f277aa75c5f9a89a4a212077850.
2025-11-02 15:56:32,618 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 48d622f1fd40077ef7a2adb02cae9703 for job d566ac56bb78c1c0c311e4de6984739d from resource manager with leader id 00000000000000000000000000000000.
2025-11-02 15:56:32,622 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 48d622f1fd40077ef7a2adb02cae9703 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-02 15:56:32,622 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job d566ac56bb78c1c0c311e4de6984739d for job leader monitoring.
2025-11-02 15:56:32,623 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_45 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-02 15:56:32,629 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-02 15:56:32,633 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_45 for job d566ac56bb78c1c0c311e4de6984739d.
2025-11-02 15:56:32,633 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job d566ac56bb78c1c0c311e4de6984739d.
2025-11-02 15:56:32,633 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job d566ac56bb78c1c0c311e4de6984739d.
2025-11-02 15:56:32,700 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,704 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-02 15:56:32,704 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id d566ac56bb78c1c0c311e4de6984739d
2025-11-02 15:56:32,720 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0), deploy into slot with allocation id 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,721 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,721 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0) switched from CREATED to DEPLOYING.
2025-11-02 15:56:32,721 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0) [DEPLOYING].
2025-11-02 15:56:32,721 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading d566ac56bb78c1c0c311e4de6984739d/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-46bf3edbbe1f202f58b6150e0dabf557 from localhost/127.0.0.1:49383
2025-11-02 15:56:32,745 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Join[43] -> Calc[44] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0), deploy into slot with allocation id 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,745 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,745 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[43] -> Calc[44] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0) switched from CREATED to DEPLOYING.
2025-11-02 15:56:32,745 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Join[43] -> Calc[44] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0) [DEPLOYING].
2025-11-02 15:56:32,748 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task GlobalWindowAggregate[36] -> Calc[37] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0), deploy into slot with allocation id 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,748 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,748 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - GlobalWindowAggregate[36] -> Calc[37] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0) switched from CREATED to DEPLOYING.
2025-11-02 15:56:32,755 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task GlobalWindowAggregate[36] -> Calc[37] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0) [DEPLOYING].
2025-11-02 15:56:32,760 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Join[39] -> Calc[40] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0), deploy into slot with allocation id 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,760 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3ca3563f
2025-11-02 15:56:32,760 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 15:56:32,760 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6618096d
2025-11-02 15:56:32,760 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 15:56:32,760 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 15:56:32,760 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 15:56:32,760 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,761 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - GlobalWindowAggregate[36] -> Calc[37] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,761 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[39] -> Calc[40] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0) switched from CREATED to DEPLOYING.
2025-11-02 15:56:32,761 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Join[39] -> Calc[40] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0) [DEPLOYING].
2025-11-02 15:56:32,762 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[43] -> Calc[44] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,763 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@662bff69
2025-11-02 15:56:32,763 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 15:56:32,763 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 15:56:32,763 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[39] -> Calc[40] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,765 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@84a5ad9
2025-11-02 15:56:32,765 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 15:56:32,765 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 15:56:32,765 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,768 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1)#0 (0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0), deploy into slot with allocation id 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,768 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1)#0 (0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from CREATED to DEPLOYING.
2025-11-02 15:56:32,768 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1)#0 (0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0) [DEPLOYING].
2025-11-02 15:56:32,769 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 48d622f1fd40077ef7a2adb02cae9703.
2025-11-02 15:56:32,770 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@417c3b04
2025-11-02 15:56:32,770 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-02 15:56:32,770 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-02 15:56:32,770 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1)#0 (0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-02 15:56:32,915 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6b8b3947
2025-11-02 15:56:32,915 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6a4666b9
2025-11-02 15:56:32,917 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@66017e86
2025-11-02 15:56:32,917 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@21f7090f
2025-11-02 15:56:32,917 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@16ceb652
2025-11-02 15:56:32,918 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@14b7a1ce
2025-11-02 15:56:32,918 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@38ab1fc7
2025-11-02 15:56:32,918 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3712e916
2025-11-02 15:56:32,925 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2025-11-02 15:56:32,927 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder [] - Finished to build heap keyed state-backend.
2025-11-02 15:56:32,927 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder [] - Finished to build heap keyed state-backend.
2025-11-02 15:56:32,927 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder [] - Finished to build heap keyed state-backend.
2025-11-02 15:56:32,932 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-11-02 15:56:32,935 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend    [] - Initializing heap keyed state backend with stream factory.
2025-11-02 15:56:32,935 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend    [] - Initializing heap keyed state backend with stream factory.
2025-11-02 15:56:32,935 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend    [] - Initializing heap keyed state backend with stream factory.
2025-11-02 15:56:32,946 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@667ac131
2025-11-02 15:56:32,949 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 15:56:32,949 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 15:56:32,949 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762079192949
2025-11-02 15:56:32,962 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[39] -> Calc[40] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_4fda3f41f10225fc13b7996a1749e065_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:56:32,968 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - fraud_alerts[48]: Writer -> fraud_alerts[48]: Committer (1/1)#0 (0d3b8903738e8e7348741c39094ef702_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:56:32,971 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[43] -> Calc[44] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_f903181e99c89a09cba2df29130e7591_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:56:32,977 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@35f70290
2025-11-02 15:56:32,977 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5a77072f
2025-11-02 15:56:32,977 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@e94ebcb
2025-11-02 15:56:33,001 INFO  org.apache.flink.table.runtime.util.collections.binary.AbstractBytesMultiMap [] - BytesMultiMap with initial memory segments 2048, 67108864 in bytes, init allocating 32 for bucket area.
2025-11-02 15:56:33,001 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7422d272
2025-11-02 15:56:33,002 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@74f3f75e
2025-11-02 15:56:33,002 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5582530c
2025-11-02 15:56:33,002 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3fbb490c
2025-11-02 15:56:33,003 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[30] -> (Calc[31], Calc[33] -> LocalWindowAggregate[34], Calc[41], Calc[46]) (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5da08a4269629ebce1b7dfad7a855276_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:56:33,004 INFO  org.apache.flink.table.runtime.util.collections.binary.AbstractBytesMultiMap [] - BytesMultiMap with initial memory segments 2048, 67108864 in bytes, init allocating 32 for bucket area.
2025-11-02 15:56:33,005 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - GlobalWindowAggregate[36] -> Calc[37] (1/1)#0 (0d3b8903738e8e7348741c39094ef702_5e000441d5075bb085278cafa0ec71ad_0_0) switched from INITIALIZING to RUNNING.
2025-11-02 15:56:33,009 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-02 15:56:33,010 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-02 15:56:33,023 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-02 15:56:33,023 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 15:56:33,023 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 15:56:33,023 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762079193023
2025-11-02 15:56:33,025 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-02 15:56:33,025 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-02 15:56:33,025 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition bank_transactions-0
2025-11-02 15:56:33,034 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 15:56:33,034 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-1] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 15:56:33,044 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition bank_transactions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
2025-11-02 15:56:33,046 INFO  org.apache.kafka.clients.producer.internals.TransactionManager [] - [Producer clientId=producer-1] ProducerId set to 7006 with epoch 0
2025-11-02 15:56:33,204 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2025-11-02 15:56:33,204 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-2] Instantiated an idempotent producer.
2025-11-02 15:56:33,208 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-02 15:56:33,208 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-02 15:56:33,208 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762079193208
2025-11-02 15:56:33,209 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-2] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-02 15:56:33,210 INFO  org.apache.kafka.clients.producer.internals.TransactionManager [] - [Producer clientId=producer-2] ProducerId set to 7007 with epoch 0
2025-11-02 15:56:33,210 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2025-11-02 15:56:33,212 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-02 15:56:33,212 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-02 15:56:33,212 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-02 15:56:33,212 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-2 unregistered
2025-11-02 16:05:33,089 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node -1 disconnected.
2025-11-02 16:05:33,215 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node -1 disconnected.
2025-11-03 15:23:28,139 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-03 15:23:28,213 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 39816 due to node 1 being disconnected (elapsed time since creation: 986022ms, elapsed time since send: 986022ms, request timeout: 30000ms)
2025-11-03 15:23:28,357 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=202390049, epoch=39674) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-04 16:08:59,025 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-04 16:08:59,326 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 47716 due to node 1 being disconnected (elapsed time since creation: 50652968ms, elapsed time since send: 50652968ms, request timeout: 30000ms)
2025-11-04 16:08:59,434 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=1321691065, epoch=7845) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-04 17:13:20,033 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:20,033 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:20,048 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 56010 due to node 1 being disconnected (elapsed time since creation: 51ms, elapsed time since send: 51ms, request timeout: 30000ms)
2025-11-04 17:13:20,049 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=802123910, epoch=8242) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-04 17:13:20,132 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:20,132 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:20,133 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,133 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,234 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:20,235 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,286 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:20,289 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,488 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:20,488 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,532 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:20,533 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,940 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:20,940 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:20,998 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:20,998 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,705 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:21,705 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:21,712 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:21,712 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:22,621 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:22,621 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:22,883 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:22,883 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:23,744 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:23,744 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:24,105 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:24,105 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:24,659 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:24,660 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:26,083 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:26,083 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:26,083 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:26,084 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:27,000 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node 1 disconnected.
2025-11-04 17:13:27,000 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:27,104 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node 1 disconnected.
2025-11-04 17:13:27,104 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2025-11-04 17:13:27,721 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - RECEIVED SIGNAL 15: SIGTERM. Shutting down as requested.
2025-11-04 17:13:27,734 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Shutting down BLOB cache
2025-11-04 17:13:27,737 INFO  org.apache.flink.runtime.state.TaskExecutorFileMergingManager [] - Shutting down TaskExecutorFileMergingManager.
2025-11-04 17:13:27,781 INFO  org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager [] - Shutting down TaskExecutorStateChangelogStoragesManager.
2025-11-04 17:13:27,797 INFO  org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager [] - Shutting down TaskExecutorLocalStateStoresManager.
2025-11-04 17:13:27,802 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Shutting down BLOB cache
2025-11-04 17:13:27,803 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-dist-cache-e6b001b0-31ef-4554-92dd-fdd8da7d4126
2025-11-04 17:13:27,805 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-io-626b58c3-b8e6-4be2-ab2a-3e9055884092
2025-11-04 17:13:27,808 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-netty-shuffle-7039d7ba-3273-49da-95b1-22f06241818b
2025-11-04 17:13:27,815 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Stopping TaskExecutor pekko.tcp://flink@localhost:51798/user/rpc/taskmanager_0.
2025-11-04 17:13:27,817 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close ResourceManager connection 467535e488a77a2152a8d85ef53ec3b0.
2025-11-04 17:13:29,008 INFO  org.apache.pekko.actor.CoordinatedShutdown                   [] - Running CoordinatedShutdown with reason [ActorSystemTerminateReason]
2025-11-04 17:13:29,179 INFO  org.apache.pekko.remote.RemoteActorRefProvider$RemotingTerminator [] - Shutting down remote daemon.
2025-11-04 17:13:29,184 INFO  org.apache.pekko.remote.RemoteActorRefProvider$RemotingTerminator [] - Shutting down remote daemon.
2025-11-04 17:13:29,185 INFO  org.apache.pekko.remote.RemoteActorRefProvider$RemotingTerminator [] - Remote daemon shut down; proceeding with flushing remote transports.
2025-11-04 17:13:29,186 INFO  org.apache.pekko.remote.RemoteActorRefProvider$RemotingTerminator [] - Remote daemon shut down; proceeding with flushing remote transports.
2025-11-04 17:13:29,272 INFO  org.apache.pekko.remote.RemoteActorRefProvider$RemotingTerminator [] - Remoting shut down.
2025-11-04 17:13:29,425 INFO  org.apache.pekko.remote.RemoteActorRefProvider$RemotingTerminator [] - Remoting shut down.
