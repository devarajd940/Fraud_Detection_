2025-11-06 00:18:24,325 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-11-06 00:18:24,326 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Preconfiguration: 
2025-11-06 00:18:24,326 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - 


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx536870902 -Xms536870902 -XX:MaxDirectMemorySize=268435458 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D taskmanager.memory.network.min=134217730b -D taskmanager.cpu.cores=4.0 -D taskmanager.memory.task.off-heap.size=0b -D taskmanager.memory.jvm-metaspace.size=268435456b -D external-resources=none -D taskmanager.memory.jvm-overhead.min=201326592b -D taskmanager.memory.framework.off-heap.size=134217728b -D taskmanager.memory.network.max=134217730b -D taskmanager.memory.framework.heap.size=134217728b -D taskmanager.memory.managed.size=536870920b -D taskmanager.memory.task.heap.size=402653174b -D taskmanager.numberOfTaskSlots=4 -D taskmanager.memory.jvm-overhead.max=201326592b
logs: INFO  [] - Using standard YAML parser to load flink configuration file from /Users/dev/Fraud_Detection/flink-1.20.2/conf/config.yaml.
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1728m
INFO  [] - Loading configuration property: taskmanager.bind-host, localhost
INFO  [] - Loading configuration property: jobmanager.execution.failover-strategy, region
INFO  [] - Loading configuration property: jobmanager.rpc.address, localhost
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1600m
INFO  [] - Loading configuration property: jobmanager.rpc.port, 6123
INFO  [] - Loading configuration property: rest.bind-address, localhost
INFO  [] - Loading configuration property: jobmanager.bind-host, localhost
INFO  [] - Loading configuration property: taskmanager.host, localhost
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 4
INFO  [] - Loading configuration property: rest.address, localhost
INFO  [] - Loading configuration property: env.java.opts.all, --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
INFO  [] - The derived from fraction jvm overhead memory (172.800mb (181193935 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final TaskExecutor Memory configuration:
INFO  [] -   Total Process Memory:          1.688gb (1811939328 bytes)
INFO  [] -     Total Flink Memory:          1.250gb (1342177280 bytes)
INFO  [] -       Total JVM Heap Memory:     512.000mb (536870902 bytes)
INFO  [] -         Framework:               128.000mb (134217728 bytes)
INFO  [] -         Task:                    384.000mb (402653174 bytes)
INFO  [] -       Total Off-heap Memory:     768.000mb (805306378 bytes)
INFO  [] -         Managed:                 512.000mb (536870920 bytes)
INFO  [] -         Total JVM Direct Memory: 256.000mb (268435458 bytes)
INFO  [] -           Framework:             128.000mb (134217728 bytes)
INFO  [] -           Task:                  0 bytes
INFO  [] -           Network:               128.000mb (134217730 bytes)
INFO  [] -     JVM Metaspace:               256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:                192.000mb (201326592 bytes)

2025-11-06 00:18:24,326 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-11-06 00:18:24,326 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Starting TaskManager (Version: 1.20.2, Scala: 2.12, Rev:1641cb9, Date:2025-06-12T21:40:37+02:00)
2025-11-06 00:18:24,326 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  OS current user: dev
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Current Hadoop/Kerberos user: <no hadoop dependency found>
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM: OpenJDK 64-Bit Server VM - Homebrew - 17/17.0.16+0
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Arch: aarch64
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Maximum heap size: 512 MiBytes
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JAVA_HOME: /opt/homebrew/opt/openjdk@17
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  No Hadoop Dependency available
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM Options:
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xmx536870902
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xms536870902
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxDirectMemorySize=268435458
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxMetaspaceSize=268435456
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:+IgnoreUnrecognizedVMOptions
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=java.base/sun.net.util=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.lang=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.net=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.io=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.nio=ALL-UNNAMED
2025-11-06 00:18:24,327 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/sun.nio.ch=ALL-UNNAMED
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.text=ALL-UNNAMED
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.time=ALL-UNNAMED
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.util=ALL-UNNAMED
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.util.concurrent=ALL-UNNAMED
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog.file=/Users/dev/Fraud_Detection/flink-1.20.2/log/flink-dev-taskexecutor-0-Ds-MacBook-Air.local.log
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configuration=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/log4j.properties
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configurationFile=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/log4j.properties
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlogback.configurationFile=file:/Users/dev/Fraud_Detection/flink-1.20.2/conf/logback.xml
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Program Arguments:
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --configDir
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     /Users/dev/Fraud_Detection/flink-1.20.2/conf
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.min=134217730b
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,328 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.cpu.cores=4.0
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.off-heap.size=0b
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-metaspace.size=268435456b
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     external-resources=none
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.min=201326592b
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.off-heap.size=134217728b
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.max=134217730b
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.heap.size=134217728b
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.managed.size=536870920b
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.heap.size=402653174b
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.numberOfTaskSlots=4
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.max=201326592b
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Classpath: /Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-cep-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-connector-files-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-connector-kafka-3.4.0-1.20.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-csv-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-json-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-scala_2.12-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-api-java-uber-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-planner-loader-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-table-runtime-1.20.2.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/kafka-clients-3.6.0.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-1.2-api-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-api-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-core-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/log4j-slf4j-impl-2.24.3.jar:/Users/dev/Fraud_Detection/flink-1.20.2/lib/flink-dist-1.20.2.jar::::
2025-11-06 00:18:24,329 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-11-06 00:18:24,330 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2025-11-06 00:18:24,331 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Maximum number of open file descriptors is 1048576.
2025-11-06 00:18:24,334 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Using standard YAML parser to load flink configuration file from /Users/dev/Fraud_Detection/flink-1.20.2/conf/config.yaml.
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1728m
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.bind-host, localhost
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1600m
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-address, localhost
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.bind-host, localhost
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.host, localhost
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 4
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.address, localhost
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: env.java.opts.all, --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
2025-11-06 00:18:24,352 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.network.min, 134217730b
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.jvm-metaspace.size, 268435456b
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.task.off-heap.size, 0b
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.cpu.cores, 4.0
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: external-resources, none
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.jvm-overhead.min, 201326592b
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.framework.off-heap.size, 134217728b
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.network.max, 134217730b
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.framework.heap.size, 134217728b
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.managed.size, 536870920b
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.task.heap.size, 402653174b
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.numberOfTaskSlots, 4
2025-11-06 00:18:24,353 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.jvm-overhead.max, 201326592b
2025-11-06 00:18:24,367 INFO  org.apache.flink.core.fs.FileSystem                          [] - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2025-11-06 00:18:24,374 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-statsd
2025-11-06 00:18:24,375 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-prometheus
2025-11-06 00:18:24,375 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-graphite
2025-11-06 00:18:24,375 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: external-resource-gpu
2025-11-06 00:18:24,375 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-jmx
2025-11-06 00:18:24,375 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-influx
2025-11-06 00:18:24,376 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-slf4j
2025-11-06 00:18:24,376 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-datadog
2025-11-06 00:18:24,382 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - StateChangelogStorageLoader initialized with shortcut names {memory,filesystem}.
2025-11-06 00:18:24,382 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-11-06 00:18:24,382 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-11-06 00:18:24,382 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-11-06 00:18:24,382 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-11-06 00:18:24,382 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-11-06 00:18:24,382 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-11-06 00:18:24,382 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-11-06 00:18:24,382 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-11-06 00:18:24,383 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - StateChangelogStorageLoader initialized with shortcut names {memory,filesystem}.
2025-11-06 00:18:24,386 INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory [] - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.
2025-11-06 00:18:24,395 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/jaas-7696806290119725850.conf.
2025-11-06 00:18:24,397 INFO  org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory [] - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.
2025-11-06 00:18:24,515 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using configured hostname/address for TaskManager: localhost.
2025-11-06 00:18:24,529 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2025-11-06 00:18:24,748 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-11-06 00:18:24,756 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-11-06 00:18:24,757 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-11-06 00:18:24,834 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink@localhost:58208]
2025-11-06 00:18:24,866 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink@localhost:58208
2025-11-06 00:18:24,872 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using working directory: WorkingDirectory(/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/tm_localhost:58208-561ceb)
2025-11-06 00:18:24,875 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2025-11-06 00:18:24,875 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No trace reporter configured, no metrics will be exposed/reported.
2025-11-06 00:18:24,877 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2025-11-06 00:18:24,882 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2025-11-06 00:18:24,884 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-11-06 00:18:24,884 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2025-11-06 00:18:24,886 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink-metrics@localhost:58209]
2025-11-06 00:18:24,889 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink-metrics@localhost:58209
2025-11-06 00:18:24,893 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at pekko://flink-metrics/user/rpc/MetricQueryService_localhost:58208-561ceb .
2025-11-06 00:18:24,898 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/tm_localhost:58208-561ceb/blobStorage
2025-11-06 00:18:24,899 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/tm_localhost:58208-561ceb/blobStorage
2025-11-06 00:18:24,900 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2025-11-06 00:18:24,901 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2025-11-06 00:18:24,902 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2025-11-06 00:18:24,902 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2025-11-06 00:18:24,902 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-11-06 00:18:24,902 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-11-06 00:18:24,902 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-11-06 00:18:24,902 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-11-06 00:18:24,902 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-11-06 00:18:24,902 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-11-06 00:18:24,902 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-11-06 00:18:24,902 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-11-06 00:18:24,902 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2025-11-06 00:18:24,902 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: localhost:58208-561ceb
2025-11-06 00:18:24,932 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T': total 228 GB, usable 27 GB (11.84% usable)
2025-11-06 00:18:24,934 INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager         [] - Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:
	/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-io-343b7131-409d-44e3-a485-3103e67902d6
2025-11-06 00:18:24,938 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: localhost/127.0.0.1, server port range: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 4 (manual), number of client threads: 4 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2025-11-06 00:18:24,942 INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory [] - Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:
	/var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-netty-shuffle-384e46b2-db62-4f6c-a1d0-9c2fc612481d
2025-11-06 00:18:24,964 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 128 MB for network buffer pool (number of memory segments: 4096, bytes per segment: 32768).
2025-11-06 00:18:24,970 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2025-11-06 00:18:24,976 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using NIO.
2025-11-06 00:18:24,976 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 6 ms).
2025-11-06 00:18:24,977 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using NIO.
2025-11-06 00:18:24,977 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 0 ms). Listening on SocketAddress /127.0.0.1:58210.
2025-11-06 00:18:24,977 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - TaskManager data connection initialized successfully; listening internally on port: 58210
2025-11-06 00:18:24,978 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2025-11-06 00:18:24,996 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at pekko://flink/user/rpc/taskmanager_0 .
2025-11-06 00:18:25,002 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2025-11-06 00:18:25,003 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /var/folders/w8/tq7jb3rs56d45dstn263zg080000gn/T/flink-dist-cache-dc190520-946e-48a5-9c12-8bfd71ced1d6
2025-11-06 00:18:25,004 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000).
2025-11-06 00:18:25,095 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2025-11-06 00:18:25,130 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager pekko.tcp://flink@localhost:6123/user/rpc/resourcemanager_* under registration id 0731f03369374112b1d640acdcd294cc.
2025-11-06 00:19:33,429 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 514a40386c6f271ee09789bb932c5d5e for job 3d1eb7b24d44e5885efc6ab7672308f1 from resource manager with leader id 00000000000000000000000000000000.
2025-11-06 00:19:33,431 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 514a40386c6f271ee09789bb932c5d5e with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:19:33,434 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 3d1eb7b24d44e5885efc6ab7672308f1 for job leader monitoring.
2025-11-06 00:19:33,434 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-06 00:19:33,446 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-06 00:19:33,459 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 3d1eb7b24d44e5885efc6ab7672308f1.
2025-11-06 00:19:33,459 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 3d1eb7b24d44e5885efc6ab7672308f1.
2025-11-06 00:19:33,460 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 3d1eb7b24d44e5885efc6ab7672308f1.
2025-11-06 00:19:33,482 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 514a40386c6f271ee09789bb932c5d5e.
2025-11-06 00:19:33,491 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-06 00:19:33,496 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 3d1eb7b24d44e5885efc6ab7672308f1
2025-11-06 00:19:33,501 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Transactions[1] -> Sink: Collect table sink (1/1)#0 (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 514a40386c6f271ee09789bb932c5d5e.
2025-11-06 00:19:33,501 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Transactions[1] -> Sink: Collect table sink (1/1)#0 (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:19:33,503 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Transactions[1] -> Sink: Collect table sink (1/1)#0 (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-06 00:19:33,504 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 514a40386c6f271ee09789bb932c5d5e.
2025-11-06 00:19:33,505 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 3d1eb7b24d44e5885efc6ab7672308f1/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-bf72e555bb5cce27ec684161d99b9257 from localhost/127.0.0.1:58206
2025-11-06 00:19:33,547 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2cee4b20
2025-11-06 00:19:33,547 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:19:33,547 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:19:33,554 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Transactions[1] -> Sink: Collect table sink (1/1)#0 (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:19:33,686 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5e6232d7
2025-11-06 00:19:33,704 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-06 00:19:33,708 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:58413
2025-11-06 00:19:33,709 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2d438b63
2025-11-06 00:19:33,714 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Transactions[1] -> Sink: Collect table sink (1/1)#0 (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:19:33,764 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]
2025-11-06 00:19:33,774 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-06 00:19:33,795 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-06 00:19:33,796 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = 3e5f2d13-94cc-44ca-a6f4-e1bc3415d0d9, offset = 0
2025-11-06 00:19:33,805 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-06 00:19:33,806 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:19:33,806 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:19:33,806 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762368573805
2025-11-06 00:19:33,809 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-06 00:19:33,811 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-06 00:19:33,910 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-06 00:19:33,911 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null)
2025-11-06 00:19:33,919 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Found no committed offset for partition bank_transactions-0
2025-11-06 00:19:33,919 ERROR org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Received uncaught exception.
java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) [flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	... 6 more
2025-11-06 00:19:33,924 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-06 00:19:33,924 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-06 00:19:33,925 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:19:33,925 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:19:33,925 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:19:33,926 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-06 00:19:33,926 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-06 00:19:33,928 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-06 00:19:33,928 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-06 00:19:33,929 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Transactions[1] -> Sink: Collect table sink (1/1)#0 (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) [flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) [flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) [flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-06 00:19:33,930 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Transactions[1] -> Sink: Collect table sink (1/1)#0 (26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:19:33,933 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FAILED to JobManager for task Source: Transactions[1] -> Sink: Collect table sink (1/1)#0 26404d29448fb2b69526e4dd926b07e1_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-06 00:19:33,983 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:4, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 514a40386c6f271ee09789bb932c5d5e, jobId: 3d1eb7b24d44e5885efc6ab7672308f1).
2025-11-06 00:19:33,985 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 3d1eb7b24d44e5885efc6ab7672308f1 from job leader monitoring.
2025-11-06 00:19:33,985 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 3d1eb7b24d44e5885efc6ab7672308f1.
2025-11-06 00:29:46,416 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 50bee677f2badb8c7ff2503b8f1404ba for job 8523860244483d33dcb88d4181aed1ac from resource manager with leader id 00000000000000000000000000000000.
2025-11-06 00:29:46,418 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 50bee677f2badb8c7ff2503b8f1404ba with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:29:46,419 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 8523860244483d33dcb88d4181aed1ac for job leader monitoring.
2025-11-06 00:29:46,419 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_3 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-06 00:29:46,426 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-06 00:29:46,433 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job 8523860244483d33dcb88d4181aed1ac.
2025-11-06 00:29:46,433 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 8523860244483d33dcb88d4181aed1ac.
2025-11-06 00:29:46,433 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 8523860244483d33dcb88d4181aed1ac.
2025-11-06 00:29:46,443 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 50bee677f2badb8c7ff2503b8f1404ba.
2025-11-06 00:29:46,445 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-06 00:29:46,445 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 8523860244483d33dcb88d4181aed1ac
2025-11-06 00:29:46,445 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[3] -> Sink: Collect table sink (1/1)#0 (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 50bee677f2badb8c7ff2503b8f1404ba.
2025-11-06 00:29:46,447 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[3] -> Sink: Collect table sink (1/1)#0 (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:29:46,447 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 50bee677f2badb8c7ff2503b8f1404ba.
2025-11-06 00:29:46,448 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[3] -> Sink: Collect table sink (1/1)#0 (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-06 00:29:46,449 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 8523860244483d33dcb88d4181aed1ac/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-5ff77c6fb2ace8792d804d3450541a49 from localhost/127.0.0.1:58206
2025-11-06 00:29:46,463 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@94d5060
2025-11-06 00:29:46,463 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:29:46,463 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:29:46,463 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[3] -> Sink: Collect table sink (1/1)#0 (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:29:46,476 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5af7afe5
2025-11-06 00:29:46,477 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-06 00:29:46,477 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:59446
2025-11-06 00:29:46,477 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@72557a67
2025-11-06 00:29:46,478 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[3] -> Sink: Collect table sink (1/1)#0 (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:29:46,492 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]
2025-11-06 00:29:46,494 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-06 00:29:46,501 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-06 00:29:46,501 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:29:46,501 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:29:46,501 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762369186501
2025-11-06 00:29:46,502 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-06 00:29:46,502 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-06 00:29:46,505 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-06 00:29:46,505 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = daf36d05-6c06-437b-b617-6ec0897a3e85, offset = 0
2025-11-06 00:29:46,506 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-06 00:29:46,508 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null)
2025-11-06 00:29:46,510 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Found no committed offset for partition bank_transactions-0
2025-11-06 00:29:46,511 ERROR org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Received uncaught exception.
java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) [flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	... 6 more
2025-11-06 00:29:46,511 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-06 00:29:46,511 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-06 00:29:46,512 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:29:46,513 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:29:46,513 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:29:46,514 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-06 00:29:46,514 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-06 00:29:46,514 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-06 00:29:46,514 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-06 00:29:46,515 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[3] -> Sink: Collect table sink (1/1)#0 (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) [flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) [flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) [flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [bank_transactions-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-06 00:29:46,516 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[3] -> Sink: Collect table sink (1/1)#0 (1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:29:46,517 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FAILED to JobManager for task Source: bank_transactions[3] -> Sink: Collect table sink (1/1)#0 1965a48cce53713e15a553fa65e423d2_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-06 00:29:46,536 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:5, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 50bee677f2badb8c7ff2503b8f1404ba, jobId: 8523860244483d33dcb88d4181aed1ac).
2025-11-06 00:29:46,537 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 8523860244483d33dcb88d4181aed1ac from job leader monitoring.
2025-11-06 00:29:46,538 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 8523860244483d33dcb88d4181aed1ac.
2025-11-06 00:34:39,717 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request c7d866e63b870ee0be20445ba3c71283 for job 10eb6caec79f41c59376b243828b6df4 from resource manager with leader id 00000000000000000000000000000000.
2025-11-06 00:34:39,719 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for c7d866e63b870ee0be20445ba3c71283 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:34:39,720 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 10eb6caec79f41c59376b243828b6df4 for job leader monitoring.
2025-11-06 00:34:39,720 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_4 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-06 00:34:39,729 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-06 00:34:39,739 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job 10eb6caec79f41c59376b243828b6df4.
2025-11-06 00:34:39,740 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 10eb6caec79f41c59376b243828b6df4.
2025-11-06 00:34:39,740 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 10eb6caec79f41c59376b243828b6df4.
2025-11-06 00:34:39,749 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot c7d866e63b870ee0be20445ba3c71283.
2025-11-06 00:34:39,752 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-06 00:34:39,752 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 10eb6caec79f41c59376b243828b6df4
2025-11-06 00:34:39,754 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id c7d866e63b870ee0be20445ba3c71283.
2025-11-06 00:34:39,755 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:34:39,755 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot c7d866e63b870ee0be20445ba3c71283.
2025-11-06 00:34:39,756 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-06 00:34:39,757 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 10eb6caec79f41c59376b243828b6df4/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-acc5c7a7ae56ab442a16443c184bd0b2 from localhost/127.0.0.1:58206
2025-11-06 00:34:39,770 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@70029f27
2025-11-06 00:34:39,771 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:34:39,771 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:34:39,771 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:34:39,785 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7de0b501
2025-11-06 00:34:39,785 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-06 00:34:39,786 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:60015
2025-11-06 00:34:39,787 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@37709615
2025-11-06 00:34:39,789 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:34:39,799 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: 2512, StoppingOffset: -9223372036854775808]]
2025-11-06 00:34:39,800 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-06 00:34:39,803 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-06 00:34:39,803 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:34:39,803 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:34:39,803 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762369479803
2025-11-06 00:34:39,804 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-06 00:34:39,804 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-06 00:34:39,808 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to offset 2512 for partition bank_transactions-0
2025-11-06 00:34:39,816 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-06 00:34:39,816 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = 7c6fd169-8b59-4d64-8c85-1af718b63190, offset = 0
2025-11-06 00:34:39,820 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-06 00:34:45,827 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:34:45,828 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-06 00:34:45,828 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:34:45,829 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-06 00:34:45,830 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-06 00:34:45,830 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-06 00:34:45,830 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-06 00:34:46,239 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:34:46,240 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:34:46,240 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:34:46,243 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-06 00:34:46,243 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-06 00:34:46,245 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-06 00:34:46,245 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 (0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:34:46,246 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[5] -> Sink: Collect table sink (1/1)#0 0a76de0710d2646d7c4e351b0a44c4cd_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-06 00:34:46,261 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:6, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: c7d866e63b870ee0be20445ba3c71283, jobId: 10eb6caec79f41c59376b243828b6df4).
2025-11-06 00:34:46,262 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 10eb6caec79f41c59376b243828b6df4 from job leader monitoring.
2025-11-06 00:34:46,262 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 10eb6caec79f41c59376b243828b6df4.
2025-11-06 00:35:18,462 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 8720892abccdfd412244e31f3985bca0 for job f8db9ac8636b2d020c59b3c865773346 from resource manager with leader id 00000000000000000000000000000000.
2025-11-06 00:35:18,464 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 8720892abccdfd412244e31f3985bca0 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:35:18,465 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job f8db9ac8636b2d020c59b3c865773346 for job leader monitoring.
2025-11-06 00:35:18,465 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_5 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-06 00:35:18,468 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-06 00:35:18,470 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job f8db9ac8636b2d020c59b3c865773346.
2025-11-06 00:35:18,470 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job f8db9ac8636b2d020c59b3c865773346.
2025-11-06 00:35:18,470 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job f8db9ac8636b2d020c59b3c865773346.
2025-11-06 00:35:18,475 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 8720892abccdfd412244e31f3985bca0.
2025-11-06 00:35:18,475 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 8720892abccdfd412244e31f3985bca0.
2025-11-06 00:35:18,476 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-06 00:35:18,476 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id f8db9ac8636b2d020c59b3c865773346
2025-11-06 00:35:18,476 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 8720892abccdfd412244e31f3985bca0.
2025-11-06 00:35:18,477 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:35:18,477 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-06 00:35:18,478 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading f8db9ac8636b2d020c59b3c865773346/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-97dce960c2470fe085bb1dc5f87678fa from localhost/127.0.0.1:58206
2025-11-06 00:35:18,485 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@f95ebe8
2025-11-06 00:35:18,485 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:35:18,485 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:35:18,485 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:35:18,494 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@4cae0a17
2025-11-06 00:35:18,495 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-06 00:35:18,495 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:62821
2025-11-06 00:35:18,495 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@4d2d43a0
2025-11-06 00:35:18,496 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:35:18,506 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-06 00:35:18,507 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-06 00:35:18,511 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-06 00:35:18,512 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:35:18,512 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:35:18,512 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762369518512
2025-11-06 00:35:18,512 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-06 00:35:18,513 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-06 00:35:18,514 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition bank_transactions-0
2025-11-06 00:35:18,521 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-06 00:35:18,527 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition bank_transactions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=4}}.
2025-11-06 00:35:18,566 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-06 00:35:18,566 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = 0f489e1f-6c70-4adb-9d8c-6b7101964e23, offset = 0
2025-11-06 00:35:23,577 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:35:23,577 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-06 00:35:23,577 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:35:23,579 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-06 00:35:23,579 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-06 00:35:23,579 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-06 00:35:23,579 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-06 00:35:23,892 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:35:23,893 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:35:23,893 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:35:23,894 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-06 00:35:23,895 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-06 00:35:23,895 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-06 00:35:23,895 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 (031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:35:23,895 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: bank_transactions[7] -> Sink: Collect table sink (1/1)#0 031d31755902136904cc276b9d0ccee8_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-06 00:35:23,907 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:7, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: 8720892abccdfd412244e31f3985bca0, jobId: f8db9ac8636b2d020c59b3c865773346).
2025-11-06 00:35:23,907 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job f8db9ac8636b2d020c59b3c865773346 from job leader monitoring.
2025-11-06 00:35:23,907 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job f8db9ac8636b2d020c59b3c865773346.
2025-11-06 00:45:32,787 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request b6d99023b0b70ffb267e39de305b24b9 for job cd2386fda47b118106c8361b9776ae13 from resource manager with leader id 00000000000000000000000000000000.
2025-11-06 00:45:32,790 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for b6d99023b0b70ffb267e39de305b24b9 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:45:32,790 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job cd2386fda47b118106c8361b9776ae13 for job leader monitoring.
2025-11-06 00:45:32,791 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_6 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-06 00:45:32,796 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-06 00:45:32,800 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job cd2386fda47b118106c8361b9776ae13.
2025-11-06 00:45:32,800 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job cd2386fda47b118106c8361b9776ae13.
2025-11-06 00:45:32,800 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job cd2386fda47b118106c8361b9776ae13.
2025-11-06 00:45:32,808 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot b6d99023b0b70ffb267e39de305b24b9.
2025-11-06 00:45:32,808 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot b6d99023b0b70ffb267e39de305b24b9.
2025-11-06 00:45:32,810 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-06 00:45:32,810 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id cd2386fda47b118106c8361b9776ae13
2025-11-06 00:45:32,810 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: fraud_alerts[11] -> Sink: Collect table sink (1/1)#0 (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id b6d99023b0b70ffb267e39de305b24b9.
2025-11-06 00:45:32,811 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: fraud_alerts[11] -> Sink: Collect table sink (1/1)#0 (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:45:32,812 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: fraud_alerts[11] -> Sink: Collect table sink (1/1)#0 (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-06 00:45:32,813 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading cd2386fda47b118106c8361b9776ae13/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-8ca14ef164d3318b4ef917342b50a50e from localhost/127.0.0.1:58206
2025-11-06 00:45:32,821 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@60a08cdd
2025-11-06 00:45:32,821 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:45:32,821 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:45:32,821 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: fraud_alerts[11] -> Sink: Collect table sink (1/1)#0 (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:45:32,830 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@844e567
2025-11-06 00:45:32,830 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-06 00:45:32,830 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:62298
2025-11-06 00:45:32,831 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@66a1693d
2025-11-06 00:45:32,832 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: fraud_alerts[11] -> Sink: Collect table sink (1/1)#0 (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:45:32,835 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: fraud_alerts-0, StartingOffset: -3, StoppingOffset: -9223372036854775808]]
2025-11-06 00:45:32,836 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-06 00:45:32,839 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-06 00:45:32,839 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:45:32,839 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:45:32,839 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762370132839
2025-11-06 00:45:32,840 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-06 00:45:32,840 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): fraud_alerts-0
2025-11-06 00:45:32,843 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-06 00:45:32,845 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null)
2025-11-06 00:45:32,864 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Found no committed offset for partition fraud_alerts-0
2025-11-06 00:45:32,865 ERROR org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Received uncaught exception.
java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) [flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [fraud_alerts-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	... 6 more
2025-11-06 00:45:32,866 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-06 00:45:32,866 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-06 00:45:32,867 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:45:32,867 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:45:32,867 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:45:32,867 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-06 00:45:32,867 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-06 00:45:32,869 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-06 00:45:32,869 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-06 00:45:32,869 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - Source: fraud_alerts[11] -> Sink: Collect table sink (1/1)#0 (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:333) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:228) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:190) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:443) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:638) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:973) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:917) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:970) ~[flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:949) [flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:763) [flink-dist-1.20.2.jar:1.20.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) [flink-dist-1.20.2.jar:1.20.2]
	at java.base/java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
Caused by: org.apache.kafka.clients.consumer.NoOffsetForPartitionException: Undefined offset with no reset policy for partitions: [fraud_alerts-0]
	at org.apache.kafka.clients.consumer.internals.SubscriptionState.resetInitializingPositions(SubscriptionState.java:711) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2451) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1727) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1686) ~[kafka-clients-3.6.0.jar:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.lambda$removeEmptySplits$5(KafkaPartitionSplitReader.java:375) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.retryOnWakeup(KafkaPartitionSplitReader.java:481) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.removeEmptySplits(KafkaPartitionSplitReader.java:374) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.handleSplitsChanges(KafkaPartitionSplitReader.java:224) ~[flink-connector-kafka-3.4.0-1.20.jar:3.4.0-1.20]
	at org.apache.flink.connector.base.source.reader.fetcher.AddSplitsTask.run(AddSplitsTask.java:51) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.20.2.jar:1.20.2]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	... 1 more
2025-11-06 00:45:32,871 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: fraud_alerts[11] -> Sink: Collect table sink (1/1)#0 (fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:45:32,872 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FAILED to JobManager for task Source: fraud_alerts[11] -> Sink: Collect table sink (1/1)#0 fde20c2ad244ffbc14563ea9edb6c13a_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-06 00:45:32,885 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:8, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: b6d99023b0b70ffb267e39de305b24b9, jobId: cd2386fda47b118106c8361b9776ae13).
2025-11-06 00:45:32,885 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job cd2386fda47b118106c8361b9776ae13 from job leader monitoring.
2025-11-06 00:45:32,885 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job cd2386fda47b118106c8361b9776ae13.
2025-11-06 00:47:40,276 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request c94dc1619f308efc85ce79c4e11625bf for job 6838c0282a56a12fd35a2c5439010c3f from resource manager with leader id 00000000000000000000000000000000.
2025-11-06 00:47:40,278 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for c94dc1619f308efc85ce79c4e11625bf with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:47:40,278 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 6838c0282a56a12fd35a2c5439010c3f for job leader monitoring.
2025-11-06 00:47:40,279 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_7 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-06 00:47:40,282 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-06 00:47:40,287 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_7 for job 6838c0282a56a12fd35a2c5439010c3f.
2025-11-06 00:47:40,287 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 6838c0282a56a12fd35a2c5439010c3f.
2025-11-06 00:47:40,287 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 6838c0282a56a12fd35a2c5439010c3f.
2025-11-06 00:47:40,292 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot c94dc1619f308efc85ce79c4e11625bf.
2025-11-06 00:47:40,293 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot c94dc1619f308efc85ce79c4e11625bf.
2025-11-06 00:47:40,295 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-06 00:47:40,295 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 6838c0282a56a12fd35a2c5439010c3f
2025-11-06 00:47:40,296 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id c94dc1619f308efc85ce79c4e11625bf.
2025-11-06 00:47:40,296 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:47:40,297 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-11-06 00:47:40,299 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 6838c0282a56a12fd35a2c5439010c3f/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-985fe024554086e88cfd2f7dcefe4ade from localhost/127.0.0.1:58206
2025-11-06 00:47:40,312 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@71db5e49
2025-11-06 00:47:40,312 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:47:40,312 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:47:40,313 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:47:40,321 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@692f7cc7
2025-11-06 00:47:40,322 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Initializing collect sink state with offset = 0, buffered results bytes = 0
2025-11-06 00:47:40,323 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Collect sink server established, address = localhost/127.0.0.1:63252
2025-11-06 00:47:40,324 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1d817f72
2025-11-06 00:47:40,324 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:47:40,328 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: fraud_alerts-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-06 00:47:40,329 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-06 00:47:40,333 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-06 00:47:40,333 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:47:40,333 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:47:40,333 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762370260333
2025-11-06 00:47:40,334 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-06 00:47:40,334 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): fraud_alerts-0
2025-11-06 00:47:40,335 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition fraud_alerts-0
2025-11-06 00:47:40,350 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-06 00:47:40,356 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition fraud_alerts-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=4}}.
2025-11-06 00:47:40,371 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Coordinator connection received
2025-11-06 00:47:40,371 INFO  org.apache.flink.streaming.api.operators.collect.CollectSinkFunction [] - Invalid request. Received version = , offset = 0, while expected version = 90d4894b-336c-4727-90cc-edded812fd0c, offset = 0
2025-11-06 00:48:16,354 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:48:16,354 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2025-11-06 00:48:16,355 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:48:16,357 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2025-11-06 00:48:16,357 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2025-11-06 00:48:16,358 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-11-06 00:48:16,358 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2025-11-06 00:48:16,896 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:48:16,897 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:48:16,897 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:48:16,899 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for flink-consumer-group-0 unregistered
2025-11-06 00:48:16,899 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2025-11-06 00:48:16,900 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2025-11-06 00:48:16,900 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 (f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-11-06 00:48:16,901 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: fraud_alerts[13] -> Sink: Collect table sink (1/1)#0 f718b06da9308ed319bd6ea70c037b61_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-11-06 00:48:16,926 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:9, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}, allocationId: c94dc1619f308efc85ce79c4e11625bf, jobId: 6838c0282a56a12fd35a2c5439010c3f).
2025-11-06 00:48:16,927 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 6838c0282a56a12fd35a2c5439010c3f from job leader monitoring.
2025-11-06 00:48:16,929 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 6838c0282a56a12fd35a2c5439010c3f.
2025-11-06 00:54:45,645 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 7a957edf10c763bbcd16ec3f75c61723 for job 99cc4dbedc6b43cb38426cc7205f57a3 from resource manager with leader id 00000000000000000000000000000000.
2025-11-06 00:54:45,646 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Allocated slot for 7a957edf10c763bbcd16ec3f75c61723 with resources ResourceProfile{cpuCores=1, taskHeapMemory=96.000mb (100663293 bytes), taskOffHeapMemory=0 bytes, managedMemory=128.000mb (134217730 bytes), networkMemory=32.000mb (33554432 bytes)}.
2025-11-06 00:54:45,647 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 99cc4dbedc6b43cb38426cc7205f57a3 for job leader monitoring.
2025-11-06 00:54:45,647 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_8 with leader id 00000000-0000-0000-0000-000000000000.
2025-11-06 00:54:45,652 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-11-06 00:54:45,654 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager pekko.tcp://flink@localhost:6123/user/rpc/jobmanager_8 for job 99cc4dbedc6b43cb38426cc7205f57a3.
2025-11-06 00:54:45,655 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 99cc4dbedc6b43cb38426cc7205f57a3.
2025-11-06 00:54:45,655 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 99cc4dbedc6b43cb38426cc7205f57a3.
2025-11-06 00:54:45,673 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,676 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-11-06 00:54:45,677 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 99cc4dbedc6b43cb38426cc7205f57a3
2025-11-06 00:54:45,685 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0), deploy into slot with allocation id 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,686 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,686 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:54:45,686 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0) [DEPLOYING].
2025-11-06 00:54:45,687 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 99cc4dbedc6b43cb38426cc7205f57a3/p-d47a6ec598a41f8cb5c21f3ed7444f957b096f90-cede7eb8c9d82b7af3d672ab1c12e9df from localhost/127.0.0.1:58206
2025-11-06 00:54:45,716 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Join[28] -> Calc[29] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0), deploy into slot with allocation id 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,716 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,716 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[28] -> Calc[29] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:54:45,717 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Join[28] -> Calc[29] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0) [DEPLOYING].
2025-11-06 00:54:45,719 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task GlobalWindowAggregate[21] -> Calc[22] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0), deploy into slot with allocation id 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,719 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,720 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - GlobalWindowAggregate[21] -> Calc[22] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:54:45,721 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task GlobalWindowAggregate[21] -> Calc[22] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0) [DEPLOYING].
2025-11-06 00:54:45,721 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@b237876
2025-11-06 00:54:45,721 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:54:45,721 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:54:45,722 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6c83bc3
2025-11-06 00:54:45,722 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:54:45,722 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:54:45,722 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Join[24] -> Calc[25] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0), deploy into slot with allocation id 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,722 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,722 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[28] -> Calc[29] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,723 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,723 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,723 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[24] -> Calc[25] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:54:45,723 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Join[24] -> Calc[25] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0) [DEPLOYING].
2025-11-06 00:54:45,724 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1e37e4da
2025-11-06 00:54:45,724 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:54:45,725 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:54:45,725 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - GlobalWindowAggregate[21] -> Calc[22] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,725 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@64ac5db2
2025-11-06 00:54:45,725 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:54:45,725 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:54:45,726 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[24] -> Calc[25] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,728 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0), deploy into slot with allocation id 7a957edf10c763bbcd16ec3f75c61723.
2025-11-06 00:54:45,729 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from CREATED to DEPLOYING.
2025-11-06 00:54:45,729 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0) [DEPLOYING].
2025-11-06 00:54:45,729 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@62555175
2025-11-06 00:54:45,729 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-11-06 00:54:45,729 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-11-06 00:54:45,729 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from DEPLOYING to INITIALIZING.
2025-11-06 00:54:45,785 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3d39d793
2025-11-06 00:54:45,787 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6d43d900
2025-11-06 00:54:45,789 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@58baf044
2025-11-06 00:54:45,790 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@480c4021
2025-11-06 00:54:45,793 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@470939b4
2025-11-06 00:54:45,793 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2bb1ce25
2025-11-06 00:54:45,809 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7df809d3
2025-11-06 00:54:45,810 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@edba5ed
2025-11-06 00:54:45,814 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2025-11-06 00:54:45,816 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder [] - Finished to build heap keyed state-backend.
2025-11-06 00:54:45,816 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder [] - Finished to build heap keyed state-backend.
2025-11-06 00:54:45,816 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder [] - Finished to build heap keyed state-backend.
2025-11-06 00:54:45,820 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-11-06 00:54:45,823 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend    [] - Initializing heap keyed state backend with stream factory.
2025-11-06 00:54:45,823 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend    [] - Initializing heap keyed state backend with stream factory.
2025-11-06 00:54:45,823 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend    [] - Initializing heap keyed state backend with stream factory.
2025-11-06 00:54:45,842 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@bb96937
2025-11-06 00:54:45,847 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - These configurations '[group.id]' were supplied but are not used yet.
2025-11-06 00:54:45,847 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:54:45,847 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:54:45,848 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762370685847
2025-11-06 00:54:45,854 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - fraud_alerts[33]: Writer -> fraud_alerts[33]: Committer (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_c1426cf63a44e3f9acf0182406d6949f_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,855 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-1] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-06 00:54:45,858 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[24] -> Calc[25] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_4fda3f41f10225fc13b7996a1749e065_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,865 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Join[28] -> Calc[29] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_f903181e99c89a09cba2df29130e7591_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,871 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@22aa6002
2025-11-06 00:54:45,872 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7821cbb
2025-11-06 00:54:45,872 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@50f7c70
2025-11-06 00:54:45,884 INFO  org.apache.flink.table.runtime.util.collections.binary.AbstractBytesMultiMap [] - BytesMultiMap with initial memory segments 2048, 67108864 in bytes, init allocating 32 for bucket area.
2025-11-06 00:54:45,884 INFO  org.apache.flink.table.runtime.util.collections.binary.AbstractBytesMultiMap [] - BytesMultiMap with initial memory segments 2048, 67108864 in bytes, init allocating 32 for bucket area.
2025-11-06 00:54:45,884 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@66304fe3
2025-11-06 00:54:45,884 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2015c5fb
2025-11-06 00:54:45,884 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@166240d4
2025-11-06 00:54:45,885 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend is set to heap memory org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5da9f06a
2025-11-06 00:54:45,885 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - GlobalWindowAggregate[21] -> Calc[22] (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5e000441d5075bb085278cafa0ec71ad_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,885 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: bank_transactions[15] -> (Calc[16], Calc[18] -> LocalWindowAggregate[19], Calc[26], Calc[31]) (1/1)#0 (902f24fb1630037e82f9c6c8929192fc_5da08a4269629ebce1b7dfad7a855276_0_0) switched from INITIALIZING to RUNNING.
2025-11-06 00:54:45,888 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: bank_transactions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2025-11-06 00:54:45,888 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-11-06 00:54:45,889 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.
2025-11-06 00:54:45,889 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:54:45,889 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:54:45,889 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762370685889
2025-11-06 00:54:45,890 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2025-11-06 00:54:45,890 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Assigned to partition(s): bank_transactions-0
2025-11-06 00:54:45,890 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Seeking to earliest offset of partition bank_transactions-0
2025-11-06 00:54:45,892 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-06 00:54:45,895 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Resetting offset for partition bank_transactions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=4}}.
2025-11-06 00:54:45,932 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2025-11-06 00:54:45,933 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-2] Instantiated an idempotent producer.
2025-11-06 00:54:45,935 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - These configurations '[group.id]' were supplied but are not used yet.
2025-11-06 00:54:45,935 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.6.0
2025-11-06 00:54:45,935 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 60e845626d8a465a
2025-11-06 00:54:45,935 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1762370685935
2025-11-06 00:54:45,939 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-2] Cluster ID: q3xk7deyQhC2vrswHioXSw
2025-11-06 00:54:45,940 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2025-11-06 00:54:46,044 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-11-06 00:54:46,045 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-06 00:54:46,045 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-11-06 00:54:46,045 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-2 unregistered
2025-11-06 00:54:46,139 INFO  org.apache.kafka.clients.producer.internals.TransactionManager [] - [Producer clientId=producer-1] ProducerId set to 8000 with epoch 0
2025-11-06 03:34:10,853 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Node -1 disconnected.
2025-11-06 03:34:38,074 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node -1 disconnected.
2025-11-07 03:47:34,661 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-07 03:47:34,681 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 3888 due to node 1 being disconnected (elapsed time since creation: 981209ms, elapsed time since send: 981209ms, request timeout: 30000ms)
2025-11-07 03:47:34,691 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=107487103, epoch=3780) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-07 08:58:38,744 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-07 08:58:38,746 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 4175 due to node 1 being disconnected (elapsed time since creation: 990520ms, elapsed time since send: 990520ms, request timeout: 30000ms)
2025-11-07 08:58:38,746 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=805914465, epoch=265) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-07 10:41:22,586 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-07 10:41:22,647 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 4284 due to node 1 being disconnected (elapsed time since creation: 904126ms, elapsed time since send: 904126ms, request timeout: 30000ms)
2025-11-07 10:41:22,648 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=1348789513, epoch=100) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-07 14:46:58,884 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-07 14:46:58,886 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 4543 due to node 1 being disconnected (elapsed time since creation: 576169ms, elapsed time since send: 576169ms, request timeout: 30000ms)
2025-11-07 14:46:58,887 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=1905348519, epoch=241) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-07 16:36:52,723 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-07 16:36:52,725 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 4670 due to node 1 being disconnected (elapsed time since creation: 908216ms, elapsed time since send: 908216ms, request timeout: 30000ms)
2025-11-07 16:36:52,726 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=286796739, epoch=117) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-08 12:57:44,009 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-08 12:57:44,011 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 6266 due to node 1 being disconnected (elapsed time since creation: 392856ms, elapsed time since send: 392856ms, request timeout: 30000ms)
2025-11-08 12:57:44,012 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=705709910, epoch=1512) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-08 22:10:28,778 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-08 22:10:28,781 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 6944 due to node 1 being disconnected (elapsed time since creation: 617628ms, elapsed time since send: 617628ms, request timeout: 30000ms)
2025-11-08 22:10:28,781 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=1258659348, epoch=638) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-08 23:50:12,406 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-08 23:50:12,454 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 7082 due to node 1 being disconnected (elapsed time since creation: 1050352ms, elapsed time since send: 1050352ms, request timeout: 30000ms)
2025-11-08 23:50:12,454 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=2118942689, epoch=129) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-09 06:27:06,499 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-09 06:27:06,507 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 7405 due to node 1 being disconnected (elapsed time since creation: 993167ms, elapsed time since send: 993167ms, request timeout: 30000ms)
2025-11-09 06:27:06,507 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=23204957, epoch=296) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-11-09 17:15:32,505 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Disconnecting from node 1 due to request timeout.
2025-11-09 17:15:32,511 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Cancelled in-flight FETCH request with correlation id 8439 due to node 1 being disconnected (elapsed time since creation: 918627ms, elapsed time since send: 918627ms, request timeout: 30000ms)
2025-11-09 17:15:32,512 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=flink-consumer-group-0, groupId=flink-consumer-group] Error sending fetch request (sessionId=397970956, epoch=989) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
